<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[k8s-国内环境集群搭建-通过sealos]]></title>
    <url>%2F2020%2F08%2F06%2Fk8s-%E5%9B%BD%E5%86%85%E7%8E%AF%E5%A2%83%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-%E9%80%9A%E8%BF%87sealos%2F</url>
    <content type="text"><![CDATA[k8s-国内环境集群搭建-通过sealos准备工作 获得 Kubernetes 最新版本离线包, 除默认的 1.14.1 版本外, 需要付费下载 准备服务器 主机名不可重复 12# 修改 hostname$ hostnamectl set-hostname --static k8s-x 支持 root 用户远程 ssh 登录 1234567$ vim /etc/ssh/sshd_config修改 PasswordAuthentication yes若无法使用 root 用户进行 SSH 登录, 还需修改 PermitRootLogin yes$ service sshd restart 安装 sealos 123# 下载并安装sealos, sealos是个golang的二进制工具，直接下载拷贝到bin目录即可, release页面也可下载wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos &amp;&amp; \ chmod +x sealos &amp;&amp; mv sealos /usr/bin 提前下载离线资源包, 也可以 init 时直接指定下载地址 12# 下载离线资源包wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/054f15a19f3c943bf387b3da25ef3de1-1.18.6/kube1.18.6.tar.gz 执行命令安装 需要 root 用户执行 123456# 安装 kubernetes 集群sealos init --passwd 123456 \ --master 192.168.0.2 --master 192.168.0.3 --master 192.168.0.4 \ --node 192.168.0.5 --node 192.168.0.6 --node 192.168.0.7 \ --pkg-url https://sealyun.oss-cn-beijing.aliyuncs.com/054f15a19f3c943bf387b3da25ef3de1-1.18.6/kube1.18.6.tar.gz \ --version v1.18.6 检查安装是否正常1234567891011121314151617181920212223242526272829303132[root@iZj6cdqfqw4o4o9tc0q44rZ ~]# kubectl get nodeNAME STATUS ROLES AGE VERSIONizj6cdqfqw4o4o9tc0q44rz Ready master 2m25s v1.14.1izj6cdqfqw4o4o9tc0q44sz Ready master 119s v1.14.1izj6cdqfqw4o4o9tc0q44tz Ready master 63s v1.14.1izj6cdqfqw4o4o9tc0q44uz Ready &lt;none&gt; 38s v1.14.1[root@iZj6cdqfqw4o4o9tc0q44rZ ~]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-5cbcccc885-9n2p8 1/1 Running 0 3m1skube-system calico-node-656zn 1/1 Running 0 93skube-system calico-node-bv5hn 1/1 Running 0 2m54skube-system calico-node-f2vmd 1/1 Running 0 3m1skube-system calico-node-tbd5l 1/1 Running 0 118skube-system coredns-fb8b8dccf-8bnkv 1/1 Running 0 3m1skube-system coredns-fb8b8dccf-spq7r 1/1 Running 0 3m1skube-system etcd-izj6cdqfqw4o4o9tc0q44rz 1/1 Running 0 2m25skube-system etcd-izj6cdqfqw4o4o9tc0q44sz 1/1 Running 0 2m53skube-system etcd-izj6cdqfqw4o4o9tc0q44tz 1/1 Running 0 118skube-system kube-apiserver-izj6cdqfqw4o4o9tc0q44rz 1/1 Running 0 2m15skube-system kube-apiserver-izj6cdqfqw4o4o9tc0q44sz 1/1 Running 0 2m54skube-system kube-apiserver-izj6cdqfqw4o4o9tc0q44tz 1/1 Running 1 47skube-system kube-controller-manager-izj6cdqfqw4o4o9tc0q44rz 1/1 Running 1 2m43skube-system kube-controller-manager-izj6cdqfqw4o4o9tc0q44sz 1/1 Running 0 2m54skube-system kube-controller-manager-izj6cdqfqw4o4o9tc0q44tz 1/1 Running 0 63skube-system kube-proxy-b9b9z 1/1 Running 0 2m54skube-system kube-proxy-nf66n 1/1 Running 0 3m1skube-system kube-proxy-q2bqp 1/1 Running 0 118skube-system kube-proxy-s5g2k 1/1 Running 0 93skube-system kube-scheduler-izj6cdqfqw4o4o9tc0q44rz 1/1 Running 1 2m43skube-system kube-scheduler-izj6cdqfqw4o4o9tc0q44sz 1/1 Running 0 2m54skube-system kube-scheduler-izj6cdqfqw4o4o9tc0q44tz 1/1 Running 0 61skube-system kube-sealyun-lvscare-izj6cdqfqw4o4o9tc0q44uz 1/1 Running 0 86s 其他配置授权信息给非 root 用户 登录需要授权的用户 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 安装 Web UI (Kuboard) 在 master 服务器输入以下命令 12kubectl apply -f https://kuboard.cn/install-script/kuboard.yamlkubectl apply -f https://addons.kuboard.cn/metrics-server/0.3.7/metrics-server.yaml 查看 Kuboard 运行状态 1kubectl get pods -l k8s.kuboard.cn/name=kuboard -n kube-system 12NAME READY STATUS RESTARTS AGEkuboard-54c9c4f6cb-6lf88 1/1 Running 0 45s 获取 token 1echo $(kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk '&#123;print $1&#125;') -o go-template='&#123;&#123;.data.token&#125;&#125;' | base64 -d) 1eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWc4aHhiIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI5NDhiYjVlNi04Y2RjLTExZTktYjY3ZS1mYTE2M2U1ZjdhMGYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.DZ6dMTr8GExo5IH_vCWdB_MDfQaNognjfZKl0E5VW8vUFMVvALwo0BS-6Qsqpfxrlz87oE9yGVCpBYV0D00811bLhHIg-IR_MiBneadcqdQ_TGm_a0Pz0RbIzqJlRPiyMSxk1eXhmayfPn01upPdVCQj6D3vAY77dpcGplu3p5wE6vsNWAvrQ2d_V1KhR03IB1jJZkYwrI8FHCq_5YuzkPfHsgZ9MBQgH-jqqNXs6r8aoUZIbLsYcMHkin2vzRsMy_tjMCI9yXGiOqI-E5efTb-_KbDVwV5cbdqEIegdtYZ2J3mlrFQlmPGYTwFI8Ba9LleSYbCi4o0k74568KcN_w 访问 Kuboard Kuboard Service 使用了 NodePort 的方式暴露服务，NodePort 为 32567 可以访问 http://任意一个 Worker 节点的 IP 地址:32567/ 输入前一步骤中获得的 token，可进入 Kuboard 集群概览页 官方文档: https://sealyun.com/docs/ https://kuboard.cn/install/install-dashboard.html]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 集合与同步]]></title>
    <url>%2F2020%2F08%2F05%2FJava-%E9%9B%86%E5%90%88%E4%B8%8E%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java 垃圾回收]]></title>
    <url>%2F2020%2F07%2F28%2FJava-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%8E%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Java 垃圾回收 垃圾回收就是由程序自动的回收已死对象, 可以分为两个部分 如何判断对象已死 如何清理掉已死对象 判断对象是否存活引用计数法 给对象中添加一个引用计数器 每当有一个地方引用它时，计数器就加 1 当引用失效时, 计数器就减 1 当对象的计数器值为 0 时，则代表该对象可以被回收了 优点是实现简单且回收效率高 缺点是无法解决循环引用的问题, 即两个对象相互引用的情况 可达性分析 被商用 JVM 采用 从 GC ROOT 作为起点开始遍历所有节点, GC ROOT 指以下几类对象 虚拟机栈的栈帧的局部变量表所引用的对象 本地方法栈的 JNI 所引用的对象 方法区的静态变量和常量所引用的对象 对于遍历到的每个节点都做一个标识 遍历完成后, 没有标识的节点说明是可回收的 回收算法标记清除 通常使用一张表 (类似) 来记录哪些空间已被使用 首先通过可达性分析找到所有的垃圾，然后将其占用的空间释放掉 该算法的问题是可能会产生大量的内存碎片 标记整理 为了解决内存碎片的问题，标记整理在标记清除算法上做了优化 在找到所有垃圾对象后，不是直接释放掉其占用的空间，而是将所有存活对象往内存一端移动 回收完成后，所有对象都是相邻的 复制算法 复制算法将内存区域划分为两个，同一时间只有一个区域有对象 每次垃圾回收时，通过可达性分析算法，找出所有存活对象，将这些存活对象移动到另一区域 为新对象分配内存时，可以通过智能指针的形式，高效简单 复制算法的缺点是会浪费一部分空间以便存放下次回收后存活的对象且需要一块额外的空间进行担保（当一个区域存放不下存活的对象时） 分代收集 在商用 JVM 中，大多使用的是分代收集算法 根据对象的特性，可以将内存划分为 3 个代：年轻代，老年代，永久代（ JVM 8 后称为元空间） 年轻代存放新分配的对象，使用的是复制算法 老年代使用标记清除或标记整理算法 其中年轻代分为一个 Eden 区和两个 Survivor 区 (From, To)，其比例默认为 8:1:1（-XX:SurvivorRatio） 优先在 Eden 区分配对象 Eden 区空间不足，触发 Minor GC (Young GC)，标记可回收对象，然后 Eden 区存活对象拷贝到往 Survivor-From 区，接下来清空 Eden 区 再次触发 Minor GC，扫描 Eden 区和 From 区，把存活的对象复制到 To 区，清空 Eden 区和 From 区 如果在 Minor GC 复制存活对象到 Survivor 区时，发现 Survivor 区内存不够，则提前把对象放入老年代 大对象直接进入老年代 如果发现需要大量连续内存空间的 Java 对象，如很长的字符串或者数组，则直接把对象放入老年代 可通过 -XX:PretenureSizeThreshold 参数设置大对象的最小大小，该参数只对 Serial 和 ParNew 两款收集器有效 因为新生代采用复制算法收集垃圾，大对象直接进入老年代，避免在 Eden 区和 Survivor 区发生大量内存复制 写程序的时候尽量避免大对象 长期存活对象进入老年代 固定对象年龄判断：默认情况，存活对象在 Survivor 的 From 和 To 区来回交换 15 次后，如果对象最终还是存活，就放入老年代 可以通过 -XX:MaxTenuringThreshold 参数来设置对象的年龄 动态对象年龄判断：如果发现 Survivor 中有相同年龄的对象空间总和大于 Survivor 空间的一半，那么年龄大于或者等于该年龄的对象直接晋升到老年代 空间分配担保 为什么需要分配担保 如果 Survivor 区存活了很多对象，空间不够了，都需要晋升到老年代，那么就需要老年代进行分配担保，也就是将Survivor 无法容纳的对象直接进入老年代 发生 Minor GC 前，JVM 先检查老年代最大可用连续空间是否大于新生代所有对象的总空间 大于：空间足够，直接 Minor GC 小于：进行一次 Full GC JDK 6 Update 24 前会根据 HandlePromotionFailure 参数判断是否允许担保失败 如果允许，则尝试一次 Minor GC 否则，则进行 Full GC 年轻代老年代比例默认为 1:2 (-XX:NewRatio, -Xmn) 年轻代使用复制算法的原因是年轻代对象的创建和回收很频繁，同时大部分对象很快都会死亡，所以复制算法创建和回收对象的效率都比较高 老年代不使用复制算法的原因是老年代对象通常存活时间比较长，如果采用复制算法，则复制存活对象的开销会比较大，且复制算法是需要其他区域担保的。 所以老年代不使用复制算法 垃圾回收器Serial 串行回收器（年轻代） 使用单线程，复制算法实现 在回收的整个过程中需要 STW (Stop The World) 在单核 CPU 的机器上，使用单线程进行垃圾回收效率更高 使用方法：XX:+UseSerialGC ps：在 JDK Client 模式，不指定 VM 参数，默认是串行垃圾回收器 Serial Old 串行回收器（老年代） 与 Serial 相似，但使用标记整理算法实现 ParNew 并行回收器（年轻代） Serial 的多线程形式 -XX:+UseParNewGC（新生代使用并行收集器，老年代使用串行回收收集器） 或者 -XX:+UseConcMarkSweepGC (新生代使用并行收集器，老年代使用 CMS) Parallel Scavenge 基于吞吐量的并行回收器（年轻代） 多线程的回收器，高吞吐量（= 程序运行时间 / (程序运行时间+回收器运行时间)），可以高效率的利用 CPU 时间，尽快完成程序的运算任务，适合后台应用等对响应时间要求不高的场景 有一个自适应条件参数（-XX:+UseAdaptiveSizePolicy），当这个参数打开后，无需手动指定新生代大小（-Xmn），Eden 和Survivor 比例（-XX:SurvivorRatio）等参数，虚拟机会动态调节这些参数来选择最适合的停顿时间（-XX:MaxGCPauseMillis）或吞吐量（ -XX:GCTimeRatio） Parallel Scavenge 是 Server 级别多 CPU 机器上的默认 GC 方式，也可以通过 -XX:+UseParallelGC 来指定，并且可以采用 -XX:ParallelGCThread 来指定线程数 Parallel Scavenge 对应的老年代收集器只有 Serial Old 和 Parallel Old。不能与 CMS 搭配使用的原因是，其使用的框架不同，并不是技术原因 Parallel Old 基于吞吐量的并行回收器（老年代） 使用多线程和标记整理算法 与 Parallen Scavenge 相似，只不过是运用于老年代 CMS 关注暂停时间的回收器 （老年代） 基于标记清除算法实现，关注 GC 的暂停时间，在注重响应时间的应用上使用 三色标记法 在说 CMS 具体步骤前，先看下 CMS 使用的垃圾标记算法：三色标记法 将堆中对象分为 3 个集合：白色、灰色和黑色 白色集合：需要被回收的对象 黑色集合：没有引用白色集合中的对象，且从 GC ROOT 可达。该集合的对象是不会被回收的 灰色集合：从根可达但是还没有扫描完其引用的所有对象，该集合的对象不会被回收，且当其引用的白色对象全部被扫描后，会将其加入到黑色集合中 一般来说，会将被 GC ROOT 直接引用到的对象初始化到灰色集合，其余所有对象初始化到白色集合，然后开始执行算法： 将一个灰色对象加入到黑色集合 将其引用到的所有白色对象加入到灰色集合 重复上述两步，直到灰色集合为空 该算法保证从 GC ROOT 出发，所有没有被引用到的对象都在白色集合中，所以最后白色集合中的所有对象就是要回收的对象 CMS 回收过程 分为 4 个过程，初始标记，并发标记，重新标记，并发清理 初始标记 从 GC ROOT 出发，找到所有被 GC ROOT 直接引用的节点 此过程需要 STW (Stop The World) 并发标记 以上一步骤的节点为根节点，并发的遍历所有节点 同时会开启 Write Barrier 如果在此过程中存在黑色对象新增对白色对象的引用，则会通过 Write Barrier 记录下来 如下图，在 GC 过程中，用三色标记法遍历到 A 这个对象（图 1），将A引用到的BCD标记为灰色 之后，在应用程序线程中创建了一个对象 E，A 引用了它（ 图 2 这个阶段 GC 是并发标记的） 然后将 A 标记为黑色（图 3） 在 GC 扫描结束后，E 这个对象因为是白色的，所以将被回收掉 这显然是不能接受的，并发垃圾回收器的底线是允许一部分垃圾暂时不回收（见下面的浮动垃圾），但绝不允许从根可达的存活对象被当作垃圾处理掉 重新标记 因为并发标记的过程中可能有引用关系的变化，所以该阶段需要 STW 以 GC ROOT，Write Barrier 中记录的对象为根节点，重新遍历 这里为什么还需要再遍历 GC ROOT ？ 因为 Write Barrier 是作用在堆上的，无法感知到 GC ROOT 上引用关系的变更 并发清理： 并发的清理所有垃圾对象 CMS 通过将步骤拆分，实现了降低 STW 时间的目的。但 CMS 也会有以下问题： 浮动垃圾，在并发标记的过程中（及之后阶段），可能存在原来被引用的对象变成无人引用了 在这次 GC 不会对其清理 CPU 敏感，因为用户程序是和 GC 线程同时运行的，所以会导致 GC 的过程中程序运行变慢，GC 运行时间增长，吞吐量降低 默认回收线程是（CPU 数量 + 3）/ 4，也就是 CPU 不足 4 个时，会有一半的 CPU 资源给 GC 线程 空间碎片，标记清除算法共有的问题。当碎片过多时，为大对象分配内存空间就会很麻烦 有时候就是老年代空间有大量空间剩余，但没有连续的大空间来分配当前对象，不得不提前触发 Full GC CMS 提供一个参数（-XX:+UseCMSCompactAtFullCollection），在 Full GC 发生时开启内存合并整理 这个过程是 STW 的 同时还可以通过参数（-XX:CMSFullGCsBeforeCom-paction）设置执行多少次不压缩的 Full GC 后，进行一次压缩的 需要更大的内存空间，因为是同时运行的 GC 和用户程序，所以不能像其他老年代收集器一样，等老年代满了再触发 GC，而是要预留一定的空间 CMS 可以配置当老年代使用率到达某个阈值时（ -XX:CMSInitiatingOccupancyFraction=80 ），开始 CMS GC 在 Old GC 运行的过程中，可能有大量对象从年轻代晋升，而出现老年代存放不下的问题（因为这个时候垃圾还没被回收掉），该问题叫 Concurrent Model Failure, 这时候会启用 Serial Old 收集器，重新回收整个老年代 Concurrent Model Failure 一般伴随着 ParNew promotion failed（晋升担保失败）, 解决这个问题的办法就是可以让 CMS 在进行一定次数的 Full GC（标记清除）的时候进行一次标记整理算法，或者降低触发 CMS GC 的阈值 Java 引用类型原理 Java 中主要有 4 种引用类型：强引用、软引用、弱引用、虚引用 序号 引用类型 取得目标对象方式 垃圾回收条件 是否可能内存泄漏 1 强引用 直接调用 不回收 可能 2 软引用 通过 get() 方法 视内存情况回收 不可能 3 弱引用 通过 get() 方法 永远回收 不可能 4 虚引用 无法取得 不回收 可能 强引用就是我们经常使用的 Object a = new Object(); 这样的形式，在 Java 中并没有对应的 Reference 类 其他三种引用类型都继承于 Reference 类 Reference相关字段1234567891011121314151617181920212223public abstract class Reference&lt;T&gt; &#123; // 引用的对象 private T referent; // 回收队列，由使用者在 Reference 的构造函数中指定, 开发者可以通过从 ReferenceQueue 中 poll 感知到对象被回收的事件 volatile ReferenceQueue&lt;? super T&gt; queue; // 当该引用被加入到 queue 中的时候，该字段被设置为 queue 中的下一个元素，以形成链表结构 volatile Reference next; // 在 GC 时，JVM 底层会维护一个叫 DiscoveredList 的链表，存放的是 Reference 对象，discovered 字段指向的就是链表中的下一个元素，由 JVM 设置 transient private Reference&lt;T&gt; discovered; // 进行线程同步的锁对象 static private class Lock &#123; &#125; private static Lock lock = new Lock(); // 等待加入 queue 的 Reference 对象，在 GC 时由 JVM 设置，会有一个 Java 层的线程 (ReferenceHandler) 源源不断的从pending 中提取元素加入到 queue private static Reference&lt;Object&gt; pending = null; ......&#125; 生命周期 主要分为 Native 层和 Java 层两个部分 Native 层在 GC 时将需要被回收的 Reference 对象加入到 DiscoveredList 中，然后将 DiscoveredList 的元素移动到 PendingList 中, PendingList 的队首就是 Reference 类中的 pending 对象 Java 层代码 123456789101112131415161718192021222324252627282930313233343536373839404142private static class ReferenceHandler extends Thread &#123; ... public void run() &#123; while (true) &#123; tryHandlePending(true); &#125; &#125; &#125; static boolean tryHandlePending(boolean waitForNotify) &#123; Reference&lt;Object&gt; r; Cleaner c; try &#123; synchronized (lock) &#123; if (pending != null) &#123; r = pending; // 如果是 Cleaner 对象，则记录下来，下面做特殊处理 c = r instanceof Cleaner ? (Cleaner) r : null; // 指向 PendingList 的下一个对象 pending = r.discovered; r.discovered = null; &#125; else &#123; // 如果 pending 为 null 就先等待，当有对象加入到 PendingList 中时，JVM 会执行 notify if (waitForNotify) &#123; lock.wait(); &#125; // retry if waited return waitForNotify; &#125; &#125; &#125; ... // 如果是 CLeaner 对象，则调用 clean 方法进行资源回收 if (c != null) &#123; c.clean(); return true; &#125; // 将 Reference 加入到 ReferenceQueue ReferenceQueue&lt;? super Object&gt; q = r.queue; if (q != ReferenceQueue.NULL) q.enqueue(r); return true; &#125; 对于 Cleaner 类型（继承自虚引用）的对象会有额外的处理 在其指向的对象被回收时，会调用 clean 方法，该方法主要是用来做对应的资源回收 在堆外内存 DirectByteBuffer 中就是用 Cleaner 进行堆外内存的回收，这也是虚引用在 Java 中的典型应用 SoftReference123456789101112131415161718192021222324public class SoftReference&lt;T&gt; extends Reference&lt;T&gt; &#123; static private long clock; private long timestamp; public SoftReference(T referent) &#123; super(referent); this.timestamp = clock; &#125; public SoftReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); this.timestamp = clock; &#125; public T get() &#123; T o = super.get(); if (o != null &amp;&amp; this.timestamp != clock) this.timestamp = clock; return o; &#125;&#125; 软引用的实现多了两个字段：clock 和 timestamp clock 是个静态变量，每次 GC 时都会将该字段设置成当前时间 timestamp 字段则会在每次调用 get 方法时将其赋值为 clock（如果不相等且对象没被回收） 通过 JVM 源码查看这两个字段的作用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455size_tReferenceProcessor::process_discovered_reflist( DiscoveredList refs_lists[], ReferencePolicy* policy, bool clear_referent, BoolObjectClosure* is_alive, OopClosure* keep_alive, VoidClosure* complete_gc, AbstractRefProcTaskExecutor* task_executor)&#123; ... // refs_lists 就是前面提到的 DiscoveredList // 对于 DiscoveredList 的处理分为几个阶段，SoftReference 的处理就在第一阶段 ... for (uint i = 0; i &lt; _max_num_q; i++) &#123; process_phase1(refs_lists[i], policy, is_alive, keep_alive, complete_gc); &#125; ...&#125;// 该阶段的主要目的就是当内存足够时，将对应的 SoftReference 从 refs_list 中移除voidReferenceProcessor::process_phase1(DiscoveredList&amp; refs_list, ReferencePolicy* policy, BoolObjectClosure* is_alive, OopClosure* keep_alive, VoidClosure* complete_gc) &#123; DiscoveredListIterator iter(refs_list, keep_alive, is_alive); // Decide which softly reachable refs should be kept alive. while (iter.has_next()) &#123; iter.load_ptrs(DEBUG_ONLY(!discovery_is_atomic() /* allow_null_referent */)); // 判断引用的对象是否存活 bool referent_is_dead = (iter.referent() != NULL) &amp;&amp; !iter.is_referent_alive(); // 如果引用的对象已经不存活了，则会去调用对应的 ReferencePolicy 判断该对象是不时要被回收 if (referent_is_dead &amp;&amp; !policy-&gt;should_clear_reference(iter.obj(), _soft_ref_timestamp_clock)) &#123; if (TraceReferenceGC) &#123; gclog_or_tty-&gt;print_cr("Dropping reference (" INTPTR_FORMAT ": %s" ") by policy", (void *)iter.obj(), iter.obj()-&gt;klass()-&gt;internal_name()); &#125; // Remove Reference object from list iter.remove(); // Make the Reference object active again iter.make_active(); // keep the referent around iter.make_referent_alive(); iter.move_to_next(); &#125; else &#123; iter.next(); &#125; &#125; ...&#125; refs_lists 中存放了本次 GC 发现的某种引用类型（虚引用、软引用、弱引用等），而 process_discovered_reflist 方法的作用就是将不需要被回收的对象从 refs_lists 移除掉，refs_lists 最后剩下的元素全是需要被回收的元素，最后会将其第一个元素赋值给上文提到过的 Reference.java#pending 字段 ReferencePolicy 一共有4种实现 NeverClearPolicy，永远返回 false, 代表永远不回收 SoftReference，在 JVM 中该类没有被使用 AlwaysClearPolicy，永远返回 true，在 referenceProcessor.hpp#setup 方法中中可以设置 policy 为 AlwaysClearPolicy LRUCurrentHeapPolicy，LRUMaxHeapPolicy should_clear_reference 方法完全相同 123456789101112bool LRUMaxHeapPolicy::should_clear_reference(oop p, jlong timestamp_clock) &#123; jlong interval = timestamp_clock - java_lang_ref_SoftReference::timestamp(p); assert(interval &gt;= 0, "Sanity check"); // The interval will be zero if the ref was accessed since the last scavenge/gc. if(interval &lt;= _max_interval) &#123; return false; &#125; return true;&#125; timestamp_clock 就是 SoftReference 的静态字段 clock java_lang_ref_SoftReference::timestamp(p) 对应是字段 timestamp 如果上次 GC 后有调用 SoftReference#get，interval 值为 0，否则为若干次 GC 之间的时间差 _max_interval 则代表了一个临界值，它的值在 LRUCurrentHeapPolicy 和 LRUMaxHeapPolicy 两种策略中有差异 12345678910111213void LRUCurrentHeapPolicy::setup() &#123; _max_interval = (Universe::get_heap_free_at_last_gc() / M) * SoftRefLRUPolicyMSPerMB; assert(_max_interval &gt;= 0,"Sanity check");&#125;void LRUMaxHeapPolicy::setup() &#123; size_t max_heap = MaxHeapSize; max_heap -= Universe::get_heap_used_at_last_gc(); max_heap /= M; _max_interval = max_heap * SoftRefLRUPolicyMSPerMB; assert(_max_interval &gt;= 0,"Sanity check");&#125; 其中 SoftRefLRUPolicyMSPerMB 默认为 1000 前者的计算方法和上次 GC 后可用堆大小有关 后者计算方法和（堆大小 - 上次 GC 时堆使用大小）有关 所以 SoftReference 什么时候被回收和使用的策略（默认应该是 LRUCurrentHeapPolicy），堆可用大小，该 SoftReference 上一次调用 get 方法的时间都有关系 WeakReference1234567891011public class WeakReference&lt;T&gt; extends Reference&lt;T&gt; &#123; public WeakReference(T referent) &#123; super(referent); &#125; public WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); &#125;&#125; WeakReference 在 Java 层只是继承了 Reference，没有做任何的改动 那 referent 字段是什么时候被置为 null 的呢？我们再看下上文提到过的 process_discovered_reflist 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778size_tReferenceProcessor::process_discovered_reflist( DiscoveredList refs_lists[], ReferencePolicy* policy, bool clear_referent, BoolObjectClosure* is_alive, OopClosure* keep_alive, VoidClosure* complete_gc, AbstractRefProcTaskExecutor* task_executor)&#123; ... // Phase 1: 将所有不存活但是还不能被回收的软引用从 refs_lists 中移除（只有 refs_lists 为软引用的时候，这里 policy 才不为 null） if (policy != NULL) &#123; if (mt_processing) &#123; RefProcPhase1Task phase1(*this, refs_lists, policy, true /*marks_oops_alive*/); task_executor-&gt;execute(phase1); &#125; else &#123; for (uint i = 0; i &lt; _max_num_q; i++) &#123; process_phase1(refs_lists[i], policy, is_alive, keep_alive, complete_gc); &#125; &#125; &#125; else &#123; // policy == NULL assert(refs_lists != _discoveredSoftRefs, "Policy must be specified for soft references."); &#125; // Phase 2: // 移除所有指向对象还存活的引用 if (mt_processing) &#123; RefProcPhase2Task phase2(*this, refs_lists, !discovery_is_atomic() /*marks_oops_alive*/); task_executor-&gt;execute(phase2); &#125; else &#123; for (uint i = 0; i &lt; _max_num_q; i++) &#123; process_phase2(refs_lists[i], is_alive, keep_alive, complete_gc); &#125; &#125; // Phase 3: // 根据 clear_referent 的值决定是否将不存活对象回收 if (mt_processing) &#123; RefProcPhase3Task phase3(*this, refs_lists, clear_referent, true /*marks_oops_alive*/); task_executor-&gt;execute(phase3); &#125; else &#123; for (uint i = 0; i &lt; _max_num_q; i++) &#123; process_phase3(refs_lists[i], clear_referent, is_alive, keep_alive, complete_gc); &#125; &#125; return total_list_count;&#125;voidReferenceProcessor::process_phase3(DiscoveredList&amp; refs_list, bool clear_referent, BoolObjectClosure* is_alive, OopClosure* keep_alive, VoidClosure* complete_gc) &#123; ResourceMark rm; DiscoveredListIterator iter(refs_list, keep_alive, is_alive); while (iter.has_next()) &#123; iter.update_discovered(); iter.load_ptrs(DEBUG_ONLY(false /* allow_null_referent */)); if (clear_referent) &#123; // NULL out referent pointer // 将 Reference 的 referent 字段置为 null，之后会被 GC 回收 iter.clear_referent(); &#125; else &#123; // keep the referent around // 标记引用的对象为存活，该对象在这次 GC 将不会被回收 iter.make_referent_alive(); &#125; ... &#125; ...&#125; 不管是弱引用还是其他引用类型，将字段 referent 置 null 的操作都发生在 process_phase3 中，而具体行为是由 clear_referent 的值决定的。而 clear_referent 的值则和引用类型相关 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ReferenceProcessorStats ReferenceProcessor::process_discovered_references( BoolObjectClosure* is_alive, OopClosure* keep_alive, VoidClosure* complete_gc, AbstractRefProcTaskExecutor* task_executor, GCTimer* gc_timer) &#123; NOT_PRODUCT(verify_ok_to_handle_reflists()); ... // process_discovered_reflist 方法的第 3 个字段就是 clear_referent // Soft references size_t soft_count = 0; &#123; GCTraceTime tt("SoftReference", trace_time, false, gc_timer); soft_count = process_discovered_reflist(_discoveredSoftRefs, _current_soft_ref_policy, true, is_alive, keep_alive, complete_gc, task_executor); &#125; update_soft_ref_master_clock(); // Weak references size_t weak_count = 0; &#123; GCTraceTime tt("WeakReference", trace_time, false, gc_timer); weak_count = process_discovered_reflist(_discoveredWeakRefs, NULL, true, is_alive, keep_alive, complete_gc, task_executor); &#125; // Final references size_t final_count = 0; &#123; GCTraceTime tt("FinalReference", trace_time, false, gc_timer); final_count = process_discovered_reflist(_discoveredFinalRefs, NULL, false, is_alive, keep_alive, complete_gc, task_executor); &#125; // Phantom references size_t phantom_count = 0; &#123; GCTraceTime tt("PhantomReference", trace_time, false, gc_timer); phantom_count = process_discovered_reflist(_discoveredPhantomRefs, NULL, false, is_alive, keep_alive, complete_gc, task_executor); &#125; ...&#125; 可以看到，对于 Soft references 和 Weak references clear_referent 字段传入的都是 true 对象不可达后，引用字段就会被置为 null，然后对象就会被回收 对于软引用来说，如果内存足够的话，在 Phase 1 相关的引用就会从 refs_list 中被移除，到 Phase 3 时 refs_list 为空集合 对于 Final references 和 Phantom references，clear_referent 字段传入的是 false 也就意味着被这两种引用类型引用的对象，如果没有其他额外处理，只要 Reference 对象还存活，那引用的对象是不会被回收的 Final references 和对象是否重写了 finalize 方法有关, 不在本文分析范围之内 PhantomReference1234567891011public class PhantomReference&lt;T&gt; extends Reference&lt;T&gt; &#123; public T get() &#123; return null; &#125; public PhantomReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); &#125;&#125; 可以看到虚引用的 get 方法永远返回 null，我们看个 demo 1234567891011121314151617 public static void demo() throws InterruptedException &#123; Object obj = new Object(); ReferenceQueue&lt;Object&gt; refQueue = new ReferenceQueue&lt;&gt;(); PhantomReference&lt;Object&gt; phanRef = new PhantomReference&lt;&gt;(obj, refQueue); Object objg = phanRef.get(); // 这里拿到的是 null System.out.println(objg); // 让 obj 变成垃圾 obj = null; System.gc(); Thread.sleep(3000); // gc 后会将 phanRef 加入到 refQueue 中 Reference&lt;? extends Object&gt; phanRefP = refQueue.remove(); // 这里输出 true System.out.println(phanRefP == phanRef);&#125; 从以上代码中可以看到，虚引用能够在指向对象不可达时得到一个’通知’（其实所有继承 References 的类都有这个功能） 需要注意的是 GC 完成后，phanRef.referent 依然指向之前创建 Object，也就是说 Object 对象一直没被回收 造成这一现象的原因在前面也已经说了：clear_referent 字段传入的是 false 对于虚引用来说，从 refQueue.remove(); 得到引用对象后，可以调用 clear 方法强行解除引用和对象之间的关系，使得对象下次可以 GC 时可以被回收掉 总结 我们经常在网上看到软引用的介绍是：在内存不足的时候才会回收，那内存不足是怎么定义的？为什么才叫内存不足？ 软引用会在内存不足时被回收，内存不足的定义和该引用对象 get 的时间以及当前堆可用内存大小都有关系，计算公式在上文中也已经给出 网上对于虚引用的介绍是：形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。主要用来跟踪对象被垃圾回收器回收的活动。真的是这样吗？ 严格的说，虚引用是会影响对象生命周期的，如果不做任何处理，只要虚引用不被回收，那其引用的对象永远不会被回收 所以一般来说，从 ReferenceQueue 中获得 PhantomReference 对象后，如果 PhantomReference 对象不会被回收的话（比如被其他 GC ROOT 可达的对象引用），需要调用 clear 方法解除 PhantomReference 和其引用对象的引用关系 各个引用的使用场景 软引用 用于缓存，创建的对象放进缓存中，当内存不足时，JVM 就会回收早先创建的对象 弱引用 WeakHashMap 中的 key 使用的是弱引用 Threadlocal 中 ThreadLocalMap 的 Entry 继承自弱引用, 避免 Threadlocal 无法回收 虚引用 DirectByteBuffer 中使用虚引用的子类 Cleaner.java 来实现堆外内存的回收 关于 JVM 堆外内存 Java 中的对象都是在 JVM 堆中分配的，其好处在于开发者不用关心对象的回收 但有利必有弊，堆内内存主要有两个缺点 GC 是有成本的，堆中的对象数量越多，GC 的开销也会越大 使用堆内内存进行文件、网络的 IO 时，JVM 会使用堆外内存做一次额外的中转，也就是会多一次内存拷贝 和堆内内存相对应，堆外内存就是把内存对象分配在 Java 虚拟机堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机），这样做的结果就是能够在一定程度上减少垃圾回收对应用程序造成的影响 堆外内存的实现 (DirectByteBuffer) Java 中分配堆外内存的方式有两种 一是通过 ByteBuffer.java#allocateDirect 得到以一个 DirectByteBuffer 对象 二是直接调用 Unsafe.java#allocateMemory 分配内存，但 Unsafe 只能在 JDK 的代码中调用，一般不会直接使用该方法分配内存 其中 DirectByteBuffer 也是用 Unsafe 去实现内存分配的，对堆内存的分配、读写、回收都做了封装 堆外内存的分配与回收123456789101112131415161718192021222324252627282930313233343536373839// ByteBuffer.java public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125;// DirectByteBuffer.java DirectByteBuffer(int cap) &#123; // package-private // 主要是调用 ByteBuffer 的构造方法，为字段赋值 super(-1, 0, cap, cap); // 如果是按页对齐，则还要加一个 Page 的大小；我们分析只 pa 为 false 的情况就好了 boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); // 预分配内存 Bits.reserveMemory(size, cap); long base = 0; try &#123; // 分配内存 base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; // 将分配的内存的所有值赋值为 0 unsafe.setMemory(base, size, (byte) 0); // 为 address 赋值，address 就是分配内存的起始地址，之后的数据读写都是以它作为基准 if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; // pa 为 false 的情况，address == base address = base; &#125; // 创建一个 Cleaner，将 this 和一个 Deallocator 对象传进去 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; DirectByteBuffer 构造方法分为几个步骤 预分配内存 分配内存 将刚分配的内存空间初始化为 0 创建一个 Cleaner 对象，Cleaner 对象的作用是当 DirectByteBuffer 对象被回收时，释放其对应的堆外内存 当 GC 发现 DirectByteBuffer 对象变成垃圾时，会调用 Cleaner#clean 回收对应的堆外内存，一定程度上防止了内存泄露 当然也可以手动的调用该方法，对堆外内存进行提前回收 Cleaner 的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Cleaner extends PhantomReference&lt;Object&gt; &#123; ... private Cleaner(Object referent, Runnable thunk) &#123; super(referent, dummyQueue); this.thunk = thunk; &#125; public void clean() &#123; if (remove(this)) &#123; try &#123; // thunk 是一个 Deallocator 对象 this.thunk.run(); &#125; catch (final Throwable var2) &#123; ... &#125; &#125; &#125;&#125;private static class Deallocator implements Runnable &#123; private static Unsafe unsafe = Unsafe.getUnsafe(); private long address; private long size; private int capacity; private Deallocator(long address, long size, int capacity) &#123; assert (address != 0); this.address = address; this.size = size; this.capacity = capacity; &#125; public void run() &#123; if (address == 0) &#123; // Paranoia return; &#125; // 调用 unsafe 方法回收堆外内存 unsafe.freeMemory(address); address = 0; Bits.unreserveMemory(size, capacity); &#125; &#125; 当字段 referent (也就是 DirectByteBuffer 对象)被回收时，会调用到 Cleaner#clean 方法，最终会调用到 Deallocator#run 进行堆外内存的回收 Cleaner 是虚引用在 JDK 中的一个典型应用场景 预分配内存1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374static void reserveMemory(long size, int cap) &#123; // maxMemory 代表最大堆外内存，也就是 -XX:MaxDirectMemorySize 指定的值 if (!memoryLimitSet &amp;&amp; VM.isBooted()) &#123; maxMemory = VM.maxDirectMemory(); memoryLimitSet = true; &#125; // 1.如果堆外内存还有空间，则直接返回 if (tryReserveMemory(size, cap)) &#123; return; &#125; // 走到这里说明堆外内存剩余空间已经不足了 final JavaLangRefAccess jlra = SharedSecrets.getJavaLangRefAccess(); // 2.堆外内存进行回收，最终会调用到 Cleaner#clean 的方法。如果目前没有堆外内存可以回收则跳过该循环 while (jlra.tryHandlePendingReference()) &#123; // 如果空闲的内存足够了，则 return if (tryReserveMemory(size, cap)) &#123; return; &#125; &#125; // 3.主动触发一次 GC，目的是触发老年代 GC System.gc(); // 4.重复上面的过程 boolean interrupted = false; try &#123; long sleepTime = 1; int sleeps = 0; while (true) &#123; if (tryReserveMemory(size, cap)) &#123; return; &#125; if (sleeps &gt;= MAX_SLEEPS) &#123; break; &#125; if (!jlra.tryHandlePendingReference()) &#123; try &#123; Thread.sleep(sleepTime); sleepTime &lt;&lt;= 1; sleeps++; &#125; catch (InterruptedException e) &#123; interrupted = true; &#125; &#125; &#125; // 5.超出指定的次数后，还是没有足够内存，则抛异常 throw new OutOfMemoryError("Direct buffer memory"); &#125; finally &#123; if (interrupted) &#123; // don't swallow interrupts Thread.currentThread().interrupt(); &#125; &#125; &#125; private static boolean tryReserveMemory(long size, int cap) &#123; // size 和 cap 主要是 page 对齐的区别，这里我们把这两个值看作是相等的 long totalCap; // totalCapacity 代表通过 DirectByteBuffer 分配的堆外内存的大小 // 当已分配大小 &lt;= 还剩下的堆外内存大小 时，更新 totalCapacity 的值返回 true while (cap &lt;= maxMemory - (totalCap = totalCapacity.get())) &#123; if (totalCapacity.compareAndSet(totalCap, totalCap + cap)) &#123; reservedMemory.addAndGet(size); count.incrementAndGet(); return true; &#125; &#125; // 堆外内存不足，返回 false return false; &#125; 在创建一个新的 DirecByteBuffer 时，会先确认有没有足够的内存，如果没有的话，会通过一些手段回收一部分堆外内存，直到可用内存大于需要分配的内存。具体步骤如下： 如果可用堆外内存足够，则直接返回 调用 tryHandlePendingReference 方法回收已经变成垃圾的 DirectByteBuffer 对象对应的堆外内存，直到可用内存足够，或目前没有垃圾 DirectByteBuffer 对象 tryHandlePendingReference 最终调用到的是 Reference#tryHandlePending 方法 此方法在前面有介绍过, 对于 Cleaner 对象调用对应的 Cleaner#clean 方法进行回收 触发一次 Full GC, 其主要目的是为了防止冰山现象 一个 DirectByteBuffer 对象本身占用的内存很小，但是它可能引用了一块很大的堆外内存 如果 DirectByteBuffer 对象进入了老年代之后变成了垃圾，因为老年代 GC 一直没有触发，导致这块堆外内存也一直没有被回收 需要注意的是如果使用参数 -XX:+DisableExplicitGC，那 System.gc(); 是无效的 重复 1，2 步骤的流程，直到可用内存大于需要分配的内存 如果超出指定次数还没有回收到足够内存，则 OOM 堆外内存的读写123456789101112131415161718192021222324public ByteBuffer put(byte x) &#123; unsafe.putByte(ix(nextPutIndex()), ((x))); return this;&#125;final int nextPutIndex() &#123; if (position &gt;= limit) throw new BufferOverflowException(); return position++;&#125;private long ix(int i) &#123; return address + ((long)i &lt;&lt; 0);&#125;public byte get() &#123; return ((unsafe.getByte(ix(nextGetIndex()))));&#125;final int nextGetIndex() &#123; // package-private if (position &gt;= limit) throw new BufferUnderflowException(); return position++;&#125; 读写的逻辑比较简单，address 就是构造方法中分配的 native 内存的起始地址 Unsafe 的 putByte/getByte 都是 native 方法，就是写入值到某个地址/获取某个地址的值 堆外内存的使用场景 适合长期存在或能复用的场景, 堆外内存分配回收也是有开销的，所以适合长期存在的对象 适合注重稳定的场景, 堆外内存能有效避免因 GC 导致的暂停问题 堆外内存能有效避免因GC导致的暂停问题。 适合简单对象的存储, 因为堆外内存只能存储字节数组，所以对于复杂的 DTO 对象，每次存储/读取都需要序列化/反序列化 适合注重 IO 效率的场景, 用堆外内存读写文件性能更好 文件IO 堆外内存 IO 为什么有更好的性能 BIO BIO 的文件写 FileOutputStream#write 最终会调用到 native 层的 io_util.c#writeBytes 方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455voidwriteBytes(JNIEnv *env, jobject this, jbyteArray bytes, jint off, jint len, jboolean append, jfieldID fid)&#123; jint n; char stackBuf[BUF_SIZE]; char *buf = NULL; FD fd; ... // 如果写入长度为 0，直接返回 0 if (len == 0) &#123; return; &#125; else if (len &gt; BUF_SIZE) &#123; // 如果写入长度大于 BUF_SIZE（8192），无法使用栈空间 buffer // 需要调用 malloc 在堆空间申请 buffer buf = malloc(len); if (buf == NULL) &#123; JNU_ThrowOutOfMemoryError(env, NULL); return; &#125; &#125; else &#123; buf = stackBuf; &#125; // 复制 Java 传入的 byte 数组数据到 C 空间的 buffer 中 (*env)-&gt;GetByteArrayRegion(env, bytes, off, len, (jbyte *)buf); if (!(*env)-&gt;ExceptionOccurred(env)) &#123; off = 0; while (len &gt; 0) &#123; fd = GET_FD(this, fid); if (fd == -1) &#123; JNU_ThrowIOException(env, "Stream Closed"); break; &#125; // 写入到文件，这里传递的数组是我们新创建的 buf if (append == JNI_TRUE) &#123; n = (jint)IO_Append(fd, buf+off, len); &#125; else &#123; n = (jint)IO_Write(fd, buf+off, len); &#125; if (n == JVM_IO_ERR) &#123; JNU_ThrowIOExceptionWithLastError(env, "Write error"); break; &#125; else if (n == JVM_IO_INTR) &#123; JNU_ThrowByName(env, "java/io/InterruptedIOException", NULL); break; &#125; off += n; len -= n; &#125; &#125;&#125; GetByteArrayRegion 其实就是对数组进行了一份拷贝，该函数的实现在 jni.cpp 宏定义中 12345678910111213// jni.cppJNI_ENTRY(void, \jni_Get##Result##ArrayRegion(JNIEnv *env, ElementType##Array array, jsize start, \ jsize len, ElementType *buf)) \ ... int sc = TypeArrayKlass::cast(src-&gt;klass())-&gt;log2_element_size(); \ // 内存拷贝 memcpy((u_char*) buf, \ (u_char*) src-&gt;Tag##_at_addr(start), \ len &lt;&lt; sc); \... &#125; \JNI_END 传统的 BIO，在 native 层真正写文件前，会在堆外内存（c 分配的内存）中对字节数组拷贝一份，之后真正 IO 时，使用的是堆外的数组, 这样做的原因是: 底层通过 write、read、pwrite，pread 函数进行系统调用时，需要传入 buffer 的起始地址和 buffer count 作为参数 如果使用 Java Heap 的话，我们知道 JVM 中 buffer 往往以 byte[] 的形式存在，这是一个特殊的对象，由于 Java Heap GC 的存在，这里对象在堆中的位置往往会发生移动，移动后我们传入系统函数的地址参数就不是真正的 buffer 地址了，这样的话无论读写都会发生出错。而 C Heap 仅仅受 Full GC 的影响，相对来说地址稳定 JVM 规范中没有要求 Java 的 byte[] 必须是连续的内存空间，它往往受宿主语言的类型约束 而 C Heap 中我们分配的虚拟地址空间是可以连续的，而上述的系统调用要求我们使用连续的地址空间作为 buffer NIO NIO 的文件写最终会调用到 IOUtil#write 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd, Object lock) throws IOException &#123; // 如果是堆外内存，则直接写 if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd, lock); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); // 创建一块堆外内存，并将数据赋值到堆外内存中去 ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try &#123; bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd, lock); if (n &gt; 0) &#123; // now update src src.position(pos + n); &#125; return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125; &#125; /** * 分配一片堆外内存 */ static ByteBuffer getTemporaryDirectBuffer(int size) &#123; BufferCache cache = bufferCache.get(); ByteBuffer buf = cache.get(size); if (buf != null) &#123; return buf; &#125; else &#123; // No suitable buffer in the cache so we need to allocate a new // one. To avoid the cache growing then we remove the first // buffer from the cache and free it. if (!cache.isEmpty()) &#123; buf = cache.removeFirst(); free(buf); &#125; return ByteBuffer.allocateDirect(size); &#125; &#125; NIO 的文件写，对于堆内内存来说也是会有一次额外的内存拷贝的 参考 https://github.com/farmerjohngit/myblog/issues/3 https://zhuanlan.zhihu.com/p/102758471 https://my.oschina.net/dust8080/blog/3094511 https://github.com/farmerjohngit/myblog/issues/10]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java 线程与线程池]]></title>
    <url>%2F2020%2F05%2F20%2FJava-%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[Java 线程与线程池线程的状态 NEW, 新建状态, 线程被创建出来, 但尚未启动时的线程状态 RUNNABLE, 就绪状态, 表示可以运行的线程状态, 它可能正在运行, 或者是在排队等待操作系统给它分配 CPU 资源 BLOCKED, 阻塞等待锁的线程状态, 表示处于阻塞状态的线程正在等待监视器锁, 比如等待执行 synchronized 代码块或者使用 synchronized 标记的方法 WAITING, 等待状态, 一个处于等待状态的线程正在等待另一个线程执行某个特定的动作, 比如, 一个线程调用了 Object.wait() 方法, 那它就在等待另一个线程调用 Object.notify() 或 Object.notifyAll() 方法 TIMED_WAITING, 计时等待状态, 和 WAITING 类似, 它只是多了超时时间, 比如调用了有超时时间设置的方法 Object.wait(long timeout) 和 Thread.join(long timeout) 等这些方法时, 它才会进入此状态 TERMINATED, 终止状态, 表示线程已经执行完成 关于 Object.wait/notify相关代码12345678910111213141516171819202122232425262728293031323334353637383940public class WaitNotifyCase &#123; public static void main(String[] args) &#123; final Object lock = new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("thread A is waiting to get lock"); synchronized (lock) &#123; try &#123; System.out.println("thread A get lock"); TimeUnit.SECONDS.sleep(1); System.out.println("thread A do wait method"); lock.wait(); System.out.println("wait end"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("thread B is waiting to get lock"); synchronized (lock) &#123; System.out.println("thread B get lock"); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.notify(); System.out.println("thread B do notify method"); &#125; &#125; &#125;).start(); &#125;&#125; 执行结果1234567thread A is waiting to get lockthread A get lockthread B is waiting to get lockthread A do wait methodthread B get lockthread B do notify methodwait end 疑问 进入 wait/notify 方法之前, 为什么要获取 synchronized 锁？ 线程 A 获取了 synchronized 锁, 执行 wait 方法并挂起, 线程 B 又如何再次获取锁？ 分析 synchronized 代码块通过 javap 生成的字节码中包含 monitorenter 和 monitorexit 指令, 执行 monitorenter 指令可以获取对象的 monitor , 在 wait() 接口注释中有标明 The current thread must own this object&#39;s monitor , 所以通过 synchronized 该线程持有了对象的 monitor 的情况下才能调用对象的 wait() 方法 wait() 接口注释中还提到调用 wait() 后该线程会释放持有的 monitor 进入等待状态直到被唤醒, 被唤醒的线程还要等到能重新持有 monitor 才会继续执行 线程状态变化: 调用 wait(): RUNNABLE -&gt; WAITING 调用 notify: WAITING -&gt; BLOCKED -&gt; RUNNABLE WAITING -&gt; RUNNABLE 具体看 JVM 实现和策略配置 深入: 什么是 monitor 在 HotSpot 虚拟机中 (1.7 版本), monitor 采用 ObjectMonitor 实现 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; // 用来记录该线程获取锁的次数 _waiters = 0, _recursions = 0; // 锁的重入次数 _object = NULL; // 对应的对象 _owner = NULL; // 指向持有 ObjectMonitor 对象的线程 _WaitSet = NULL; // 处于 WAITING 状态的线程, 会被加入到 _WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; // 竞争锁的线程都会先通过互斥同步或 CAS 操作进入 cxq, 队首的对象会进入到 EntryList 中, 进行 tryLock 操作 FreeNext = NULL ; _EntryList = NULL ; // 处于 BLOCKED 状态的线程, 会被加入到 _EntryList _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;&#125; 每个线程都有两个 ObjectMonitor 对象列表, 分别为 free 和 used 列表, 如果当前 free 列表为空, 线程将向全局 global ListLock 请求分配 ObjectMonitor ObjectMonitor 对象中有两个队列：_WaitSet 和 _EntryList, 用来保存 ObjectWaiter 对象列表；_owner 指向获得 ObjectMonitor 对象的线程 每个等待锁的线程都会被封装成 ObjectWaiter 对象 ObjectWaiter 对象是双向链表结构, 保存了_thread（当前线程）以及当前的状态 TState等数据 ObjectMonitor 获得锁是通过 void ATTR enter(TRAPS); 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465void ATTR ObjectMonitor::enter(TRAPS) &#123; Thread * const Self = THREAD ; void * cur ; // 通过 CAS 尝试把 monitor 的 _owner 设置为当前线程 cur = Atomic::cmpxchg_ptr (Self, &amp;_owner, NULL) ; // 获取锁失败 if (cur == NULL) &#123; assert (_recursions == 0 , "invariant") ; assert (_owner == Self, "invariant") ; // CONSIDER: set or assert OwnerIsThread == 1 return ; &#125; // 如果旧值和当前线程一样, 说明当前线程已经持有锁, 此次为重入, _recursions 自增即可 if (cur == Self) &#123; // TODO-FIXME: check for integer overflow! BUGID 6557169. _recursions ++ ; return ; &#125; // 如果当前线程是第一次进入该 monitor, 设置 _recursions 为 1, _owner 为当前线程 if (Self-&gt;is_lock_owned ((address)cur)) &#123; assert (_recursions == 0, "internal state error"); _recursions = 1 ; // Commute owner from a thread-specific on-stack BasicLockObject address to // a full-fledged "Thread *". _owner = Self ; OwnerIsThread = 1 ; return ; &#125; // 省略部分代码 ...... // 在调用系统的同步操作之前，先尝试自旋获得锁 if (Knob_SpinEarly &amp;&amp; TrySpin (Self) &gt; 0) &#123; ... //自旋的过程中获得了锁，则直接返回 Self-&gt;_Stalled = 0 ; return ; &#125; ...... // 通过自旋执行 ObjectMonitor::EnterI 方法等待锁的释放 for (;;) &#123; jt-&gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() // or java_suspend_self() // 将当前线程插入到 cxq 队列, 挂起等待重新尝试获取锁 EnterI (THREAD) ; if (!ExitSuspendEquivalent(jt)) break ; // We have acquired the contended monitor, but while we were // waiting another thread suspended us. We don't want to enter // the monitor while suspended because that would surprise the // thread that suspended us. // _recursions = 0 ; _succ = NULL ; exit (Self) ; jt-&gt;java_suspend_self(); &#125;&#125; ObjectMonitor 释放锁是通过 void ATTR exit(TRAPS); 方法 123456789101112131415161718192021222324252627282930313233void ATTR ObjectMonitor::exit(TRAPS) &#123; Thread * Self = THREAD ; // 如果当前线程不是 Monitor 的所有者 if (THREAD != _owner) &#123; if (THREAD-&gt;is_lock_owned((address) _owner)) &#123; // Transmute _owner from a BasicLock pointer to a Thread address. // We don't need to hold _mutex for this transition. // Non-null to Non-null is safe as long as all readers can // tolerate either flavor. assert (_recursions == 0, "invariant") ; _owner = THREAD ; _recursions = 0 ; OwnerIsThread = 1 ; &#125; else &#123; // NOTE: we need to handle unbalanced monitor enter/exit // in native code by throwing an exception. // TODO: Throw an IllegalMonitorStateException ? TEVENT (Exit - Throw IMSX) ; assert(false, "Non-balanced monitor enter/exit!"); if (false) &#123; THROW(vmSymbols::java_lang_IllegalMonitorStateException()); &#125; return; &#125; &#125; // 如果 _recursions 次数不为 0.自减 if (_recursions != 0) &#123; _recursions--; // this is simple recursive enter TEVENT (Inflated exit - recursive) ; return ; &#125; // 省略部分代码, 根据不同的策略（由 QMode 指定）, 从 _cxq 或 EntryList 中获取头节点, 通过 ObjectMonitor::ExitEpilog 方法唤醒该节点封装的线程, 唤醒操作最终由 unpark 完成。 lock.wait() 方法最终通过 ObjectMonitor 的 void wait(jlong millis, bool interruptable, TRAPS); 实现: 将当前线程封装成 ObjectWaiter 对象 node 通过 ObjectMonitor::AddWaiter 方法将 node 添加到 _WaitSet 列表中 通过 ObjectMonitor::exit 方法释放当前的 ObjectMonitor 对象, 这样其它竞争线程就可以获取该 ObjectMonitor 对象 最终底层的 park 方法会挂起线程 lock.notify() 方法最终通过 ObjectMonitor 的 void notify(TRAPS) 实现: 如果当前 _WaitSet 为空, 即没有正在等待的线程, 则直接返回 通过 ObjectMonitor::DequeueWaiter 方法, 获取 _WaitSet 列表中的第一个 ObjectWaiter节点 根据不同的策略, 将取出来的 ObjectWaiter 节点加入到 _EntryList 或则通过 Atomic::cmpxchg_ptr 指令进行自旋操作 _cxq 关于中断Java 中线程间是协作式，而非抢占式 调用一个线程的 interrupt() 方法中断一个线程，并不是强行关闭这个线程，只是通知线程停止，将线程的中断标志位置为 true，线程是否中断，由线程本身决定, 线程可以进行停止前的释放资源, 完成必要的处理任务 相关方法 在线程内可通过 isInterrupted() 判断终端并进行相应处理 另一个静态方法 Thread.interrupted() 返回当前线程的中断状态，同时重置中断标志位为 false 如何正确停止线程 中断会唤醒阻塞的线程, 并且大部分都会抛出 InterruptedException 如果方法里如果抛出中断异常 InterruptedException，则线程的中断标志位会被复位成 false 实际开发中的两种最佳实践 传递中断 对于底层的方法, 在方法的签名上标注异常 (throws InterruptedException) 抛出异常，而异常的真正处理，应该交给调用它的那个函数 因为标注了异常, 调用者必须对 InterruptedException 异常进行处理 恢复中断 在底层方法中 catch 处理异常 处理完成后手动调用 Thread.currentThread().interrupt() 恢复中断 相关问题1. BLOCKED（阻塞等待）和 WAITING（等待）有什么区别？ 状态形成的调用方法不同 BLOCKED 可以理解为当前线程还处于活跃状态, 只是在阻塞等待其他线程使用完某个锁资源 WAITING 则是因为自身调用了 Object.wait() 或着是 Thread.join() 又或者是 LockSupport.park() 而进入等待状态, 只能等待其他线程执行某个特定的动作才能被继续唤醒, 比如当线程因为调用了 Object.wait() 而进入 WAITING 状态之后, 则需要等待另一个线程执行 Object.notify() 或 Object.notifyAll() 才能被唤醒 2. start() 方法和 run() 方法有什么区别？ 12345678910111213141516171819202122public synchronized void start() &#123; // 状态验证, 不等于 NEW 的状态会抛出异常 if (threadStatus != 0) throw new IllegalThreadStateException(); // 通知线程组, 此线程即将启动 group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; // 通知线程组, 此线程启动失败 group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; // 不处理任何异常, 如果 start0 抛出异常, 则它将被传递到调用堆栈上 &#125; &#125;&#125; start() 方法属于 Thread 自身的方法, 并且使用了 synchronized 来保证线程安全 run() 方法为 Runnable 的抽象方法, 重写的 run() 方法其实就是此线程要执行的业务方法 调用 start() 方法是另起线程来运行 run() 方法中的内容 3. 线程的优先级有什么用？该如何设置？ 在 Thread 源码中和线程优先级相关的属性有 3 个 12345678// 线程可以拥有的最小优先级public final static int MIN_PRIORITY = 1;// 线程默认优先级public final static int NORM_PRIORITY = 5;// 线程可以拥有的最大优先级public final static int MAX_PRIORITY = 10 线程的优先级可以理解为线程抢占 CPU 时间片的概率, 优先级越高的线程优先执行的概率就越大, 但并不能保证优先级高的线程一定先执行 在程序中我们可以通过 Thread.setPriority() 来设置优先级 12345678910111213141516public final void setPriority(int newPriority) &#123; ThreadGroup g; // 检查当前线程是否有权限修改优先级 checkAccess(); // 先验证优先级的合理性 if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; if((g = getThreadGroup()) != null) &#123; // 优先级如果超过线程组的最高优先级, 则把优先级设置为线程组的最高优先级 if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125;&#125; 4. 线程的常用方法有哪些？ sleep Thread.sleep() 让线程进入到 TIMED_WAITING 状态, 并停止占用 CPU 资源, 但是不释放持有的 monitor , 直到规定事件后再执行, 休眠期间如果被中断, 会抛出异常并清除中断状态 TimeUnit.SECONDS.sleep() 比 Thread.sleep() 多了非负数判断 join 123456789101112131415161718192021222324public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 本质是用 wait() 实现, 这里 wait() 在循环中调用, 是为了避免可能发生的 虚假唤醒 (spurious wakeup) 情况 JVM 的 Thread 执行完毕会自动执行一次 notifyAll(), 所以不建议在程序中对 Thread 对象调用 wait/notify, 可能会造成干扰 yield A hint to the scheduler that the current thread is willing to yield its current use of a processor. The scheduler is free to ignore this hint. 状态依旧是 RUNNABLE, 不保证释放 CPU 资源 Thread.sleep(0) 可以重新触发 CPU 的竞争, 而 yield 不一定 5. 被弃用的方法有哪些? 为什么被弃用? suspend 使线程暂停, 但不会释放 monitor, 所以容易造成死锁 resume 恢复通过调用 suspend() 方法而停止运行的线程 stop 强制停止当前线程, 会释放该线程所持有对象的 monitor, 因而可能造成这些对象处于不一致的状态 而且这个方法造成的 ThreadDeath 异常不像其他的检查期异常一样被捕获 ThreadLocal ThreadLocal 是线程的内部存储类，可以在指定线程内存储数据。只有指定线程可以得到存储数据 每个线程都有一个 ThreadLocalMap 的实例对象，并且通过 ThreadLocal 管理 ThreadLocalMap 123456789class Thread implements Runnable &#123; ...... /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; ...... &#125; 应用场景 每个线程需要有自己单独的实例 实例需要在多个方法中共享，但不希望被多线程共享 并非必须使用 ThreadLocal ，其它方式完全可以实现同样的效果，只是 ThreadLocal 使得实现更简洁 相关变量和定义12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class ThreadLocal&lt;T&gt; &#123; // 每个 ThreadLocal 实例都有唯一的 hashCode private final int threadLocalHashCode = nextHashCode(); // threadLocalHashCode 值是从 0 开始每次累加 HASH_INCREMENT private static AtomicInteger nextHashCode = new AtomicInteger(); // 该魔法值是取自 2^32 * 黄金分割数, 为的是能好的散列 private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; // 通过继承 ThreadLocal 并实现 initialValue() 方法可以实现初始值 protected T initialValue() &#123; return null; &#125; static class ThreadLocalMap &#123; // map 中的 key 为弱引用 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; // 存放的值 Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; // Entry 数组初始容量 private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int size = 0; // Entry 数组扩容阈值 private int threshold; // Default to 0 // 阈值为容量的 2/3 private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125; ...... &#125;&#125; 关于为什么 HASH_INCREMENT = 0x61c88647 可阅读 从 ThreadLocal 的实现看散列算法 set()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201public void set(T value) &#123; // 获取当前线程实例 Thread t = Thread.currentThread(); // 从当前线程实例中取出 map ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else // 未初始化 map, 初始化 map createMap(t, value);&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; // 存在哈希冲突的情况时需要后移一位继续判断 e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // key 匹配，直接设置值 if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; // 原先该位置的 key 已被回收, 进行清除工作并替换 replaceStaleEntry(key, value, i); return; &#125; &#125; // 当 i 位置为空或哈希冲突后移找到空位置时, 插入数组 tab[i] = new Entry(key, value); int sz = ++size; // 从 i 位置进行快速清理，如果清理成功并且 sz 大于阈值则触发扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 向前寻找最前一个 key 已被回收的 Entry int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 考虑哈希冲突的情况, 向后查找要插入的 key 是否存在 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; // 存在 key, 覆盖旧 value e.value = value; // 原先冲突的 key 已经被回收, 所以将该 Entry 与其交换 tab[i] = tab[staleSlot]; tab[staleSlot] = e; // slotToExpunge == staleSlot 代表 staleSlot 前没有 key 已被回收的 Entry if (slotToExpunge == staleSlot) // 因为交换过位置, 则 slotToExpunge 也要改为 i slotToExpunge = i; // 从 slotToExpunge 位置开始清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; if (k == null &amp;&amp; slotToExpunge == staleSlot) // staleSlot 前没有 key 已被回收的 Entry, 则 slotToExpunge 从这个位置开始 slotToExpunge = i; &#125; // 找不到存在的 key 则新建一个 Entry 插入 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 如果 slotToExpunge != staleSlot 说明还存在其他 key 已被回收的 Entry, 进行清理 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125;private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 将 value 和对应位置置空, 使其能够被回收 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // 继续向后清理, 直到 tab[i] 为 null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; // 将哈希冲突的 Entry 往前移填补清理后空出来的位置 int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; // 返回 staleSlot 后下一个为 null 的位置 return i;&#125;private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; // 发现 key 为 null 则进行清理 if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; // 每次 n 取半 // 这是权衡后的算法, 虽然不能全部扫描但能使清理工作能保持在 O(log2(n)) // 避免插入时会有 O(n) 的时间消耗 &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125;private void rehash() &#123; // 清理 expungeStaleEntries(); // 清理完之后大小还是不够 3/4 阈值的话进行扩容 if (size &gt;= threshold - threshold / 4) resize();&#125;private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; // 从旧数组循环取出 Entry 放入新数组 for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125;// 遍历并调用 expungeStaleEntry(j) 清理 Stale Entryprivate void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125; get()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public T get() &#123; // 获取当前线程实例 Thread t = Thread.currentThread(); // 从当前线程实例中取出 map ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; // 未初始化 map, 初始化 map 并返回初始值 return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else // 存在哈希冲突的情况, 无法直接根据坐标取到想要的 Entry return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 向后查找 key, 遇到 Stale Entry 则进行清理 while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 关于内存泄露 ThreadLocal 对象实际上存放在 Thread 实例中 threadLocals 成员的 Entry 数组里 如果线程一直处于活跃状态, 则 ThreadLocal 对象就算离开具体业务逻辑的作用域, 也因为 threadLocals 持有强引用而无法被回收 所以 ThreadLocalMap 已经将 Entry 设为弱引用, gc 会在 ThreadLocal 离开作用域后对其回收, 但是这是针对 key 的, Entry 持有的 value 却不会被回收 针对这种情况, ThreadLocal 中 get()、set()、remove()这些方法中都存在清理 threadLocals 中 key 为 null 的逻辑, 起到了惰性删除释放内存的作用 InheritableThreadLocal InheritableThreadLocal 是为了解决在子线程中获取不到父线程 ThreadLocal 值的问题 Thread 中也持有对应的 inheritableThreadLocals, 并在 init 中有相关的初始化逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Thread implements Runnable &#123; /* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; ...... Thread parent = currentThread(); // 如果存在 inheritableThreadLocals 则传递给新建出来的子线程 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); ...... &#125; ...... &#125; public class ThreadLocal&lt;T&gt; &#123; static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap); &#125; static class ThreadLocalMap &#123; private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; // 逐一复制 parentMap 的记录 for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings("unchecked") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125; ...... &#125; ......&#125; 重写了 ThreadLocal 的三个方法 1234567891011121314public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; protected T childValue(T parentValue) &#123; return parentValue; &#125; ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125;&#125; 线程池 ( ThreadPoolExecutor) 线程池是为了避免线程频繁的创建和销毁带来的性能消耗, 而建立的一种池化技术, 它是把已创建的线程放入“池”中, 当有任务来临时就可以重用已有的线程, 无需等待创建的过程, 这样就可以有效提高程序的响应速度 构造函数 12345678910public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ......&#125; corePoolSize 表示线程池的常驻核心线程数。如果设置为 0, 则表示在没有任何任务时, 销毁线程池；如果大于 0, 即使没有任务时也会保证线程池的线程数量等于此值。但需要注意, 此值如果设置的比较小, 则会频繁的创建和销毁线程；如果设置的比较大, 则会浪费系统资源, 所以开发者需要根据自己的实际业务来调整此值 maximumPoolSize 表示线程池在任务最多时, 最大可以创建的线程数。官方规定此值必须大于 0, 也必须大于等于 corePoolSize, 此值只有在任务比较多, 且不能存放在任务队列时, 才会用到 keepAliveTime 表示线程的存活时间, 当线程池空闲时并且超过了此时间, 多余的线程就会销毁, 直到线程池中的线程数量销毁的等于 corePoolSize 为止, 如果 maximumPoolSize 等于 corePoolSize, 那么线程池在空闲的时候也不会销毁任何线程 unit 表示存活时间的单位, 它是配合 keepAliveTime 参数共同使用的 workQueue 表示线程池执行的任务队列, 当线程池的所有线程都在处理任务时, 如果来了新任务就会缓存到此任务队列中排队等待执行 threadFactory 表示线程的创建工厂, 此参数一般用的比较少, 我们通常在创建线程池时不指定此参数, 它会使用默认的线程创建工厂的方法来创建线程: 123456789101112131415161718192021222324252627// 默认的线程创建工厂, 需要实现 ThreadFactory 接口static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = "pool-" + poolNumber.getAndIncrement() + "-thread-"; &#125; // 创建线程 public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); // 创建一个非守护线程 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); // 线程优先级设置为默认值 return t; &#125;&#125; 我们也可以自定义一个线程工厂, 通过实现 ThreadFactory 接口来完成, 这样就可以自定义线程的名称或线程执行的优先级了 RejectedExecutionHandler 表示指定线程池的拒绝策略, 当线程池的任务已经在缓存队列 workQueue 中存储满了之后, 并且不能创建新的线程来执行此任务时, 就会用到此拒绝策略, 它属于一种限流保护的机制 ctl 123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 用一个 AtomicInteger 包装两个字段: 高 3 位保存 runState, 低 29 位保存 workerCount 用一个变量去存储两个值, 可避免在做相关决策时, 出现不一致的情况, 不必为了维护两者的一致, 而占用锁资源 workerCount: 有效线程数 runState: 线程池的运行状态 定义 RUNNING: 接受新任务并处理排队的任务 SHUTDOWN: 拒绝接受新任务, 但是会处理还在排队的任务 STOP: 拒绝接受新任务, 也不处理排队中任务, 并且会中断正在执行的任务 TIDYING: 所有任务都已经停止, workerCount 为 0, 转换为状态 TIDYING 的线程将运行 terminated() 方法 TERMINATED: terminated() 执行完毕 这些值之间的数字顺序很重要, 可以进行有序的比较 runState 随着时间逐步增加, 但不一定达到每个状态, 过渡的顺序为: RUNNING -&gt; SHUTDOWN, 在调用 shutdown() 时, 可能隐藏在 finalize() 中调用 (RUNNING or SHUTDOWN) -&gt; STOP, 在调用 shutdownNow() 时 SHUTDOWN -&gt; TIDYING, 当队列和池子内的任务都为空时 STOP -&gt; TIDYING, 当池子内的任务为空时 TIDYING -&gt; TERMINATED, 当 terminated() 执行完毕时 线程池工作流程 通过 execute() 执行任务12345678910111213141516171819202122232425262728public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前工作的线程数小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; // 创建新的线程执行此任务, 传入 true 以核心线程数作为判断阈值 if (addWorker(command, true)) return; // 创建失败, 说明 ctl 有变化, 重新获取 c = ctl.get(); &#125; // 检查线程池是否处于运行状态, 如果是则把任务添加到队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次检查线程池是否处于运行状态, 防止在第一次校验通过后线程池关闭 // 如果是非运行状态, 则将刚加入队列的任务移除 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果线程池的线程数为 0 时（当 corePoolSize 设置为 0 时会发生） else if (workerCountOf(recheck) == 0) addWorker(null, false); // 新建线程执行任务, 传入 false 以最大线程数作为判断阈值 &#125; // 核心线程和队列都满了, 新建非核心线程执行 else if (!addWorker(command, false)) // 新建线程失败, 执行拒绝策略 reject(command);&#125; addWorker(Runnable firstTask, boolean core) 方法 firstTask, 线程应首先运行的任务, 如果没有则可以设置为 null core, 判断是否可以创建线程的阀值（最大值）, 如果等于 true 则表示使用 corePoolSize 作为阀值, false 则表示使用 maximumPoolSize 作为阀值 Worker构造函数 123456789101112private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; final Thread thread; // Worker 持有的线程 Runnable firstTask; // 初始化的任务, 可以为 null Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; ......&#125; 执行任务流程 继承 AQS 原因分析Worker 是通过继承 AQS, 使用 AQS 来实现独占锁这个功能。不用可重入锁 ReentrantLock 而用 AQS, 为的就是实现不可重入的特性去反应线程现在的执行状态 Worker.lock 方法一旦获取了独占锁, 表示当前线程正在执行任务中, 正在执行任务的线程不应该被中断 如果正在执行任务，则不应该中断线程 线程池在执行 shutdown 方法或 tryTerminate 方法时会调用 interruptIdleWorkers 方法来中断空闲的线程, interruptIdleWorkers 方法会使用 tryLock 方法来判断线程是否在执行任务, 如果是空闲状态则可以安全回收 之所以要不可重入, 是为了避免在 Worker 中会调用到线程池 interruptIdleWorkers , 像 setCorePoolSize 方法。如果使用 ReentrantLock, 它是可重入的, 这样会导致该 Worker 自己被中断 此外, 在构造方法中执行了setState(-1);, 把 state 变量设置为 -1, 是因为 AQS 默认的 state 是 0, 如果刚创建了一个 Worker 对象, 还没有执行任务时, 这时就不应该被中断： 12345678910111213protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false;&#125;protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true;&#125; tryAcquire 方法是根据 state 是否是 0 来判断的, 所以, setState(-1); 将 state 设置为 -1 是为了防止在执行任务前就中断了线程 在 runWorker 方法中会先调用 Worker 对象的 unlock 方法将 state 设置为 0, 允许中断和 Worker.lock 相关参数1234567891011121314// 用于操作 workers private final ReentrantLock mainLock = new ReentrantLock();// 持有线程的引用, 管理线程的生命周期private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();// 用于通知线程池终止完毕private final Condition termination = mainLock.newCondition();// 线程池曾经创建过的最大线程数量private int largestPoolSize;// 线程池已经执行的和未执行的任务总数private long completedTaskCount; 为什么workers 不采用线程安全的集合 ? 有许多复合的操作, 比如说将 worker 添加到 workers 后还需要判断是否需要更新 largestPoolSize 等, workers 只在获取到 mainLock 的情况下才会进行读写 mainLock 也用于在中断线程的时候串行执行, 否则可能会并发进行线程中断, 引起不必要的中断高峰 addWorker : 增加工作线程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); if (rs &gt;= SHUTDOWN &amp;&amp; // 线程池是否已停止 ! (rs == SHUTDOWN &amp;&amp; // 线程池是否正在停止 firstTask == null &amp;&amp; ! workQueue.isEmpty()) // 线程是否用于执行剩余任务 ) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || // 线程数是否超过容量 wc &gt;= (core ? corePoolSize : maximumPoolSize)) // 是否超过判断的阀值 return false; if (compareAndIncrementWorkerCount(c)) // CAS 尝试登记线程数 break retry; // 登记成功 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) // 判断线程池状态运行过程中是否有改变 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); // 持有引用 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; // 更新创建过的最大线程数 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); // 启动线程, 而线程的 run 方法就是执行 runWorker() workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; runWorker : 不断获取任务并执行 Worker 被创建出来后, 就会不断地进行轮询, 然后获取任务去执行, 核心线程可以无限等待获取任务, 非核心线程要限时获取任务 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获取第一个任务 Runnable task = w.firstTask; w.firstTask = null; // 允许中断 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为空, 则通过getTask来获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt /** * 确保只有在线程 stoping 时，才会被设置中断标示，否则清除中断标示 * 1、如果线程池状态 &gt;= stop，且当前线程没有设置中断状态，wt.interrupt() * 2、如果一开始判断线程池状态 &lt; stop，但 Thread.interrupted() 为 true (调用的同时清除了中断标示)，即线程已经被中断，再次判断线程池状态是否 &gt;= stop * 是，再次设置中断标示，wt.interrupt() * 否，不做操作，清除中断标示后进行后续步骤 */ if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; // 标明是正常退出 completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask : 从任务队列获取任务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162private Runnable getTask() &#123; // timeOut 表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. /* * 1. 线程池已经 stop * 2. 线程池处于 shutdown 并且队列为空 * 如果以上任何条件满足, 则将 workerCount 减 1 并返回 null */ if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? // timed 用于判断是否需要进行超时控制 // allowCoreThreadTimeOut 默认是 false, 也就是核心线程不允许进行超时 // wc &gt; corePoolSize, 表示当前线程池中的线程数量大于核心线程数量 // 对于超过核心线程数量的这些线程, 需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * 1. 判断 wc &gt; maximumPoolSize 是因为可能通过 setMaximumPoolSize 修改过 maximumPoolSize * 2. timed &amp;&amp; timedOut 如果为 true, 表示当前操作需要进行超时控制, 并且上次从阻塞队列中获取任务发生了超时 * 满足 1 或 2 并且如果有效线程数量大于 1 或者阻塞队列是空的, 那么尝试将 workerCount 减 1 * 判断 wc &gt; 1 是防止在 allowCoreThreadTimeOut 为 true 或 corePoolSize 为 0 时无线程执行还在等待中的任务 * 如果减 1 失败, 则返回重试 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; /* * 根据 timed 来判断, 如果为 true, 则通过阻塞队列的 poll 方法进行超时控制 * 如果在 keepAliveTime 时间内没有获取到任务, 则返回 null * 否则通过 take 方法, 如果这时队列为空, 则 take 方法会阻塞直到队列不为空。 * */ Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 如果 r == null, 说明已经超时, timedOut 设置为 true timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断, 则设置 timedOut 为 false 并返回循环重试 timedOut = false; &#125; &#125;&#125; processWorkerExit : 线程回收 线程池中线程的销毁依赖 JVM 的垃圾回收, 当线程池决定哪些线程需要回收时, 只需要将其引用消除即可 当 Worker 无法获取到任务, 也就是获取的任务为空时, 循环会结束, Worker 会主动消除自身在线程池内的引用 线程回收的工作在 processWorkerExit 方法内完成 12345678910111213141516171819202122232425262728293031323334353637private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果 completedAbruptly 值为 true, 则说明线程执行时出现了异常, 需要将 workerCount 减 1 // 如果线程执行时没有出现异常, 说明在 getTask() 方法中已经已经对 workerCount 进行了减 1 操作 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 统计完成的任务数 completedTaskCount += w.completedTasks; // 从 workers 中移除, 也就表示着从线程池中移除了一个工作线程 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池 tryTerminate(); int c = ctl.get(); /* * 当线程池是 RUNNING 或 SHUTDOWN 状态时, 如果 worker 是异常结束, 那么会直接 addWorker * 如果 allowCoreThreadTimeOut 为 true, 并且等待队列有任务, 至少保留一个 worker * 如果 allowCoreThreadTimeOut 为 false, workerCount 不少于 corePoolSize */ if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125; 事实上在这个方法中, 将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多, 线程池还要判断是什么引发了这次销毁, 是否要改变线程池的现阶段状态, 是否要根据新状态, 重新分配线程 tryTerminate : 根据状态判断是否结束12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); /* * 当前线程池的状态为以下几种情况时, 直接返回： * 1. RUNNING, 因为还在运行中, 不能停止 * 2. TIDYING 或 TERMINATED, 说明正在或者已经在终止 * 3. SHUTDOWN 并且等待队列非空, 这时要执行完 workQueue 中的 task； */ if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 到这个位置为以下情况之一 // 1. 线程池的状态为 SHUTDOWN 并且等待队列为空 // 2. 线程池的状态为 STOP // 如果线程数量不为 0, 则中断一个空闲的工作线程, 并返回 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; // 到这个位置则说明线程数量为 0 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 尝试设置状态为 TIDYING, 如果成功则调用 terminated 方法 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // terminated 方法默认什么都不做, 留给子类实现 terminated(); &#125; finally &#123; // terminated() 执行完毕, 设置状态为 TERMINATED ctl.set(ctlOf(TERMINATED, 0)); // 通知完成终止 termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS // 没设置成功则继续 CAS 尝试 &#125;&#125; shutdown , shutdownNow : 关闭线程池123456789101112131415161718192021222324252627282930313233343536public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 安全策略判断 checkShutdownAccess(); // 切换状态为 SHUTDOWN advanceRunState(SHUTDOWN); // 中断空闲线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试结束线程池 tryTerminate();&#125;public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 设置状态为 STOP advanceRunState(STOP); // 中断所有工作线程 interruptWorkers(); // 取出队列中没有被执行的任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125; interruptIdleWorkers, interruptWorkers : 中断工作线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 通过 w.tryLock 判断是否为空闲 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125;&#125;private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; ...... void interruptIfStarted() &#123; Thread t; // 如果线程已经启动, 中断线程 if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; awaitTermination : 等待线程池完成终止123456789101112131415161718public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (;;) &#123; if (runStateAtLeast(ctl.get(), TERMINATED)) return true; if (nanos &lt;= 0) return false; // 通过 termination 进行等待 nanos = termination.awaitNanos(nanos); &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 相关问题1. ThreadPoolExecutor 的执行方法有几种？它们有什么区别？ execute() VS submit() 都是用来执行线程池任务, 它们最主要的区别是 submit() 方法可以接收线程池执行的返回值, 而 execute() 不能接收返回值 123456789101112131415161718ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 10, 10L, TimeUnit.SECONDS, new LinkedBlockingQueue(20));// execute 使用executor.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("Hello, execute."); &#125;&#125;);// submit 使用Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; System.out.println("Hello, submit."); return "Success"; &#125;&#125;);System.out.println(future.get()); execute() 方法属于 Executor 接口的方法, 而 submit() 方法则是属于 ExecutorService 接口的方法 在 submit() 中处理的任务如果抛出异常, 只有在调用返回的 Future 对象 get 方法时才会抛出 2. 拒绝策略的分类有哪些? 如何自定义拒绝策略？ 自带的拒绝策略有 4 种: AbortPolicy, 终止策略, 线程池会抛出异常并终止执行, 它是默认的拒绝策略 CallerRunsPolicy, 把任务交给当前线程来执行 DiscardPolicy, 忽略此任务 DiscardOldestPolicy, 忽略最早的任务（最先加入队列的任务） 自定义拒绝策略 自定义拒绝策略只需要新建一个 RejectedExecutionHandler 对象, 然后重写它的 rejectedExecution() 方法即可 1234567891011121314ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 3, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(2), new RejectedExecutionHandler() &#123; // 添加自定义拒绝策略 @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 业务处理方法 System.out.println("执行自定义拒绝策略"); &#125; &#125;);for (int i = 0; i &lt; 6; i++) &#123; executor.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName()); &#125;);&#125; 3. 线程池的工作队列有哪些? ArrayBlockingQueue, 是一个用数组实现的有界阻塞队列, 按 FIFO 排序任务, 支持公平锁和非公平锁 LinkedBlockingQueue, 基于链表结构的阻塞队列, 按 FIFO 排序任务, 容量可以选择进行设置, 不设置的话, 将是一个无边界的阻塞队列, 最大长度为 Integer.MAX_VALUE, 吞吐量通常要高于 ArrayBlockingQuene DelayQueue, 是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序, 否则根据插入到队列的先后排序 PriorityBlockingQueue, 是具有优先级的无界阻塞队列, 不能保证同优先级元素的顺序 SynchronousQueue, 一个不存储元素的阻塞队列, 每个插入操作必须等到另一个线程调用移除操作, 否则插入操作一直处于阻塞状态, 吞吐量通常要高于 LinkedBlockingQueue LinkedBlockingDeque, 一个由链表结构组成的双向阻塞队列, 队列头尾都可以插入和移除元素, 多线程并发时, 可以将锁的竞争最多 降到一半 4. ThreadPoolExecutor 如何实现扩展？ 通过重写 beforeExecute() 和 afterExecute() 方法, 我们可以在扩展方法中添加日志或者实现数据统计, 比如统计线程的执行时间 关于 Executors 内的线程池对象 Executors 源码中 Executors.newFixedThreadPool()、Executors.newSingleThreadExecutor() 和 Executors.newCachedThreadPool() 等方法的底层都是通过 ThreadPoolExecutor 实现的 FixedThreadPool (固定数目线程的线程池) 适用于处理 CPU 密集型的任务, 确保 CPU 在长期被工作线程使用的情况下, 尽可能的少的分配线程 特点 核心线程数和最大线程数大小一样 keepAliveTime 为 0 阻塞队列为 LinkedBlockingQueue CachedThreadPool (可缓存线程的线程池) 适用于并发执行大量短期的小任务 特点 核心线程数为 0 最大线程数为 Integer.MAX_VALUE 阻塞队列为 SynchronousQueue 非核心线程空闲存活时间为 60 秒 SingleThreadExecutor (单线程的线程池) 适用于串行执行任务的场景, 一个任务一个任务地执行 特点 核心线程数为 1 最大线程数也为 1 阻塞队列是 LinkedBlockingQueue keepAliveTime 为 0 ScheduledThreadPool (定时及周期执行的线程池) 周期性执行任务的场景, 需要限制线程数量的场景 特点 最大线程数为 Integer.MAX_VALUE 阻塞队列是 DelayedWorkQueue keepAliveTime 为 0 scheduleAtFixedRate() 按某种速率周期执行 scheduleWithFixedDelay() 在某个延迟后执行 在阿里巴巴的《 Java 开发手册 》中是这样规定的： 线程池不允许使用 Executors 去创建, 而是通过 ThreadPoolExecutor 的方式, 这样的处理方式让写的读者更加明确线程池的运行规则, 规避资源耗尽的风险。 Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE, 可能会堆积大量的请求, 从而导致 OOM CachedThreadPool 和 ScheduledThreadPool：允许的创建线程数量为 Integer.MAX_VALUE, 可能会创建大量的线程, 从而导致 OOM 参考 https://www.jianshu.com/p/f4454164c017 http://www.jasongj.com/java/threadlocal https://www.hollischuang.com/archives/2030 https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html https://github.com/openjdk-mirror/jdk7u-hotspot/blob/50bdefc3afe944ca74c3093e7448d6b889cd20d1/src/share/vm/runtime/objectMonitor.cpp]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>multithread</tag>
        <tag>concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java HashMap]]></title>
    <url>%2F2020%2F03%2F14%2FJava-HashMap%2F</url>
    <content type="text"><![CDATA[HashMap 底层 在 JDK 1.7 中 HashMap 是以数组加链表的形式组成的，JDK 1.8 之后新增了红黑树的组成结构，当链表大于 8 时，链表结构会转换成红黑树结构 数组中的元素我们称之为哈希桶，它的定义如下 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 重要属性1234567891011121314151617// HashMap 初始化长度static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// HashMap 最大长度static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 1073741824// 默认的加载因子 (扩容因子)static final float DEFAULT_LOAD_FACTOR = 0.75f;// 转换红黑树的临界值，当链表长度大于此值时，会把链表结构转换为红黑树结构static final int TREEIFY_THRESHOLD = 8;// 转换链表的临界值，当元素小于此值时，会将红黑树结构转换成链表结构static final int UNTREEIFY_THRESHOLD = 6;// 最小树容量static final int MIN_TREEIFY_CAPACITY = 64; 什么是加载因子？加载因子为什么是 0.75？ 加载因子也叫扩容因子或负载因子，用来判断什么时候该进行扩容 假如加载因子是 0.5，HashMap 的初始化容量是 16，那么当 HashMap 中有 16 * 0.5 = 8 个元素时，HashMap 就会进行扩容 0.75 是出于容量和性能之间平衡的结果 当加载因子设置比较大的时候，扩容的门槛就被提高了，扩容发生的频率比较低，占用的空间会比较小，但此时发生 Hash 冲突的几率就会提升，因此需要更复杂的数据结构来存储元素，这样对元素的操作时间就会增加，运行效率也会因此降低 而当加载因子值比较小的时候，扩容的门槛会比较低，因此会占用更多的空间，此时元素的存储就比较稀疏，发生哈希冲突的可能性就比较小，因此操作性能会比较高 还为了提升扩容效率，HashMap的容量（capacity）有一个固定的要求，那就是一定是2的幂。所以，如果负载因子是3/4的话，那么和capacity的乘积结果就可以是一个整数 重要方法查询 12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;K,V&gt; e; // 对 key 进行哈希操作 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 非空判断 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断第一个元素是否是要查询的元素 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 下一个节点非空判断 if ((e = first.next) != null) &#123; // 如果节点是树结构, 则使用 getTreeNode 直接获取相应的数据 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; // 非树结构，循环节点判断 // hash 相等并且 key 相同，则返回此节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 当哈希冲突时需要通过判断 key 值是否相等来确认此元素是否是要查询的元素 新增 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 哈希表为空则创建表 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 根据 key 的哈希值计算出要插入的数组索引 i if ((p = tab[i = (n - 1) &amp; hash]) == null) // 如果 table[i] 等于 null, 则直接插入 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 如果与第一个元素的 key 相等，直接覆盖第一个元素的 value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 需要往后插入元素，先判断是否为红黑树 else if (p instanceof TreeNode) // 红黑树直接插入键值对 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 为链表结构，循环准备插入 for (int binCount = 0; ; ++binCount) &#123; // 下一个元素为空时直接插入 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 链表长度大于 8 转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果与下一个元素的 key 相等，直接覆盖下一个元素的 value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 超过最大容量，扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 扩容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495final Node&lt;K,V&gt;[] resize() &#123; // 扩容前的数组 Node&lt;K,V&gt;[] oldTab = table; // 扩容前的数组大小 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 扩容前的扩容阈值 int oldThr = threshold; // 预定义新数组的大小和阈值 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩容了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 扩大容量为当前容量的两倍，但不能超过 MAXIMUM_CAPACITY else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 当前数组没有数据，使用初始化的值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 如果初始化的值为 0，则使用默认的初始化容量 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 如果新阈值为 0 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 开始扩容 table = newTab; // 原数据不为空，将原数据复制到新 table 中 if (oldTab != null) &#123; // 根据容量循环数组，复制非空元素到新 table for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) // 链表只有一个元素时直接赋值 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 下个元素为红黑树时, 进行相关操作 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 链表复制，JDK 1.8 扩容优化部分 // 用于连接扩容时位置不变的元素 Node&lt;K,V&gt; loHead = null, loTail = null; // 用于连接扩容时位置改变的元素 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引 + oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将原索引放到哈希桶中 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 将原索引 + oldCap 放到哈希桶中 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; JDK 1.8 在扩容时并没有像 JDK 1.7 那样，重新计算每个元素的哈希值，而是通过 e.hash &amp; oldCap 来确定元素是否需要移动 如 key1 的信息如下： key1.hash = 10 -&gt; 0000 1010 oldCap = 16 -&gt; 0001 0000 使用 e.hash &amp; oldCap 得到的结果为 0，则在扩容时位置不会发生任何变化 而 key 2 信息如下： key2.hash = 26 -&gt; 0001 1010 oldCap = 16 -&gt; 0001 0000 这时候得到的结果不为 0，新的下标位置等于原下标位置 + 原数组长度 为什么要这么做 ? 首先这里的元素扩容前都是在同一个数组下标中的, 也就是 (oldCap - 1) &amp; hash 值相同 扩容的时候新容量是左移了一位的, 如下 oldCap = 16 -&gt; 0001 0000 newCap = 32 -&gt; 0010 0000 则相应的 oldCap -1 = 15 -&gt; 0000 1111 newCap - 1 = 31 -&gt; 0001 1111 所以对于 e.hash &amp; oldCap 不为 0 的元素, 需要放置到原索引 + oldCap 的位置, 因为在 newCap 的情况下插入该元素时, (newCap - 1) &amp; hash 值就是原索引 + oldCap 死循环分析 在 JDK 1.7 中, 假设 HashMap 默认大小为 2，原本 HashMap 中有一个元素 key(5) 我们再使用两个线程 t1 添加元素 key(3) t2 添加元素 key(7) 当元素 key(3) 和 key(7) 都添加到 HashMap 中之后，开始进行扩容操作 当线程 t1 在执行到 Entry&lt;K,V&gt; next = e.next; 时，交出了 CPU 的使用权，源码如下: 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; // 线程一执行此处 if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 此时线程 t1 中的 e 指向了 key(3)，而 next 指向了 key(7) 之后线程 t2 重新 rehash 之后链表的顺序被反转, 链表的位置变成了 key(5) → key(7) → key(3)，其中 “→” 用来表示下一个元素 当 t1 重新获得执行权之后，先执行 newTalbe[i] = e; 把 key(3) 的 next 设置为 key(7) 而下次循环时查询到 key(7) 的 next 元素为 key(3)，于是就形成了 key(3) 和 key(7) 的循环引用 发生死循环的原因是 JDK 1.7 链表插入方式为首部倒序插入，这个问题在 JDK 1.8 得到了改善，变成了尾部正序插入 HashMap 本身就是非线程安全的, 所以不建议在多线程下使用]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 关键字 final]]></title>
    <url>%2F2020%2F03%2F13%2FJava-%E5%85%B3%E9%94%AE%E5%AD%97-final%2F</url>
    <content type="text"><![CDATA[final方法 被 final 修饰的方法不可被重写。它可以防止任何继承类修改方法的意义和实现 而且使用 final 修饰方法的执行效率一般高于普通方法，这里不得不提一下 Java 的内联（inline）机制 ​ 当我们调用方法时，实际上是将程序的执行转移到该方法所在的内存地址上，将该方法执行完后，再返回到执行该方法前的位置，这种转移操作要求在转移前保存当前的数据以及内存地址，在执行完后再恢复现场，继续按照转移前的地址执行，也就是通常所说的压栈和出栈（这段文字有点绕口，简单来说，比如 A 方法在执行到第 10 行的时候调用了 B 方法，JVM 会先保存 A 方法当前数据和执行地址，然后跳转到 B 方法所在的内存地址执行 B 方法，执行完后，再返回 A 方法第十行继续执行），因此，函数调用有一定时间和空间方面的开销，对于函数体积不大，但是频繁调用的函数来说，这个开销就会放大。​ 因此，对于这种函数体积不大又频繁调用的的方法，我们可以通过内联函数来提升运行效率，当我们对一个方法使用 final 修饰时，这个方法就有可能成为内联函数（JVM 会根据方法的执行效率决定是否内联）。 内联前： 1234567891011121314class A &#123; int value; public final int get()&#123; return value; &#125;&#125;public class B &#123; public void sum() &#123; A a = new A(); //调用a的get方法 int x = a.get(); &#125;&#125; 内联后： 1234567891011121314class A &#123; int value; public final int get()&#123; return value; &#125;&#125;public class B &#123; public void sum() &#123; A a = new A(); //此处将get方法展开为内联函数 int x = a.value; &#125;&#125; 类 当 final 修饰一个类时，表明其为最终类，它不能被继承 并且类中所有的属性和方法都默认是 final 类型，如 String，Integer 等包装类均为 final 类 方法默认被修饰为 final ，这时方法的内联起到作用了, 这种空间置换时间的策略需要一个平衡点（break-even），如果一个方法过于大，copy 的副本数量过于多，那么这样的平衡就会被打破，优化的目的反而失去了意义 变量 修饰基本类型变量时，变量的值不可改变 修饰引用变量时，变量指向的对象地址不可改变 这里还涉及到了一个类似 C 语言的宏替换概念，由于 final 修饰的 String 变量不可更改，所以，当一个 String 变量被 final 修饰时，这个值在编译期就可以确定，所以将该变量直接替换为它对应的值，如下： 123456789101112131415161718192021public class test &#123; public static void main(String[] args) &#123; final String a = "hello"; String b = "hello"; final String c = "world"; String d = "hello" + "world"; String e = a + c; String f = b + c; String g = "helloworld"; // 在编译期，由于 a 和 c 的值已经确定并且不会再更改（效果同 d）， // 所以 e 的值能够在编译期就确定下来，直接指向了常量区的 g，前两个均为 true System.out.println(g == d); // true System.out.println(g == e); // true // 由于 b 值的不确定性，所以在编译期不能确定其值，只能在运行时确认 System.out.println(g == f); // false // 注意: 以上比较的是变量的地址 &#125;&#125; 参数 final 修饰的参数有一个只读的属性，即可以读取该参数，但是无法更改参数的值，同修饰变量一样，当参数为基本类型时，该参数的值不可改变；当参数为引用类型时，参数的引用地址不可改变。 有什么意义? 对于通过入参引用修改对象时, 可以防止在函数中通过赋值修改该引用, 避免修改失败 可以在函数中将入参再传递给匿名函数 (lambda), 因为该入参被 final 修饰后是存在于常量池中, 而不是函数的调用栈, 这样该函数调用完之后匿名函数还是能读到该入参的值 final 的内存语义 volatile 可以禁止指令重排序，final 同样有这样的作用，对于 final 域，编译器和处理器要遵守两个重排序规则 在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 意思是说，在对象引用为任意线程可见之前，对象的 final 域已经被正确初始化了（JVM 禁止把 final 域的写重排序到构造函数之外，要保证该效果，还要确保 final 引用没有从构造函数溢出）。 初次读一个包含 final 域的对象的引用，与随后初次读这个 final 域，这两个操作之间不能重排序。 意思是说，在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。 对于内存语义这块，还需要结合代码去理解，参考《Java 并发编程的艺术》一书 3.6 节。 参考: https://zhuanlan.zhihu.com/p/60889552 https://www.jianshu.com/p/f68d6ef2dcf0]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>final</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人月神话笔记]]></title>
    <url>%2F2020%2F02%2F26%2F%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[人月神话笔记 1975 出版的经典书籍, 记录其中令我印象深刻且到目前也不过时的内容 人月神话 人月是危险和带有欺骗性的神话，因为它暗示人员数量和时间是可以相互替换的 向进度落后的项目增加人手只会导致项目更加落后 任务重新分配本身和所造成的工作中断 培训新人员 额外的相互沟通 关于进度安排, 1/3计划、1/6编码、1/4构件测试以及1/4系统测试 外科手术队伍 把大型团队拆分为若干个类似于外科手术式的小团队 每个小团队有一名主程序员（类似于主刀医生），所有的问题分解和功能定义都通过主程序员来完成，以此来降低沟通成本 每个主程序员配备若干个平庸的人帮他/她打下手 贵族专制、民主政治和系统设计 概念完整性是系统设计中最重要的考虑因素 为了获得概念完整性，设计必须由一个人或者具有共识的小型团队来完成 将设计方法、体系结构方面的工作与具体实现相分离是获得概念完整性的强有力方法 蛇添足, 贯彻执行, 为什么巴比伦塔会失败？ 不要过度设计，尤其是在第二个系统(第一个系统完成后开发的第二个系统)中，不要过度自信，保持警觉，避免初始的概念和目标得到充分的体现，而不让一些次要的功能喧宾夺主 沟通交流的重要性, 尽早交流, 持续沟通 整体部分 在设计系统结构时精心设计，减少各个部分间的耦合，各个模块的独立性越高，系统级的 bug 的可能性就越低 未雨绸缪 目标上（和开发策略上）的一些正常变化无可避免，事先为它们做准备总比假设它们不会出现要好得多 机器在变化，配置在变化，用户的需求在变化，所以现实系统不可能永远可用。崭新的、对于原有系统的重新设计是完全必要的。 祸起萧墙 里程碑的选择只有一个原则，那就是，里程碑必须是具体的、特定的、可度量的事件，能够进行清晰定义 减少角色的冲突。老板必须规范自己，不对项目经理可以解决的问题做出反应 没有银弹 不可能有某种技术突破（银弹）能够彻底解决“根本性困难”，从而导致软件开发效率有数量级的提高 增量开发，把软件当做是生长的有机体, 从简单的核心开始，一边交付一边开发，不断增加新的功能，一边增加新的功能，一边重构已有的部分]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>programing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes 学习笔记]]></title>
    <url>%2F2020%2F02%2F12%2FKubernetes-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Docker 基础 Namespace 进程之间的可见性 Cgoups 限制资源的使用 K8s 基础组件 Kubernetes 主要由以下几个核心组件组成: master 组件, 可以运行于集群中的任何机器上, 但为了简洁性通常在同一台机器上运行所有的 master 组件，且不在此机器上运行用户的容器 kube-apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 etcd 保存了整个集群的状态，就是一个数据库 kube-scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 kube-controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 cloud-controller-manager 运行了与具体云基础设施供应商互动的控制器 node 组件 Kubelet 负责维护容器的生命周期，同时也负责 Volume（CSI）和网络（CNI）的管理 Container Runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI） kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡 除了上面的这些核心组件，还有一些推荐的插件： kube-dns 负责为整个集群提供 DNS 服务 Ingress Controller 为服务提供外网入口 Heapster 提供资源监控 Dashboard 提供 GUI Kubernetes 多组件之间的通信原理 apiserver 负责 etcd 存储的所有操作，且只有 apiserver 才直接操作 etcd 集群 apiserver 对内（集群中的其他组件）和对外（用户）提供统一的 REST API，其他组件均通过 apiserver 进行通信 controller manager、scheduler、kube-proxy 和 kubelet 等均通过 apiserver watch API 监测资源变化情况，并对资源作相应的操作 所有需要更新资源状态的操作均通过 apiserver 的 REST API 进行 apiserver 也会直接调用 kubelet API（如 logs, exec, attach 等），默认不校验 kubelet 证书，但可以通过 --kubelet-certificate-authority 开启（而 GKE 通过 SSH 隧道保护它们之间的通信） 比如最典型的创建 Pod 的流程： 用户通过 REST API 创建一个 Pod apiserver 将其写入 etcd scheduluer 检测到未绑定 Node 的 Pod，开始调度并更新 Pod 的 Node 绑定 kubelet 检测到有新的 Pod 调度过来，通过 container runtime 运行该 Pod kubelet 通过 container runtime 取到 Pod 状态，并更新到 apiserver 中 Master 控制节点，负责整个集群的管理和控制 Master 节点上包含以下组件： etcd apiserver controller manager scheduler Node 工作节点, 工作负载主要是运行容器应用。Node 节点上包含以下组件： kubelet kube-proxy container runtime Pod 一个 pod 的所有容器都运行在同一个节点 在 pod 中指定容器端口只是展示作用 可以通过对端口命名更方便的使用 使用 kubectl port-forward 将本地网络端口转发到 pod 端口 kubectl port-forward nginx 8888:80 静态 Pod Pod Hook PostStart PreStop 健康检查 livenessProbe readnessProbe Init Container Deployment Replication Controller（RC） Replication Set（RS） 支持基于集合的 selector 一个 Deployment 控制多个 RS ( 为了支持回滚 ) Service 相关 IP 概念 Node IP Pod IP Cluster IP 类型 ClusterIP NodePort LoadBalancer ExternalName ConfigMap Secret Opaque kubernetes.io/dockerconfigjson kubernetes.io/service-account-token Horizontal Pod Autoscaling (HPA) Heapster Job CronJob RBAC Role 和 ClusterRole Rule Subject User Account Group Service Account RoleBinding 和 ClusterRoleBinding DaemonSet StatefulSet 服务的有状态和无状态 持久化存储 PV PVC StorageClass 服务发现 内部服务发现 通过 apiserver 查询 依赖 K8s 通过环境变量 依赖的服务必须在 Pod 启动之前就存在 DNS Server kubedns coredns 外部服务发现 ingress Traefik Helm 概念 chart config release Helm Client Tiller Server]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 定时备份 (基于 Dokcer 运行)]]></title>
    <url>%2F2020%2F01%2F17%2FMysql-%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD-(%E5%9F%BA%E4%BA%8E-Dokcer-%E8%BF%90%E8%A1%8C)%2F</url>
    <content type="text"><![CDATA[脚本编写 vim mysql_bak.sh 123456789101112131415161718192021222324252627282930#!/bin/sh# 数据库相关配置host=1.2.3.4port=3306user=rootpassword=123456db_name=db# 存放目录 (绝对路径)backupdir=/mysqlbackup# 保留天数time=1echo "开始备份数据库";# 生成脚本echo "mysqldump --host=$host --port=$port -u$user -p$password --extended-insert $db_name | gzip &gt; /mysqlbackup/$db_name`date +%Y-%m-%d_%H%M%S`.sql.gz" &gt; $backupdir/run.sh# 赋权sudo chmod 744 $backupdir/run.sh# 启动 docker 运行脚本docker run --rm -v $backupdir:/mysqlbackup mysql:5.7 /mysqlbackup/run.sh# 删除 time 天前的备份文件, 若要改为分钟, 使用 -mminfind $backupdir -name $db_name"*.sql.gz" -type f -mtime +$time -exec rm -rf &#123;&#125; \; echo "备份完成"; 赋权 sudo chmod 744 mysql_bak.sh 执行测试是否成功 sudo ./mysql_bak.sh 查看对应目录下是否生成备份文件 配置定时任务 用 crontab 定时执行备份脚本代码 sudo crontab -u root -e 以 root 身份打开编辑 crontab 的工作内容 加入内容, 若要每小时 30 分时备份, 输入以下内容 30 * * * * /(脚本所在路径)/mysql_bak.sh &gt;&gt; /(脚本所在路径)/mysql_bak.log Ubuntu 系统默认是不打开 cron 日志, 需要配置: 打开文件 sudo vi /etc/rsyslog.d/50-default.conf 在文件中找到 cron.*，把前面的 # 去掉 保存退出 重新加载配置 sudo service rsyslog restart 查看日志 tail -f /var/log/cron.log 其他 恢复数据时, 可能会因为 sql 文件过大报错, 需要修改 max_allowed_packet 的值, 默认为 4MB 12345678# 查看当前 max_allowed_packet 的值mysql&gt; show variables like &apos;max_allowed_packet&apos;;# 数据库中临时修改（重启数据库后失效）, 最大可以设置为 1Gmysql&gt; set global max_allowed_packet = 1 * 1024 * 1024 * 1024;# 需要退出保存mysql&gt; exit]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 基本使用]]></title>
    <url>%2F2019%2F08%2F02%2FDocker-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[停止并删除所有容器1$ docker stop $(docker ps -q) docker rm $(docker ps -aq) 清理镜像12345# 清理 dangling 镜像$ docker rmi $(docker images -f "dangling=true" -q)# 根据通配符查找删除指定镜像$ docker rmi $(docker images -f "reference=*" --format "&#123;&#123;.Repository&#125;&#125;:&#123;&#123;.Tag&#125;&#125;") 创建 Swarm 集群以及其基本操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 修改 node name￼$ sudo hostnamectl set-hostname &#123;$name&#125;￼$ sudo systemctl restart docker# ￼manager: 创建 swarm 集群￼$ ￼docker swarm init# 创建 swarm 集群时指定 ip 和通讯的 udp 端口 (针对云服务器上部分环境时需用到)$ docker swarm init --advertise-addr 1.2.3.4 --data-path-port 12345# ￼node: 加入 swarm 集群￼$ ￼docker swarm join ......# ￼获取加入token￼$ ￼docker swarm join-token [worker|manager]# ￼manager: 查看节点￼$ ￼docker node ls# 部署单个服务$ docker service create --replicas 3 -p 80:80 --name nginx nginx# 查看服务$ docker service ls # 服务伸缩$ docker service scale nginx=5# 删除服务$ docker service rm nginx# 根据 yaml 文件部署包含多个服务的 stack$ docker stack deploy -c xxxx.yml one-stack# 根据 yaml 文件部署 stack 时能读取同层 .env 文件内设置的环境变量$ docker stack deploy -c &lt;(docker-compose -f xxxx.yml config) one-stack# 根据 yaml 文件部署 stack 时能读取同层 .env 文件内设置的环境变量, 从私库拉取镜像$ docker stack deploy --with-registry-auth -c &lt;(docker-compose -f xxxx.yml config) one-stack# 查看 stack$ docker stack ls # 查看 stack 中的服务$ docker stack ps one-stack # 停止删除 stack (该命令不会移除服务所使用的数据卷，移除数据卷用 docker volume rm)$ docker stack down one-stack# 更新 service 镜像, 从私库拉取$ docker service update --with-registry-auth --image image-name:tag service-name# 批量删除 service$ docker service rm $(docker service ls -qf name=)# 指定 service 在某个 node 运行# 给 node 打标签$ docker node update --label-add run-a=1 xxxxxx# 给 service 加入约束条件$ docker service update --constraint-add "node.labels.run-a==1" swarm_a Docker Compose 文件相关配置 参考官方文档 yaml 中重用代码块 12345678910test: &amp;base a: 1 b: 2use1: *baseuse2: &lt;&lt;: *base b: 3 c: 4 123456789101112test: a: 1 b: 2 use1: a: 1 b: 2 use2: a: 1 b: 3 c: 4 Dockerfile ONBUILD 指令 格式：ONBUILD &lt;其它指令&gt;。 ONBUILD是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。 1234567FROM node:slimRUN mkdir /appWORKDIR /appONBUILD COPY ./package.json /appONBUILD RUN [ "npm", "install" ]ONBUILD COPY . /app/CMD [ "npm", "start" ] 这样各个子镜像在构建的时候就不需要重复加入上面三行命令 多阶段构建 12345678910111213FROM golang AS build-envADD . /go/src/appWORKDIR /go/src/appRUN go get -u -v github.com/kardianos/govendorRUN govendor syncRUN GOOS=linux GOARCH=386 go build -v -o /go/src/app/app-serverFROM alpineRUN apk add -U tzdataRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY --from=build-env /go/src/app/app-server /usr/local/bin/app-serverEXPOSE 8080CMD [ "app-server" ] 默认情况下，构建阶段是没有命令的，我们可以通过它们的索引来引用它们，第一个 FROM 指令从0开始，我们也可以用 AS 指令为阶段命令，比如我们这里的将第一阶段命名为 build-env，然后在其他阶段需要引用的时候使用 --from=build-env 参数即可]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-swarm</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在服务器上的相关运维操作]]></title>
    <url>%2F2019%2F08%2F02%2F%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[安装 Docker 其他系统的安装可以参考官方文档 Ubuntu 12345678910111213141516171819202122232425262728# 安装 Docker 依赖库$ sudo apt-get update $ sudo apt-get install apt-transport-https ca-certificates \ gnupg-agent software-properties-common \ curl# 清理过去遗留的老版本 $ sudo apt-get remove docker docker-engine docker.io containerd runc# 添加 Docker 官方的 GPG key$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 添加 docker 仓库$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"# 安装 Docker CE$ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io# 验证$ sudo docker run hello-world# 配置镜像加速器$ echo '&#123; "registry-mirrors": ["https://umbmb1yu.mirror.aliyuncs.com"] &#125;' | sudo tee /etc/docker/daemon.json$ sudo systemctl daemon-reload$ sudo systemctl restart docker# 登录私库$ sudo docker login --username=abmatrix registry.cn-hangzhou.aliyuncs.com 12# 使用阿里官方安装脚本自动安装 （仅适用于公网环境）$ sudo curl -fsSL https://get.docker.com | sudo bash -s docker --mirror Aliyun 删除 Docker12345# 卸载 Docker CE 包$ sudo apt-get purge docker-ce# 删除 images、containers 和 volumes$ sudo rm -rf /var/lib/docker 修改 hostname12# 修改 hostname$ hostnamectl set-hostname --static abm-aliyun-x 开启 ssh 密码登录1234567$ vim /etc/ssh/sshd_config修改 PasswordAuthentication yes若无法使用 root 用户进行 SSH 登录, 还需修改 PermitRootLogin yes$ service sshd restart 挂载硬盘12345678910111213# 查看主机上的硬盘$ fdisk -l# 硬盘格式化$ mkfs.ext4 /dev/vdb# 挂载$ mount /dev/vdb /mnt# 开机自动挂载, 编辑 /etc/fstab 文件$ vim /etc/fstab# 追加/dev/vdb /mnt ext4 defaults 0 0 添加用户并并将用户加入 Docker 组12345678910111213141516171819202122# 添加用户$ adduser abm# 加入 sudo 权限$ chmod u+w /etc/sudoers$ echo "abm ALL=(ALL:ALL) ALL" &gt;&gt; /etc/sudoers$ chmod u-w /etc/sudoers# 查看是否存在 docker 组$ cat /etc/group | grep docker# 不存的话创建 docker 分组$ groupadd docker# 对应用户登录# 将用户添加 docker 分组$ sudo gpasswd -a $USER docker$ newgrp docker# 设置权限$ sudo chown "$USER":"$USER" /home/"$USER"/.docker -R$ sudo chmod g+rwx "/home/$USER/.docker" -R Docker 其他组件安装12345678# 安装 docker-compose$ sudo curl -L "https://github.com/docker/compose/releases/download/1.25.5/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose# 设置权限$ sudo chmod +x /usr/local/bin/docker-compose# 安装命令补全$ sudo curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose 修改 Docker 储存位置1234567891011# 停止服务$ sudo service docker stop# 转移$ sudo mv /var/lib/docker /mnt/data/docker# 创建软链接$ sudo ln -s /mnt/data/docker /var/lib/docker# 启动服务$ sudo service docker start 设置防火墙规则123456789101112131415161718# 指定端口$ sudo ufw allow 22# Docker Swarm 相关端口$ sudo ufw allow 2376/tcp$ sudo ufw allow 2377/tcp$ sudo ufw allow 7946/tcp$ sudo ufw allow 7946/udp$ sudo ufw allow 4789/udp# 指定 ip$ sudo ufw allow from 123.123.123.123# 开启$ sudo ufw enable# 重新加载$ sudo ufw reload 测试 UPD 端口123456789# 服务端监听：$ nc -l -u 192.168.80.129 8001# 客户端：$ nc -u 192.168.80.129 8001# 在这里输入字符串， 服务端就会回显相同的字符串，表示 8001 端口上的 udp 服务是否启用.# 查看 udp 连接$ netstat -nua]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab Devops 配置]]></title>
    <url>%2F2019%2F06%2F13%2FGitlab-Devops-%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[K8s 环境在 Kubernetes 集群上安装 Gitlab-Runnerhttps://docs.gitlab.com/runner/install/kubernetes.html 123kubectl patch deploy --namespace kube-system tiller-deploy -p '&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'helm install --namespace gitlab --name gitlab-runner -f values.yaml gitlab/gitlab-runner values.yaml 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282## GitLab Runner Image#### By default it's using gitlab/gitlab-runner:alpine-v&#123;VERSION&#125;## where &#123;VERSION&#125; is taken from Chart.yaml from appVersion field#### ref: https://hub.docker.com/r/gitlab/gitlab-runner/tags/##image: gitlab/gitlab-runner:alpine-v12.0.0-rc1## Specify a imagePullPolicy## 'Always' if imageTag is 'latest', else set to 'IfNotPresent'## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images##imagePullPolicy: IfNotPresent## The GitLab Server URL (with protocol) that want to register the runner against## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-register##gitlabUrl: https://gitlab.com/## The Registration Token for adding new Runners to the GitLab Server. This must## be retrieved from your GitLab Instance.## ref: https://docs.gitlab.com/ce/ci/runners/README.html##runnerRegistrationToken: "NkeYywTkYwWf14JZxtM1"## The Runner Token for adding new Runners to the GitLab Server. This must## be retrieved from your GitLab Instance. It is token of already registered runner.## ref: (we don't yet have docs for that, but we want to use existing token)### runnerToken: ""### Unregister all runners before termination#### Updating the runner's chart version or configuration will cause the runner container## to be terminated and created again. This may cause your Gitlab instance to reference## non-existant runners. Un-registering the runner before termination mitigates this issue.## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-unregister##unregisterRunners: true## Set the certsSecretName in order to pass custom certficates for GitLab Runner to use## Provide resource name for a Kubernetes Secret Object in the same namespace,## this is used to populate the /etc/gitlab-runner/certs directory## ref: https://docs.gitlab.com/runner/configuration/tls-self-signed.html#supported-options-for-self-signed-certificates### certsSecretName:## Configure the maximum number of concurrent jobs## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section##concurrent: 10## Defines in seconds how often to check GitLab for a new builds## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section##checkInterval: 30## Configure GitLab Runner's logging level. Available values are: debug, info, warn, error, fatal, panic## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section### logLevel:## For RBAC support:rbac: create: true ## Run the gitlab-bastion container with the ability to deploy/manage containers of jobs ## cluster-wide or only within namespace clusterWideAccess: false ## Use the following Kubernetes Service Account name if RBAC is disabled in this Helm chart (see rbac.create) ## # serviceAccountName: default## Configure integrated Prometheus metrics exporter## ref: https://docs.gitlab.com/runner/monitoring/#configuration-of-the-metrics-http-servermetrics: enabled: true## Configuration for the Pods that that the runner launches for each new job##runners: ## Default container image to use for builds when none is specified ## image: ubuntu:16.04 ## Specify one or more imagePullSecrets ## ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/ ## # imagePullSecrets: [] ## Specify the image pull policy: never, if-not-present, always. The cluster default will be used if not set. ## # imagePullPolicy: "" ## Defines number of concurrent requests for new job from GitLab ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-section ## # requestConcurrency: 1 ## Specify whether the runner should be locked to a specific project: true, false. Defaults to true. ## # locked: true ## Specify the tags associated with the runner. Comma-separated list of tags. ## ## ref: https://docs.gitlab.com/ce/ci/runners/#using-tags ## tags: "k8s-runner" ## Run all containers with the privileged flag enabled ## This will allow the docker:dind image to run if you need to run Docker ## commands. Please read the docs before turning this on: ## ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-dind ## privileged: true ## The name of the secret containing runner-token and runner-registration-token # secret: gitlab-runner ## Namespace to run Kubernetes jobs in (defaults to the same namespace of this release) ## namespace: gitlab ## Distributed runners caching ## ref: https://gitlab.com/gitlab-org/gitlab-runner/blob/master/docs/configuration/autoscale.md#distributed-runners-caching ## ## If you want to use s3 based distributing caching: ## First of all you need to uncomment General settings and S3 settings sections. ## ## Create a secret 's3access' containing 'accesskey' &amp; 'secretkey' ## ref: https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/ ## ## $ kubectl create secret generic s3access \ ## --from-literal=accesskey="YourAccessKey" \ ## --from-literal=secretkey="YourSecretKey" ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ ## ## If you want to use gcs based distributing caching: ## First of all you need to uncomment General settings and GCS settings sections. ## ## Access using credentials file: ## Create a secret 'google-application-credentials' containing your application credentials file. ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section ## You could configure ## $ kubectl create secret generic google-application-credentials \ ## --from-file=gcs-applicaton-credentials-file=./path-to-your-google-application-credentials-file.json ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ ## ## Access using access-id and private-key: ## Create a secret 'gcsaccess' containing 'gcs-access-id' &amp; 'gcs-private-key'. ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section ## You could configure ## $ kubectl create secret generic gcsaccess \ ## --from-literal=gcs-access-id="YourAccessID" \ ## --from-literal=gcs-private-key="YourPrivateKey" ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ cachePath: "/opt/gitlab_runner/cache" cache: &#123;&#125; ## General settings # cacheType: s3 # cachePath: "/opt/gitlab_runner/cache" # cacheShared: true ## S3 settings # s3ServerAddress: s3.amazonaws.com # s3BucketName: # s3BucketLocation: # s3CacheInsecure: false # secretName: s3access ## GCS settings # gcsBucketName: ## Use this line for access using access-id and private-key # secretName: gcsaccess ## Use this line for access using google-application-credentials file # secretName: google-application-credentials ## Build Container specific configuration ## builds: &#123;&#125; # cpuLimit: 200m # memoryLimit: 256Mi # cpuRequests: 100m # memoryRequests: 128Mi # image: gitlab/gitlab-runner-helper:x86_64-latest ## Service Account to be used for runners ## # serviceAccountName: ## If Gitlab is not reachable through $CI_SERVER_URL ## # cloneUrl: ## Specify node labels for CI job pods assignment ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ ## # nodeSelector: &#123;&#125; ## Specify pod labels for CI job pods ## # podLabels: &#123;&#125; ## Specify annotations for job pods, useful for annotations such as iam.amazonaws.com/role # podAnnotations: &#123;&#125; ## Configure environment variables that will be injected to the pods that are created while ## the build is running. These variables are passed as parameters, i.e. `--env "NAME=VALUE"`, ## to `gitlab-runner register` command. ## ## Note that `envVars` (see below) are only present in the runner pod, not the pods that are ## created for each build. ## ## ref: https://docs.gitlab.com/runner/commands/#gitlab-runner-register ## # env: # NAME: VALUE## Configure resource requests and limits## ref: http://kubernetes.io/docs/user-guide/compute-resources/##resources: &#123;&#125; # limits: # memory: 256Mi # cpu: 200m # requests: # memory: 128Mi # cpu: 100m## Affinity for pod assignment## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity##affinity: &#123;&#125;## Node labels for pod assignment## Ref: https://kubernetes.io/docs/user-guide/node-selection/##nodeSelector: &#123;&#125; # Example: The gitlab runner manager should not run on spot instances so you can assign # them to the regular worker nodes only. # node-role.kubernetes.io/worker: "true"## List of node taints to tolerate (requires Kubernetes &gt;= 1.6)## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/##tolerations: [] # Example: Regular worker nodes may have a taint, thus you need to tolerate the taint # when you assign the gitlab runner manager with nodeSelector or affinity to the nodes. # - key: "node-role.kubernetes.io/worker" # operator: "Exists"## Configure environment variables that will be present when the registration command runs## This provides further control over the registration process and the config.toml file## ref: `gitlab-runner register --help`## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html### envVars:# - name: RUNNER_EXECUTOR# value: kubernetes## list of hosts and IPs that will be injected into the pod's hosts filehostAliases: [] # Example: # - ip: "127.0.0.1" # hostnames: # - "foo.local" # - "bar.local" # - ip: "10.1.2.3" # hostnames: # - "foo.remote" # - "bar.remote"## Annotations to be added to manager pod##podAnnotations: &#123;&#125; # Example: # iam.amazonaws.com/role: &lt;my_role_arn&gt; 123456gcr.io/kubernetes-helm/tiller:v2.12.3docker pull fishead/gcr.io.kubernetes-helm.tiller:v2.12.3docker tag fishead/gcr.io.kubernetes-helm.tiller:v2.12.3 gcr.io/kubernetes-helm/tiller:v2.12.3去 docker hub 找个镜像仓库 配置 Kubernetes cluster details 参考 官方文档 - Adding an existing Kubernetes cluster 的说明 安装 Helm Tiller 点击页面 Install 按钮 kubectl get pods -A 能看到 install-helm 的 pod 根据 pod/install-helm 生成 yaml 1kubectl get pod install-helm -n gitlab-managed-apps -o yaml &gt; install-helm.yaml 修改 yaml 中的 pod 启动命令, 加入阿里云仓库 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata:......spec: containers: - args: - -c - $(COMMAND_SCRIPT) command: - /bin/sh env: - name: HELM_VERSION value: 2.12.3 - name: TILLER_NAMESPACE value: gitlab-managed-apps - name: COMMAND_SCRIPT value: |- set -xeo pipefail helm init --tiller-tls --tiller-tls-verify --tls-ca-cert /data/helm/helm/config/ca.pem --tiller-tls-cert /data/helm/helm/config/cert.pem --tiller-tls-key /data/helm/helm/config/key.pem --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.12.3 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts helm repo add stable https://burdenbear.github.io/kube-charts-mirror/ helm repo update...... 根据修改后的 yaml 重新创建 pod 12kubectl delete pod install-helm -n gitlab-managed-apps kubectl apply -f install-helm.yaml 删除 namespace 1kubectl delete namespaces gitlab-managed-apps 重新点击页面 Install 按钮 非 K8s 环境在 Docker 中部署 GitLab Runner运行 GitLab Runner 命令行 1234$ docker run -d --name gitlab-runner --restart always \ -v /path/to/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest docke-compose 123456789version: '3.7'services: gitlab-runner: image: gitlab/gitlab-runner:latest restart: always volumes: - ./gitlab-runner/config:/etc/gitlab-runner - /var/run/docker.sock:/var/run/docker.sock 注册 GitLab Runner 执行命令注册 123456789docker exec gitlab-runner gitlab-runner register -n \ --url https://gitlab.com/ \ --registration-token xxxxxxxxxx \ --executor docker \ --tag-list runInDk \ --description "My Docker Runner" \ --docker-image "docker:latest" \ --docker-volumes /var/run/docker.sock:/var/run/docker.sock \ --docker-volumes /root/.m2:/root/.m2 优化工作 Runner 默认情况下每执行一个 Job 都会重新拉取一次所需镜像，我们可把策略改为：镜像不存在时才拉取，编辑 config.toml 文件，修改 [runners.docker] 栏中加入 pull_policy = &quot;if-not-present&quot; 重启 Runner 容器，使之生效 编写项目的 gitlab-ci.yml 文件 后端项目 12345678910111213141516171819202122232425262728293031323334353637stages: - package - build - deploymy_package: image: maven:3.6.0-jdk-8-alpine stage: package script: - mvn clean package -DskipTests - cp Dockerfile target/Dockerfile cache: key: $&#123;CI_PIPELINE_ID&#125; paths: - target/ only: - master tags: - lvTestmy_build: stage: build cache: key: $&#123;CI_PIPELINE_ID&#125; paths: - target/ script: - cd target - docker build -t 192.168.88.4:5000/$&#123;CI_PROJECT_NAME&#125;:$&#123;CI_PIPELINE_ID&#125; . - docker push 192.168.88.4:5000/$&#123;CI_PROJECT_NAME&#125;:$&#123;CI_PIPELINE_ID&#125; tags: - lvTestmy_deploy: stage: deploy script: - docker stop lxwtest &amp;&amp; docker rm lxwtest - docker run -d -p 8888:8080 --restart=always --name=lxwtest 192.168.88.4:5000/$&#123;CI_PROJECT_NAME&#125;:$&#123;CI_PIPELINE_ID&#125; tags: - lvTest 前端项目]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 笔记]]></title>
    <url>%2F2019%2F06%2F08%2FEffective-Java-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1. 考虑使用静态工厂方法替代构造方法优点 通过方法名体现不同构造方式的差异 不需要每次调用时都创建一个新对象 ( 单例模式, 享元模式 ) 可以返回其返回类型的任何子类型的对象 在编写包含该方法的类时，返回的对象的类不需要存在 限制 没有公共或受保护构造方法的类不能被子类化 ( 因为大部分实现会将构造函数设为私有 ) 没有构造函数那么明显 2. 当构造方法参数过多时使用 builder 模式分析 可伸缩 (telescoping constructor) 构造方法模式, 多个不同参数数量的构造方法 当有很多参数时，很难编写代码，而且很难读懂它 JavaBeans 模式, 调用 setter 方法来设置参数 由于构造方法在多次调用中被分割，在过程中可能处于不一致的状态 Builder 模式, 构造方法为 private, 通过内嵌的 Builder 类调用 build() 返回本身 12NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100).sodium(35).carbohydrate(27).build(); 可以在 build() 里加入参数检查 编写简单, 易读 能区分必须和可选字段 平行层次的 Builder, 抽象类有抽象的 builder, 具体的类有具体的 builder 12345NyPizza pizza = new NyPizza.Builder(SMALL) .addTopping(SAUSAGE).addTopping(ONION).build();Calzone calzone = new Calzone.Builder() .addTopping(HAM).sauceInside().build(); 3. 使用私有构造方法或枚类实现 Singleton 属性私有构造方法 通过公共静态成员提供访问 123456// Singleton with public final fieldpublic class Elvis &#123; public static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public void leaveTheBuilding() &#123; ... &#125;&#125; 通过静态的工厂方法提供访问 优点: 可以灵活地改变你的想法 优点: 可以编写一个泛型单例工厂 优点: 方法引用可以用 Supplier 1234567 // Singleton with static factorypublic class Elvis &#123; private static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public static Elvis getInstance() &#123; return INSTANCE; &#125; public void leaveTheBuilding() &#123; ... &#125;&#125; 警告 可以使用 AccessibleObject.setAccessible 方法，以反射方式调用私有构造方法 为了维护单例的保证，声明所有的实例属性为 transient，并提供一个 readResolve 方法 枚举 声明单一元素的枚举类 简洁 提供了免费的序列化机制 提供了针对多个实例化的保证 12345// Enum singleton - the preferred approachpublic enum Elvis &#123; INSTANCE; public void leaveTheBuilding() &#123; ... &#125;&#125; 4. 使用私有构造方法执行非实例化 如一些工具类, 只包含静态方法, 可以用来避免其实例化和被继承 12345678// Noninstantiable utility classpublic class UtilityClass &#123; // Suppress default constructor for noninstantiability private UtilityClass() &#123; throw new AssertionError(); &#125; ... // Remainder omitted&#125; 5. 使用依赖注入取代硬连接资源(hardwiringresources) 不要使用单例或静态的实用类来实现一个类，该类依赖于一个或多个底层资源，这些资源的行为会影响类的行为，并且不让类直接创建这些资源。相反，将资源或工厂传递给构造方法 (或静态工厂或 builder 模式)。这种称为依赖注入的实践将极大地增强类的灵活性、可重用性和可测试性。 6. 避免创建不必要的对象 如果对象是不可变的，它总是可以被重用 注意无意识的自动装箱 (autoboxing) 在现代 JVM 实现上, 使用构造方法创建和回收小的对象其实是非常廉价的, 创建额外的对象以增强程序的清晰度，简单性或功能性通常是件好事 除非池中的对象非常重量级，否则通过维护自己的对象池来避免对象创建是一个坏主意 7. 消除过期的对象引用 当一个类自己管理内存时，程序员应该警惕内存泄漏问题 每当一个元素被释放时，元素中包含的任何对象引用都应该被清除 另一个常见的内存泄漏来源是缓存 只要在缓存之外存在对某个项 (entry) 的键 (key) 引用，那么这项就是明确有关联的，就可以用 WeakHashMap 来表示缓存 可以通过一个后台线程或将新的项添加到缓存时顺便清理 第三个常见的内存泄漏来源是监听器和其他回调 客户端注册回调, 仅将它们保存在 WeakHashMap 的键 (key) 中 8. 避免使用 Finalizer 和 Cleaner 机制缺点 不能保证他们能够及时执行 不要相信 System.gc 和 System.runFinalization 方法, 可能会增加被执行的几率，但不能保证一定会执行 在执行 Finalizer 机制过程中，未捕获的异常会被忽略 导致严重的性能损失 严重的安全问题: 它们会打开你的类来进行 Finalizer 机制攻击 正确做法 实现 AutoCloseable 接口，并要求客户在不再需要时调用每个实例 close 方法，通常使用 try-with-resources 确保终止 合法用途 作为一个安全网 (safetynet)，以防资源的拥有者忽略了它的 close 方法 与本地对等类(native peers)有关。本地对等类是一个由普通对象委托的本地 (非 Java) 对象。由于本地对等类不是普通的 Java 对象，所以垃圾收集器并不知道它，当它的 Java 对等对象被回收时，本地对等类也不会回收。 9. 使用 try-with-resources 语句替代 try-finally 语句对比 try-finally 12345678910111213141516// try-finally is ugly when used with more than one resource!static void copy(String src, String dst) throws IOException &#123; InputStream in = new FileInputStream(src); try &#123; OutputStream out = new FileOutputStream(dst); try &#123; byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); &#125; finally &#123; out.close(); &#125; &#125; finally &#123; in.close();&#125; &#125; try-with-resources 12345678// try-with-resources on multiple resources - short and sweetstatic void copy(String src, String dst) throws IOException &#123; try (InputStream in = new FileInputStream(src); OutputStream out = new FileOutputStream(dst)) &#123; byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0)&#125; &#125; 分析 用 try-finally 语句关闭资源, 有多个资源时容易犯错 try-with-resources 块和 finally 块中的代码都可能抛出异常 finally 块中close()时抛出的异常会冲掉前面的异常 try-with-resources 块中close()(不可见) 时抛出的异常会被抑制 (suppressed), 这些抑制的异常没 有被抛弃， 而是打印在堆栈跟踪中，并标注为被抑制了 10. 重写 equals 方法时遵守通用约定不覆盖 equals 方法的场景 每个类的实例都是固有唯一的 类不需要提供一个“逻辑相等(logical equality)”的测试功能 父类已经重写了 equals 方法，则父类行为完全适合于该子类 类是私有的或包级私有的 覆盖 equals 方法的场景 需要提供一个逻辑相等的判断, 且父类还没重写过equals 通用约定 自反性 (Reflexivity): 对于任何非空引用 x， x.equals(x) 必须返回 true 对称性 (Symmetry): 对于任何非空引用 x 和 y，如果且仅当 y.equals(x) == true, x.equals(y)必须为 true 传递性 (Transitivity): 对于任何非空引用 x、y、z，如果 x.equals(y) == true, y.equals(z) == true, 则x.equals(z)必须返回 true 一致性 (Consistent): 对于任何非空引用 x 和 y，如果在 equals 比较中使用的信息没有修改，则x.equals(y)的多次调用必须始终返回 true 或始终返回 false 非空性 (Non-nullity): 对于任何非空引用 x, x.equals(null) 必须返回 false 编写高质量 equals 方法 使用 instanceof 运算符来检查参数是否具有正确的类型, 再将参数转换为正确的类型 检查是否与类中的每个重要属性相匹配 不同类型的比较方式 对于类型为非 float 或 double 的基本类型，使用 == 运算符进行比较 对于对象引用属性，递归地调用 equals 方法 对于 float 基本类型的属性，使用静态方法 Float.compare(float, float) 对于 double 基本类型的属性，使用静态方法 Double.compare(double, double) 对于数组属性，将这些准则应用于每个元素 某些对象引用的属性可能合法地包含 null。 为避免出现 NullPointerException 异常，请使用静态方法Objects.equals(Object, Object) 检查这些属性是否相等 性能优化 用 == 运算符检查参数是否为该对象的引用, 如果是, 返回 true 首先比较最可能不同的属性, 开销比较小的属性 不要比较不属于对象逻辑状态的属性 不需要比较可以从“重要属性”计算出来的派生属性 注意 当重写 equals 方法时，同时也要重写 hashCode 方法 不要让 equals 方法试图太聪明, 例如File 类不应该试图将引用的符号链接等同于同一文件对象 在 equal 时方法声明中，不要将参数 Object 替换成其他类型 11. 重写 equals 方法时同时也要重写 hashcode 方法Object 规范 当在一个应用程序执行过程中，如果在 equals 方法比较中没有修改任何信息，在一个对象上重复调用 hashCode 方法时，它必须始终返回相同的值。从一个应用程序到另一个应用程序的每一次执行返回的值可以是不一致的。 如果两个对象根据 equals(Object) 方法比较是相等的，那么在两个对象上调用 hashCode 就必须产生的结果是相同的整数。 如果两个对象根据 equals(Object) 方法比较并不相等，则不要求在每个对象上调用 hashCode 都必须产生不同的结果。 但是，程序员应该意识到，为不相等的对象生成不同的结果可能会提高散列表(hash tables)的性能。 一个简单的配方12345678// Typical hashCode method@Overridepublic int hashCode() &#123; int result = Short.hashCode(areaCode); result = 31 * result + Short.hashCode(prefix); result = 31 * result + Short.hashCode(lineNum); return result;&#125; 基本类型，使用 Type.hashCode(f) 方法计算，其中 Type 类是对应属性 f 基本类型的包装类。 如果该属性是一个对象引用，并且该类的 equals 方法通过递归调用 equals 来比较该属性，并递归地调用 hashCode 方法。 如果需要更复杂的比较，则计算此字段的“范式(“canonical representation)”，并在范式上调用 hashCode。 如果该字段的值为空，则使用 0(也可以使用其他常数，但通常来使用 0 表示)。 如果属性 f 是一个数组，把它看作每个重要的元素都是一个独立的属性。 也就是说，通过递归地应用 这些规则计算每个重要元素的哈希码，并且将每个步骤的值合并。 如果数组没有重要的元素，则使用一个常量，最好不要为 0。如果所有元素都很重要，则使用 Arrays.hashCode 方法。 12. 始终重写 toString 方法 便于调试 13. 谨慎地重写 clone 方法缺陷 Cloneable 接口缺少 clone 方法, 而 Object 的 clone 方法是受保护的, 所以不能保证调用成功 clone 方法的通用规范 ( 非绝对 ) x.clone() != x x.clone().getClass() == x.getClass() x.clone().equals(x) == true 如果一个 final 类有一个不调用 super.clone 的 clone 方法, 那么这个类没有理由实现 Cloneable 接口，因为它不依赖于 Object 的 clone 实现的行为 复制构造方法及其静态工厂变体与 Cloneable/clone 相比有许多优点 不依赖风险很大的语言外的对象创建机制 不要求遵守那些不太明确的惯例 不会与 final 属性的正确使用相冲突 不会抛出不必要的检查异常 不需要类型转换 14. 考虑实现 Comparable 接口 如果你正在编写具有明显自然顺序(如字母顺序，数字顺序或时间顺序)的值类，则应该实现 Comparable 接口: 123public interface Comparable&lt;T&gt; &#123; int compareTo(T t);&#125; compareTo 方法的通用约定 将此对象与指定的对象按照排序进行比较, 返回值可能为负整数, 零或正整数, 因为此对象对应小于，等于或大于指定的对象。 如果指定对象的类型与此对象不能进行比较，则引发 ClassCastException 异常 实现类必须确保所有 x 和 y 都满足 sgn(x.compareTo(y)) == -sgn(y. compareTo(x))。 （这意味着 当且仅当 y.compareTo(x) 抛出异常时， x.compareTo(y) 必须抛出异常。） 实现类还必须确保该关系是可传递的：(x. compareTo(y) &gt; 0 &amp;&amp; y.compareTo(z) &gt; 0) 意味着x.compareTo(z) &gt; 0 。 对于所有的 z，实现类必须确保 x.compareTo(y) == 0 意味着 sgn(x.compareTo(z)) == sgn(y.compareTo(z)) 。 推荐 (x.compareTo(y) == 0) == (x.equals(y)) ，但不是必需的。 一般来说，任何实现了 Comparable 接口的类违反了这个条件都应该清楚地说明这个事实。 推荐的语言是 “注意：这个类有一个自然顺序，与 equals 不一致”。 使用包装类中的静态 compare 方法或 Comparator 接口中的构建方法 12345678910// Comparator based on static compare methodstatic Comparator&lt;Object&gt; hashCodeOrder = new Comparator&lt;&gt;() &#123; public int compare(Object o1, Object o2) &#123; return Integer.compare(o1.hashCode(), o2.hashCode()); &#125;&#125;;// Comparator based on Comparator construction methodstatic Comparator&lt;Object&gt; hashCodeOrder = Comparator.comparingInt(o -&gt; o.hashCode()); 请避免使用 “&lt;” 和 “&gt;” 运算符 15. 使类和成员的可访问性最小化 使用尽可能低的访问级别 类具有公共静态 final 数组属性，或返回这样一个属性的访问器是错误的 12// Potential security hole!public static final Thing[] VALUES = &#123; ... &#125;; 有两种方法可以解决这个问题 你可以使公共数组私有并添加一个公共的不可变列表： 123private static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final List&lt;Thing&gt; VALUES = Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES)); 可以将数组设置为 private，并添加一个返回私有数组拷贝的公共方法： 1234private static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final Thing[] values() &#123; return PRIVATE_VALUES.clone();&#125; 16. 在公共类中使用访问方法而不是公共属性 如果一个类在其包之外是可访问的，则提供访问方法来保留更 改类内部表示的灵活性 如果一个类是包级私有的，或者是一个私有的内部类，那么暴露它的数据属性就没有什么本质上的错误 17. 最小化可变性要使一个类不可变，请遵循以下五条规则 不要提供修改对象状态的方法（也称为 mutators） 确保这个类不能被继承 把所有属性设置为 final 把所有的属性设置为 private 确保对任何可变组件的互斥访问 ( 确保该类的客户端无法获得对这些对象的引用 ) 不可变对象本质上是线程安全的 不需要也不应该在一个不可变的类上提供一个 clone 方法或拷贝构造方法（copy constructor） 一个不可变的类可以提供静态的工厂来缓存经常被请求的实例 一个类不得允许子类化, 可以设置类为 final , 更灵活的方式是使其所有的构造方法私有或包级私有，并添加公共静态工厂，而不是公共构造方法 如果一个类不能设计为不可变类，那么也要尽可能地限制它的可变性 18. 组合优于继承 与方法调用不同，继承打破了封装 , 父类的实现可能会不断变化, 子类可能会被破坏，即使它的代码没有任何改变 包装类 ( 装饰器模式 ) 有时组合和转发的结合被不精确地地称为委托 (delegation). 从技术上讲，除非包装对象把自身传递给被包装对象，否则不是委托 包装类的缺点 包装类不适合在回调框架（callback frameworks）中使用，其中对象将自我引用传递给其他对象以用于后续调用（“回调”） 编写转发方法有些繁琐 只有在子类真的是父类的子类型的情况下，继承才是合适的 19. 如使用继承则设计，应当文档说明，否则不该使用 这个类必须准确地描述重写这个方法带来的影响 测试为继承而设计的类的唯一方法是编写子类, 经验表明，三个子类通常足以测试一个可继承的类。 这些子类应该由父类作者以外的人编写 构造方法绝不能直接或间接调用可重写的方法 如果你决定在为继承而设计的类中实现 Cloneable 或 Serializable 接口, 那么 clone 和 readObject 都不会直接或间接调用可重写的方法 20. 接口优于抽象类 Java 只允许单一继承 接口是定义混合类型（mixin）的理想选择, 允许构建非层级类型的框架 可以通过提供一个抽象的骨架实现类（abstract skeletal implementation class）来与接口一起使用，将接口和抽象类的优点结合起来。 接口定义了类型，可能提供了一些默认的方法，而骨架实现类在原始接口方法的顶层实现了剩余的非原始接口方法。 继承骨架实现需要大部分的工作来实现一个接口。 这就是模板方法设计模式 21. 为后代设计接口 编写一个默认方法并不总是可能的，它保留了每个可能的实现的所有不变量 在默认方法的情况下，接口的现有实现类可以在没有错误或警告的情况下编译，但在运行时会失败 22. 接口仅用来定义类型 常量接口模式是对接口的糟糕使用 23. 优先使用类层次而不是标签类24. 优先考虑静态成员类 非静态成员类的每个实例都隐含地与其包含的类的宿主实例相关联, 可以调用宿主实例上的方法, 不可能在没有宿主实例的情况下创建非静态成员类的实例 非静态成员类的一个常见用法 1234567891011// Typical use of a nonstatic member classpublic class MySet&lt;E&gt; extends AbstractSet&lt;E&gt; &#123; ... // Bulk of the class omitted @Override public Iterator&lt;E&gt; iterator() &#123; return new MyIterator(); &#125; private class MyIterator implements Iterator&lt;E&gt; &#123; ... &#125;&#125; 如果你声明了一个不需要访问宿主实例的成员类，总是把 static 修饰符放在它的声明中，使它成为一个静态成员类，而不是非静态的成员类 有四种不同的嵌套类，每个都有它的用途。 如果一个嵌套的类需要在一个方法之外可见，或者太长而不能很好地适应一个方法，使用一个成员类。 如果一个成员类的每个实例都需要一个对其宿主实例的引用，使其成为非静态的; 否则，使其静态。 假设这个类属于一个方法内部，如果你只需要从一个地方创建实例，并且存在一个预置类型来说明这个类的特征，那么把它作为一个匿名类; 否则，把它变成局部类。 25. 将源文件限制为单个顶级类26. 不要使用原始类型 如果你使用原始类型，则会丧失泛型的所有安全性和表达上的优势 以下是使用泛型类型的 instanceof 运算符的首选方法 12345// Legitimate use of raw type - instanceof operatorif (o instanceof Set) &#123; // Raw type Set&lt;?&gt; s = (Set&lt;?&gt;) o; // Wildcard type ...&#125; 27. 消除非检查警告 尽可能 地消除每一个未经检查的警告 如果你不能消除警告，但你可以证明引发警告的代码是类型安全的，那么（并且只能这样）用@SuppressWarnings(“unchecked”) 注解来抑制警告 每当使用 @SuppressWarnings(“unchecked”) 注解时，请添加注释，说明为什么是安全的 28. 列表优于数组29. 优先考虑泛型30. 优先使用泛型方法31. 使用限定通配符来增加 API 的灵活性12345// pushAll method without wildcard type - deficient!public void pushAll(Iterable&lt;E&gt; src) &#123; for (E e : src) push(e);&#125; 假设有一个 Stack&lt;Number&gt;，并调用 push(intVal)，其中 intVal 的类型是 Integer, 会得到错误消息 12345// Wildcard type for a parameter that serves as an E producerpublic void pushAll(Iterable&lt;? extends E&gt; src) &#123; for (E e : src) push(e);&#125; 为了获得最大的灵活性，对代表生产者或消费者的输入参数使用通配符类型 producer-extends, consumer-super（PECS） 如果一个参数化类型代表一个 T 生产者，使用 &lt;? extends T&gt; 如果它代表 T 消费者，则使用 &lt;? super T&gt; 改造 max 方法 123public static &lt;T extends Comparable&lt;T&gt;&gt; T max(List&lt;T&gt; list)public static &lt;T extends Comparable&lt;? super T&gt;&gt; T max(List&lt;? extends T&gt; list) max 方法返回 T , 所以 List&lt;? extends T&gt; list Comparable 的 T 消费 T 实例（并生成指示顺序关系的整数）, 所以 &lt;T extends Comparable&lt;? super T&gt;&gt; 32. 合理地结合泛型和可变参数 在 Java 7 中， @SafeVarargs 注解已添加到平台，以允许具有泛型可变参数的方法的作者自动禁止客户端警 告 如果可变参数数组仅用于从调用者向方法传递可变数量的参数, 那么该方法是安全的 33. 优先考虑类型安全的异构容器]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>effective-java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 关键字 transient]]></title>
    <url>%2F2019%2F05%2F31%2FJava-%E5%85%B3%E9%94%AE%E5%AD%97-transient%2F</url>
    <content type="text"><![CDATA[transient 一旦变量被 transient 修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 transient 关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被 transient 关键字修饰的。变量如果是用户自定义类变量，则该类需要实现 Serializable 接口。 一个静态变量不管是否被 transient 修饰，均不能被序列化。 参考: https://www.cnblogs.com/lanxuezaipiao/p/3369962.html]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串池、常量池（运行时常量池、Class常量池）、intern]]></title>
    <url>%2F2019%2F05%2F30%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%B1%A0%E3%80%81%E5%B8%B8%E9%87%8F%E6%B1%A0%EF%BC%88%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%E3%80%81Class%E5%B8%B8%E9%87%8F%E6%B1%A0%EF%BC%89%E3%80%81intern%2F</url>
    <content type="text"><![CDATA[重点： Class 常量池 是编译期生成的 .class 文件中的常量池 运行时常量池 是 Class 常量池 在运行时的表示形式 字符串常量池 是缓存字符串的，全局共享，它保存的是 String 实例对象的引用 Class 常量池 常量池中主要存放两大类常量：字面量（Literal） 和 符号引用（Symbolic Reference），字面量比较接近于 Java 语言层面的常量概念，如文本字符串 、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念，包括了下面三类常量： 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 通过 javap 命令可以看到 .class 文件的常量池部分。 运行时常量池 运行时常量池（Runtime Constant Pool）是方法区的一部分，它是 Class 文件中每一个类或接口的常量池表的运行时表示形式。Class 常量池中存放的编译期生成的各种字面量和符号引用，将在类加载后进入方法区的运行时常量池中存放。 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态常量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆）。目的应该是与 Java 堆区分开来。 字符串常量池 字符串常量池是用来缓存字符串的。对于需要重复使用的字符串，每次都去 new 一个 String 实例，无疑是在浪费资源，降低效率。所以，JVM 一般会维护一个字符串常量池，它是全局共享的，你可是把它看成是一个 HashSet&lt;String&gt;。需要注意的是，它保存的是堆中字符串实例的引用，并不存储实例本身。 在 JDK 1.6, 常量池是在永久代中的，和 Java 堆是完全分开来的区域 在 JDK 1.7, 常量池在堆中 String.intern() 查找当前字符串常量池是否存在该字符串的引用，如果存在直接返回引用；如果不存在，则在堆中创建该字符串实例，并返回其引用。]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>string</tag>
      </tags>
  </entry>
</search>
