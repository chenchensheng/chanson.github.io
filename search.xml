<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java 线程与线程池]]></title>
    <url>%2F2020%2F05%2F20%2FJava-%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[Java 线程与线程池线程的状态 NEW，新建状态，线程被创建出来，但尚未启动时的线程状态 RUNNABLE，就绪状态，表示可以运行的线程状态，它可能正在运行，或者是在排队等待操作系统给它分配 CPU 资源 BLOCKED，阻塞等待锁的线程状态，表示处于阻塞状态的线程正在等待监视器锁，比如等待执行 synchronized 代码块或者使用 synchronized 标记的方法 WAITING，等待状态，一个处于等待状态的线程正在等待另一个线程执行某个特定的动作，比如，一个线程调用了 Object.wait() 方法，那它就在等待另一个线程调用 Object.notify() 或 Object.notifyAll() 方法 TIMED_WAITING，计时等待状态，和 WAITING 类似，它只是多了超时时间，比如调用了有超时时间设置的方法 Object.wait(long timeout) 和 Thread.join(long timeout) 等这些方法时，它才会进入此状态 TERMINATED，终止状态，表示线程已经执行完成 关于 Object.wait/notify相关代码12345678910111213141516171819202122232425262728293031323334353637383940public class WaitNotifyCase &#123; public static void main(String[] args) &#123; final Object lock = new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("thread A is waiting to get lock"); synchronized (lock) &#123; try &#123; System.out.println("thread A get lock"); TimeUnit.SECONDS.sleep(1); System.out.println("thread A do wait method"); lock.wait(); System.out.println("wait end"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("thread B is waiting to get lock"); synchronized (lock) &#123; System.out.println("thread B get lock"); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.notify(); System.out.println("thread B do notify method"); &#125; &#125; &#125;).start(); &#125;&#125; 执行结果1234567thread A is waiting to get lockthread A get lockthread B is waiting to get lockthread A do wait methodthread B get lockthread B do notify methodwait end 疑问 进入 wait/notify 方法之前，为什么要获取 synchronized 锁？ 线程 A 获取了 synchronized 锁，执行 wait 方法并挂起，线程 B 又如何再次获取锁？ 分析 synchronized 代码块通过 javap 生成的字节码中包含 monitorenter 和 monitorexit 指令, 执行 monitorenter 指令可以获取对象的 monitor , 在 wait() 接口注释中有标明 The current thread must own this object&#39;s monitor , 所以通过 synchronized 该线程持有了对象的 monitor 的情况下才能调用对象的 wait() 方法 wait() 接口注释中还提到调用 wait() 后该线程会释放持有的 monitor 进入等待状态直到被唤醒, 被唤醒的线程还要等到能重新持有 monitor 才会继续执行 线程状态变化: 调用 wait(): RUNNABLE -&gt; WAITING 调用 notify: WAITING -&gt; BLOCKED -&gt; RUNNABLE WAITING -&gt; RUNNABLE 具体看 JVM 实现和策略配置 深入: 什么是 monitor 在 HotSpot 虚拟机中 (1.7 版本)，monitor 采用 ObjectMonitor 实现 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; // 用来记录该线程获取锁的次数 _waiters = 0, _recursions = 0; // 锁的重入次数 _object = NULL; // 对应的对象 _owner = NULL; // 指向持有 ObjectMonitor 对象的线程 _WaitSet = NULL; // 处于 WAITING 状态的线程，会被加入到 _WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; // 竞争锁的线程都会先通过互斥同步或 CAS 操作进入 cxq，队首的对象会进入到 EntryList 中，进行 tryLock 操作 FreeNext = NULL ; _EntryList = NULL ; // 处于 BLOCKED 状态的线程，会被加入到 _EntryList _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;&#125; 每个线程都有两个 ObjectMonitor 对象列表，分别为 free 和 used 列表，如果当前 free 列表为空，线程将向全局 global ListLock 请求分配 ObjectMonitor ObjectMonitor 对象中有两个队列：_WaitSet 和 _EntryList，用来保存 ObjectWaiter 对象列表；_owner 指向获得 ObjectMonitor 对象的线程 每个等待锁的线程都会被封装成 ObjectWaiter 对象 ObjectWaiter 对象是双向链表结构，保存了_thread（当前线程）以及当前的状态 TState等数据 ObjectMonitor 获得锁是通过 void ATTR enter(TRAPS); 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void ATTR ObjectMonitor::enter(TRAPS) &#123; Thread * const Self = THREAD ; void * cur ; // 通过 CAS 尝试把 monitor 的 _owner 设置为当前线程 cur = Atomic::cmpxchg_ptr (Self, &amp;_owner, NULL) ; // 获取锁失败 if (cur == NULL) &#123; assert (_recursions == 0 , "invariant") ; assert (_owner == Self, "invariant") ; // CONSIDER: set or assert OwnerIsThread == 1 return ; &#125; // 如果旧值和当前线程一样，说明当前线程已经持有锁，此次为重入，_recursions 自增即可 if (cur == Self) &#123; // TODO-FIXME: check for integer overflow! BUGID 6557169. _recursions ++ ; return ; &#125; // 如果当前线程是第一次进入该 monitor，设置 _recursions 为 1，_owner 为当前线程 if (Self-&gt;is_lock_owned ((address)cur)) &#123; assert (_recursions == 0, "internal state error"); _recursions = 1 ; // Commute owner from a thread-specific on-stack BasicLockObject address to // a full-fledged "Thread *". _owner = Self ; OwnerIsThread = 1 ; return ; &#125; // 省略部分代码。 // 通过自旋执行 ObjectMonitor::EnterI 方法等待锁的释放 for (;;) &#123; jt-&gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() // or java_suspend_self() EnterI (THREAD) ; if (!ExitSuspendEquivalent(jt)) break ; // We have acquired the contended monitor, but while we were // waiting another thread suspended us. We don't want to enter // the monitor while suspended because that would surprise the // thread that suspended us. // _recursions = 0 ; _succ = NULL ; exit (Self) ; jt-&gt;java_suspend_self(); &#125;&#125; ObjectMonitor 释放锁是通过 void ATTR exit(TRAPS); 方法 123456789101112131415161718192021222324252627282930313233void ATTR ObjectMonitor::exit(TRAPS) &#123; Thread * Self = THREAD ; // 如果当前线程不是 Monitor 的所有者 if (THREAD != _owner) &#123; if (THREAD-&gt;is_lock_owned((address) _owner)) &#123; // Transmute _owner from a BasicLock pointer to a Thread address. // We don't need to hold _mutex for this transition. // Non-null to Non-null is safe as long as all readers can // tolerate either flavor. assert (_recursions == 0, "invariant") ; _owner = THREAD ; _recursions = 0 ; OwnerIsThread = 1 ; &#125; else &#123; // NOTE: we need to handle unbalanced monitor enter/exit // in native code by throwing an exception. // TODO: Throw an IllegalMonitorStateException ? TEVENT (Exit - Throw IMSX) ; assert(false, "Non-balanced monitor enter/exit!"); if (false) &#123; THROW(vmSymbols::java_lang_IllegalMonitorStateException()); &#125; return; &#125; &#125; // 如果 _recursions 次数不为 0.自减 if (_recursions != 0) &#123; _recursions--; // this is simple recursive enter TEVENT (Inflated exit - recursive) ; return ; &#125; // 省略部分代码，根据不同的策略（由 QMode 指定），从 cxq 或 EntryList 中获取头节点，通过ObjectMonitor::ExitEpilog 方法唤醒该节点封装的线程，唤醒操作最终由 unpark 完成。 lock.wait() 方法最终通过 ObjectMonitor 的 void wait(jlong millis, bool interruptable, TRAPS); 实现: 将当前线程封装成 ObjectWaiter 对象 node 通过 ObjectMonitor::AddWaiter 方法将 node 添加到 _WaitSet 列表中 通过 ObjectMonitor::exit 方法释放当前的 ObjectMonitor 对象，这样其它竞争线程就可以获取该 ObjectMonitor 对象 最终底层的 park 方法会挂起线程 lock.notify() 方法最终通过 ObjectMonitor 的 void notify(TRAPS) 实现: 如果当前 _WaitSet 为空，即没有正在等待的线程，则直接返回 通过 ObjectMonitor::DequeueWaiter 方法，获取 _WaitSet 列表中的第一个 ObjectWaiter节点 根据不同的策略，将取出来的 ObjectWaiter 节点加入到 _EntryList 或则通过Atomic::cmpxchg_ptr 指令进行自旋操作 _cxq 相关问题1. BLOCKED（阻塞等待）和 WAITING（等待）有什么区别？ 状态形成的调用方法不同 BLOCKED 可以理解为当前线程还处于活跃状态，只是在阻塞等待其他线程使用完某个锁资源 WAITING 则是因为自身调用了 Object.wait() 或着是 Thread.join() 又或者是 LockSupport.park() 而进入等待状态，只能等待其他线程执行某个特定的动作才能被继续唤醒，比如当线程因为调用了 Object.wait() 而进入 WAITING 状态之后，则需要等待另一个线程执行 Object.notify() 或 Object.notifyAll() 才能被唤醒 2. start() 方法和 run() 方法有什么区别？ 12345678910111213141516171819202122public synchronized void start() &#123; // 状态验证，不等于 NEW 的状态会抛出异常 if (threadStatus != 0) throw new IllegalThreadStateException(); // 通知线程组，此线程即将启动 group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; // 通知线程组，此线程启动失败 group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; // 不处理任何异常，如果 start0 抛出异常，则它将被传递到调用堆栈上 &#125; &#125;&#125; start() 方法属于 Thread 自身的方法，并且使用了 synchronized 来保证线程安全 run() 方法为 Runnable 的抽象方法，重写的 run() 方法其实就是此线程要执行的业务方法 调用 start() 方法是另起线程来运行 run() 方法中的内容 3. 线程的优先级有什么用？该如何设置？ 在 Thread 源码中和线程优先级相关的属性有 3 个 12345678// 线程可以拥有的最小优先级public final static int MIN_PRIORITY = 1;// 线程默认优先级public final static int NORM_PRIORITY = 5;// 线程可以拥有的最大优先级public final static int MAX_PRIORITY = 10 线程的优先级可以理解为线程抢占 CPU 时间片的概率，优先级越高的线程优先执行的概率就越大，但并不能保证优先级高的线程一定先执行 在程序中我们可以通过 Thread.setPriority() 来设置优先级 12345678910111213141516public final void setPriority(int newPriority) &#123; ThreadGroup g; // 检查当前线程是否有权限修改优先级 checkAccess(); // 先验证优先级的合理性 if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; if((g = getThreadGroup()) != null) &#123; // 优先级如果超过线程组的最高优先级，则把优先级设置为线程组的最高优先级 if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125;&#125; 4. 线程的常用方法有哪些？ sleep Thread.sleep() 让线程进入到 TIMED_WAITING 状态，并停止占用 CPU 资源，但是不释放持有的 monitor ，直到规定事件后再执行，休眠期间如果被中断，会抛出异常并清除中断状态 TimeUnit.SECONDS.sleep() 比 Thread.sleep() 多了非负数判断 join 123456789101112131415161718192021222324public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 本质是用 wait() 实现 JVM 的 Thread 执行完毕会自动执行一次 notifyAll() 所以不建议在程序中对 Thread 对象调用 wait/notify, 可能会造成干扰 yield A hint to the scheduler that the current thread is willing to yield its current use of a processor. The scheduler is free to ignore this hint. 状态依旧是 RUNNABLE, 不保证释放 CPU 资源 Thread.sleep(0) 可以重新触发 CPU 的竞争, 而 yield 不一定 interrupt 通知线程停止, 而不是强制停止, 线程可以进行停止前的释放资源, 完成必要的处理任务 在线程内可通过 isInterrupted() 判断终端并进行相应处理 若线程处于等待或堵塞状态, 则会抛出 InterruptedException 5. 被弃用的方法有哪些? 为什么被弃用? suspend 使线程暂停，但不会释放 monitor, 所以很容易造成死锁 resume 恢复通过调用 suspend() 方法而停止运行的线程 stop 强制停止当前线程, 会释放该线程所持有对象的 monitor，因而可能造成这些对象处于不一致的状态，而且这个方法造成的 ThreadDeath 异常不像其他的检查期异常一样被捕获 线程池 ( ThreadPoolExecutor) 线程池是为了避免线程频繁的创建和销毁带来的性能消耗，而建立的一种池化技术，它是把已创建的线程放入“池”中，当有任务来临时就可以重用已有的线程，无需等待创建的过程，这样就可以有效提高程序的响应速度 构造函数 12345678910public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ......&#125; corePoolSize 表示线程池的常驻核心线程数。如果设置为 0，则表示在没有任何任务时，销毁线程池；如果大于 0，即使没有任务时也会保证线程池的线程数量等于此值。但需要注意，此值如果设置的比较小，则会频繁的创建和销毁线程（创建和销毁的原因会在本课时的下半部分讲到）；如果设置的比较大，则会浪费系统资源，所以开发者需要根据自己的实际业务来调整此值 maximumPoolSize 表示线程池在任务最多时，最大可以创建的线程数。官方规定此值必须大于 0，也必须大于等于 corePoolSize，此值只有在任务比较多，且不能存放在任务队列时，才会用到 keepAliveTime 表示线程的存活时间，当线程池空闲时并且超过了此时间，多余的线程就会销毁，直到线程池中的线程数量销毁的等于 corePoolSize 为止，如果 maximumPoolSize 等于 corePoolSize，那么线程池在空闲的时候也不会销毁任何线程 unit 表示存活时间的单位，它是配合 keepAliveTime 参数共同使用的 workQueue 表示线程池执行的任务队列，当线程池的所有线程都在处理任务时，如果来了新任务就会缓存到此任务队列中排队等待执行 threadFactory 表示线程的创建工厂，此参数一般用的比较少，我们通常在创建线程池时不指定此参数，它会使用默认的线程创建工厂的方法来创建线程: 123456789101112131415161718192021222324252627// 默认的线程创建工厂，需要实现 ThreadFactory 接口static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = "pool-" + poolNumber.getAndIncrement() + "-thread-"; &#125; // 创建线程 public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); // 创建一个非守护线程 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); // 线程优先级设置为默认值 return t; &#125;&#125; 我们也可以自定义一个线程工厂，通过实现 ThreadFactory 接口来完成，这样就可以自定义线程的名称或线程执行的优先级了 RejectedExecutionHandler 表示指定线程池的拒绝策略，当线程池的任务已经在缓存队列 workQueue 中存储满了之后，并且不能创建新的线程来执行此任务时，就会用到此拒绝策略，它属于一种限流保护的机制 ctl 123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 用一个 AtomicInteger 包装两个字段: 高 3 位保存 runState，低 29 位保存 workerCount 用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源 workerCount: 有效线程数 runState: 线程池的运行状态 定义 RUNNING: 接受新任务并处理排队的任务 SHUTDOWN: 拒绝接受新任务, 但是会处理还在排队的任务 STOP: 拒绝接受新任务, 也不处理排队中任务, 并且会中断正在执行的任务 TIDYING: 所有任务都已经停止, workerCount 为 0, 转换为状态 TIDYING 的线程将运行 terminated() 方法 TERMINATED: terminated() 执行完毕 这些值之间的数字顺序很重要，可以进行有序的比较 runState 随着时间逐步增加，但不一定达到每个状态, 过渡的顺序为: RUNNING -&gt; SHUTDOWN, 在调用 shutdown() 时，可能隐藏在 finalize() 中调用 (RUNNING or SHUTDOWN) -&gt; STOP, 在调用 shutdownNow() 时 SHUTDOWN -&gt; TIDYING, 当队列和池子内的任务都为空时 STOP -&gt; TIDYING, 当池子内的任务为空时 TIDYING -&gt; TERMINATED, 当 terminated() 执行完毕时 线程在 awaitTermination() 中等待, 将在状态变为 TERMINATED 时返回 线程池工作流程 通过 execute() 执行任务123456789101112131415161718192021222324252627public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前工作的线程数小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; // 创建新的线程执行此任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 检查线程池是否处于运行状态，如果是则把任务添加到队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次检查线程池是否处于运行状态，防止在第一次校验通过后线程池关闭 // 如果是非运行状态，则将刚加入队列的任务移除 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果线程池的线程数为 0 时（当 corePoolSize 设置为 0 时会发生） else if (workerCountOf(recheck) == 0) addWorker(null, false); // 新建线程执行任务 &#125; // 核心线程都在忙且队列都已爆满，尝试新启动一个线程执行失败 else if (!addWorker(command, false)) // 执行拒绝策略 reject(command);&#125; addWorker(Runnable firstTask, boolean core) 方法 firstTask，线程应首先运行的任务，如果没有则可以设置为 null core，判断是否可以创建线程的阀值（最大值），如果等于 true 则表示使用 corePoolSize 作为阀值，false 则表示使用 maximumPoolSize 作为阀值 Worker构造函数 123456789101112private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; final Thread thread; // Worker 持有的线程 Runnable firstTask; // 初始化的任务，可以为 null Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; ......&#125; 执行任务流程 继承 AQS 原因分析Worker 是通过继承 AQS，使用 AQS 来实现独占锁这个功能。没有使用可重入锁 ReentrantLock，而是使用 AQS，为的就是实现不可重入的特性去反应线程现在的执行状态 lock 方法一旦获取了独占锁，表示当前线程正在执行任务中 如果正在执行任务，则不应该中断线程 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断 线程池在执行 shutdown 方法或 tryTerminate 方法时会调用 interruptIdleWorkers 方法来中断空闲的线程，interruptIdleWorkers 方法会使用 tryLock 方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收 之所以设置为不可重入，是因为我们不希望任务在调用像 setCorePoolSize 这样的线程池控制方法时重新获取锁。如果使用 ReentrantLock，它是可重入的，这样如果在任务中调用了如 setCorePoolSize 这类线程池控制的方法，会中断正在运行的线程 此外，在构造方法中执行了setState(-1);，把 state 变量设置为 -1，是因为 AQS 默认的 state 是0，如果刚创建了一个 Worker 对象，还没有执行任务时，这时就不应该被中断： 12345678910111213protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false;&#125;protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true;&#125; tryAcquire 方法是根据 state 是否是 0 来判断的，所以，setState(-1); 将 state 设置为 -1 是为了禁止在执行任务前对线程进行中断 在 runWorker 方法中会先调用 Worker 对象的 unlock 方法将 state 设置为 0, 允许中断和 lock 相关参数1234567891011121314// 用于操作 workers private final ReentrantLock mainLock = new ReentrantLock();// 持有线程的引用, 管理线程的生命周期private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();// 用于通知线程private final Condition termination = mainLock.newCondition();// 线程池曾经创建过的最大线程数量private int largestPoolSize;// 线程池已经执行的和未执行的任务总数private long completedTaskCount; 为什么workers 不采用线程安全的集合 ? 有些复合的操作，比如说将 worker 添加到 workers 后还需要判断是否需要更新 largestPoolSize 等，workers 只在获取到 mainLock 的情况下才会进行读写 mainLock 也用于在中断线程的时候串行执行，否则可能会并发进行线程中断，引起不必要的中断高峰 addWorker : 增加工作线程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); if (rs &gt;= SHUTDOWN &amp;&amp; // 线程池是否已停止 ! (rs == SHUTDOWN &amp;&amp; // 线程池是否正在停止 firstTask == null &amp;&amp; ! workQueue.isEmpty()) // 线程是否用于执行剩余任务 ) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || // 线程数是否超过容量 wc &gt;= (core ? corePoolSize : maximumPoolSize)) // 是否超过判断的阀值 return false; if (compareAndIncrementWorkerCount(c)) // CAS 尝试登记线程数 break retry; // 登记成功 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) // 判断线程池状态运行过程中是否有改变 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); // 持有引用 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; // 更新创建过的最大线程数 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); // 启动线程, 而线程的 run 方法就是执行 runWorker() workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; runWorker : 不断获取任务并执行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获取第一个任务 Runnable task = w.firstTask; w.firstTask = null; // 允许中断 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为空，则通过getTask来获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask : 从任务队列获取任务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private Runnable getTask() &#123; // timeOut 表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. /* * 1. 线程池已经 stop * 2. 线程池处于 shutdown 并且队列为空 * 如果以上任何条件满足，则将 workerCount 减 1 并返回 null */ if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? // timed 用于判断是否需要进行超时控制 // allowCoreThreadTimeOut 默认是 false，也就是核心线程不允许进行超时 // wc &gt; corePoolSize，表示当前线程池中的线程数量大于核心线程数量 // 对于超过核心线程数量的这些线程，需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * wc &gt; maximumPoolSize 是因为可能通过 setMaximumPoolSize 修改过 maximumPoolSize * timed &amp;&amp; timedOut 如果为 true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时 * 接下来判断，如果有效线程数量大于 1，或者阻塞队列是空的，那么尝试将 workerCount 减 1 * 如果减 1 失败，则返回重试 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; /* * 根据 timed 来判断，如果为 true，则通过阻塞队列的 poll 方法进行超时控制 * 如果在 keepAliveTime 时间内没有获取到任务，则返回 null * 否则通过 take 方法，如果这时队列为空，则 take 方法会阻塞直到队列不为空。 * */ Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 如果 r == null，说明已经超时，timedOut 设置为 true timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断，则设置 timedOut 为 false 并返回循环重试 timedOut = false; &#125; &#125;&#125; processWorkerExit : 线程回收 线程池中线程的销毁依赖 JVM 的垃圾回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可 Worker 被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务 当 Worker 无法获取到任务，也就是获取的任务为空时，循环会结束，Worker 会主动消除自身在线程池内的引用 线程回收的工作在 processWorkerExit 方法内完成 12345678910111213141516171819202122232425262728293031323334353637private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果 completedAbruptly 值为 true，则说明线程执行时出现了异常，需要将 workerCount 减 1 // 如果线程执行时没有出现异常，说明在 getTask() 方法中已经已经对 workerCount 进行了减 1 操作 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 统计完成的任务数 completedTaskCount += w.completedTasks; // 从 workers 中移除，也就表示着从线程池中移除了一个工作线程 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池 tryTerminate(); int c = ctl.get(); /* * 当线程池是 RUNNING 或 SHUTDOWN 状态时，如果 worker 是异常结束，那么会直接 addWorker； * 如果 allowCoreThreadTimeOut 为 true，并且等待队列有任务，至少保留一个 worker； * 如果 allowCoreThreadTimeOut 为 false，workerCount 不少于 corePoolSize。 */ if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125; 事实上在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程 tryTerminate : 根据状态判断是否结束123456789101112131415161718192021222324252627282930313233343536373839404142final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); /* * 当前线程池的状态为以下几种情况时，直接返回： * 1. RUNNING，因为还在运行中，不能停止 * 2. TIDYING 或 TERMINATED，因为线程池中已经没有正在运行的线程了 * 3. SHUTDOWN 并且等待队列非空，这时要执行完 workQueue 中的 task； */ if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 如果线程数量不为 0，则中断一个空闲的工作线程，并返回 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 判断到这个位置则说明线程数量为 0 并且等待队列为空 // 尝试设置状态为 TIDYING，如果成功则调用 terminated 方法 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // terminated 方法默认什么都不做，留给子类实现 terminated(); &#125; finally &#123; // 设置状态为 TERMINATED ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS // 没设置成功则继续 CAS 尝试 &#125;&#125; shutdown , shutdownNow123456789101112131415161718192021222324252627282930313233343536public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 安全策略判断 checkShutdownAccess(); // 切换状态为 SHUTDOWN advanceRunState(SHUTDOWN); // 中断空闲线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试结束线程池 tryTerminate();&#125;public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 设置状态为 STOP advanceRunState(STOP); // 中断所有工作线程 interruptWorkers(); // 取出队列中没有被执行的任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125; interruptIdleWorkers, interruptWorkers12345678910111213141516171819202122232425262728293031323334353637private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 相关问题1. ThreadPoolExecutor 的执行方法有几种？它们有什么区别？ execute() VS submit() 都是用来执行线程池任务，它们最主要的区别是 submit() 方法可以接收线程池执行的返回值，而 execute() 不能接收返回值 123456789101112131415161718ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 10, 10L, TimeUnit.SECONDS, new LinkedBlockingQueue(20));// execute 使用executor.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("Hello, execute."); &#125;&#125;);// submit 使用Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; System.out.println("Hello, submit."); return "Success"; &#125;&#125;);System.out.println(future.get()); execute() 方法属于 Executor 接口的方法，而 submit() 方法则是属于 ExecutorService 接口的方法 在 submit() 中处理的任务如果抛出异常, 只有在调用返回的 Future 对象 get 方法时才会抛出 2. 拒绝策略的分类有哪些? 如何自定义拒绝策略？ 自带的拒绝策略有 4 种: AbortPolicy，终止策略，线程池会抛出异常并终止执行，它是默认的拒绝策略 CallerRunsPolicy，把任务交给当前线程来执行 DiscardPolicy，忽略此任务（最新的任务） DiscardOldestPolicy，忽略最早的任务（最先加入队列的任务） 自定义拒绝策略 自定义拒绝策略只需要新建一个 RejectedExecutionHandler 对象，然后重写它的 rejectedExecution() 方法即可 1234567891011121314ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 3, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(2), new RejectedExecutionHandler() &#123; // 添加自定义拒绝策略 @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 业务处理方法 System.out.println("执行自定义拒绝策略"); &#125; &#125;);for (int i = 0; i &lt; 6; i++) &#123; executor.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName()); &#125;);&#125; 3. 线程池的工作队列有哪些? ArrayBlockingQueue, 是一个用数组实现的有界阻塞队列，按 FIFO 排序任务, 支持公平锁和非公平锁 LinkedBlockingQueue, 基于链表结构的阻塞队列，按 FIFO 排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为 Integer.MAX_VALUE，吞吐量通常要高于 ArrayBlockingQuene DelayQueue, 是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序 PriorityBlockingQueue, 是具有优先级的无界阻塞队列, 不能保证同优先级元素的顺序 SynchronousQueue, 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlockingQueue SynchronousQueue, 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlockingQueue LinkedBlockingDeque, 一个由链表结构组成的双向阻塞队列，队列头尾都可以插入和移除元素, 多线程并发时, 可以将锁的竞争最多 降到一半 4. ThreadPoolExecutor 如何实现扩展？ 通过重写 beforeExecute() 和 afterExecute() 方法，我们可以在扩展方法中添加日志或者实现数据统计，比如统计线程的执行时间 关于 Executors 内的线程池对象 Executors 源码中 Executors.newFixedThreadPool()、Executors.newSingleThreadExecutor() 和 Executors.newCachedThreadPool() 等方法的底层都是通过 ThreadPoolExecutor 实现的 FixedThreadPool (固定数目线程的线程池) 适用于处理 CPU 密集型的任务，确保 CPU 在长期被工作线程使用的情况下，尽可能的少的分配线程 特点 核心线程数和最大线程数大小一样 keepAliveTime 为 0 阻塞队列为 LinkedBlockingQueue CachedThreadPool (可缓存线程的线程池) 适用于并发执行大量短期的小任务 特点 核心线程数为 0 最大线程数为 Integer.MAX_VALUE 阻塞队列为 SynchronousQueue 非核心线程空闲存活时间为 60 秒 SingleThreadExecutor (单线程的线程池) 适用于串行执行任务的场景，一个任务一个任务地执行 特点 核心线程数为 1 最大线程数也为 1 阻塞队列是 LinkedBlockingQueue keepAliveTime 为 0 ScheduledThreadPool (定时及周期执行的线程池) 周期性执行任务的场景，需要限制线程数量的场景 特点 最大线程数为 Integer.MAX_VALUE 阻塞队列是 DelayedWorkQueue keepAliveTime 为 0 scheduleAtFixedRate() 按某种速率周期执行 scheduleWithFixedDelay() 在某个延迟后执行 在阿里巴巴的《 Java 开发手册 》中是这样规定的： 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的读者更加明确线程池的运行规则，规避资源耗尽的风险。 Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM CachedThreadPool 和 ScheduledThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>multithread</tag>
        <tag>concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java HashMap]]></title>
    <url>%2F2020%2F03%2F14%2FJava-HashMap%2F</url>
    <content type="text"><![CDATA[HashMap 底层 在 JDK 1.7 中 HashMap 是以数组加链表的形式组成的，JDK 1.8 之后新增了红黑树的组成结构，当链表大于 8 时，链表结构会转换成红黑树结构 数组中的元素我们称之为哈希桶，它的定义如下 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 重要属性1234567891011121314151617// HashMap 初始化长度static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// HashMap 最大长度static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 1073741824// 默认的加载因子 (扩容因子)static final float DEFAULT_LOAD_FACTOR = 0.75f;// 转换红黑树的临界值，当链表长度大于此值时，会把链表结构转换为红黑树结构static final int TREEIFY_THRESHOLD = 8;// 转换链表的临界值，当元素小于此值时，会将红黑树结构转换成链表结构static final int UNTREEIFY_THRESHOLD = 6;// 最小树容量static final int MIN_TREEIFY_CAPACITY = 64; 什么是加载因子？加载因子为什么是 0.75？ 加载因子也叫扩容因子或负载因子，用来判断什么时候该进行扩容 假如加载因子是 0.5，HashMap 的初始化容量是 16，那么当 HashMap 中有 16 * 0.5 = 8 个元素时，HashMap 就会进行扩容 0.75 是出于容量和性能之间平衡的结果 当加载因子设置比较大的时候，扩容的门槛就被提高了，扩容发生的频率比较低，占用的空间会比较小，但此时发生 Hash 冲突的几率就会提升，因此需要更复杂的数据结构来存储元素，这样对元素的操作时间就会增加，运行效率也会因此降低 而当加载因子值比较小的时候，扩容的门槛会比较低，因此会占用更多的空间，此时元素的存储就比较稀疏，发生哈希冲突的可能性就比较小，因此操作性能会比较高 还为了提升扩容效率，HashMap的容量（capacity）有一个固定的要求，那就是一定是2的幂。所以，如果负载因子是3/4的话，那么和capacity的乘积结果就可以是一个整数 重要方法查询 12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;K,V&gt; e; // 对 key 进行哈希操作 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 非空判断 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断第一个元素是否是要查询的元素 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 下一个节点非空判断 if ((e = first.next) != null) &#123; // 如果节点是树结构, 则使用 getTreeNode 直接获取相应的数据 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; // 非树结构，循环节点判断 // hash 相等并且 key 相同，则返回此节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 当哈希冲突时需要通过判断 key 值是否相等来确认此元素是否是要查询的元素 新增 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 哈希表为空则创建表 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 根据 key 的哈希值计算出要插入的数组索引 i if ((p = tab[i = (n - 1) &amp; hash]) == null) // 如果 table[i] 等于 null, 则直接插入 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 如果与第一个元素的 key 相等，直接覆盖第一个元素的 value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 需要往后插入元素，先判断是否为红黑树 else if (p instanceof TreeNode) // 红黑树直接插入键值对 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 为链表结构，循环准备插入 for (int binCount = 0; ; ++binCount) &#123; // 下一个元素为空时直接插入 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 链表长度大于 8 转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果与下一个元素的 key 相等，直接覆盖下一个元素的 value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 超过最大容量，扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 扩容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495final Node&lt;K,V&gt;[] resize() &#123; // 扩容前的数组 Node&lt;K,V&gt;[] oldTab = table; // 扩容前的数组大小 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 扩容前的扩容阈值 int oldThr = threshold; // 预定义新数组的大小和阈值 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩容了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 扩大容量为当前容量的两倍，但不能超过 MAXIMUM_CAPACITY else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 当前数组没有数据，使用初始化的值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 如果初始化的值为 0，则使用默认的初始化容量 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 如果新阈值为 0 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 开始扩容 table = newTab; // 原数据不为空，将原数据复制到新 table 中 if (oldTab != null) &#123; // 根据容量循环数组，复制非空元素到新 table for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) // 链表只有一个元素时直接赋值 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 下个元素为红黑树时, 进行相关操作 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 链表复制，JDK 1.8 扩容优化部分 // 用于连接扩容时位置不变的元素 Node&lt;K,V&gt; loHead = null, loTail = null; // 用于连接扩容时位置改变的元素 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引 + oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将原索引放到哈希桶中 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 将原索引 + oldCap 放到哈希桶中 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; JDK 1.8 在扩容时并没有像 JDK 1.7 那样，重新计算每个元素的哈希值，而是通过 e.hash &amp; oldCap 来确定元素是否需要移动 如 key1 的信息如下： key1.hash = 10 -&gt; 0000 1010 oldCap = 16 -&gt; 0001 0000 使用 e.hash &amp; oldCap 得到的结果为 0，则在扩容时位置不会发生任何变化 而 key 2 信息如下： key2.hash = 26 -&gt; 0001 1010 oldCap = 16 -&gt; 0001 0000 这时候得到的结果不为 0，新的下标位置等于原下标位置 + 原数组长度 为什么要这么做 ? 首先这里的元素扩容前都是在同一个数组下标中的, 也就是 (oldCap - 1) &amp; hash 值相同 扩容的时候新容量是左移了一位的, 如下 oldCap = 16 -&gt; 0001 0000 newCap = 32 -&gt; 0010 0000 则相应的 oldCap -1 = 15 -&gt; 0000 1111 newCap - 1 = 31 -&gt; 0001 1111 所以对于 e.hash &amp; oldCap 不为 0 的元素, 需要放置到原索引 + oldCap 的位置, 因为在 newCap 的情况下插入该元素时, (newCap - 1) &amp; hash 值就是原索引 + oldCap 死循环分析 在 JDK 1.7 中, 假设 HashMap 默认大小为 2，原本 HashMap 中有一个元素 key(5) 我们再使用两个线程 t1 添加元素 key(3) t2 添加元素 key(7) 当元素 key(3) 和 key(7) 都添加到 HashMap 中之后，开始进行扩容操作 当线程 t1 在执行到 Entry&lt;K,V&gt; next = e.next; 时，交出了 CPU 的使用权，源码如下: 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; // 线程一执行此处 if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 此时线程 t1 中的 e 指向了 key(3)，而 next 指向了 key(7) 之后线程 t2 重新 rehash 之后链表的顺序被反转, 链表的位置变成了 key(5) → key(7) → key(3)，其中 “→” 用来表示下一个元素 当 t1 重新获得执行权之后，先执行 newTalbe[i] = e; 把 key(3) 的 next 设置为 key(7) 而下次循环时查询到 key(7) 的 next 元素为 key(3)，于是就形成了 key(3) 和 key(7) 的循环引用 发生死循环的原因是 JDK 1.7 链表插入方式为首部倒序插入，这个问题在 JDK 1.8 得到了改善，变成了尾部正序插入 HashMap 本身就是非线程安全的, 所以不建议在多线程下使用]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 关键字 final]]></title>
    <url>%2F2020%2F03%2F13%2FJava-%E5%85%B3%E9%94%AE%E5%AD%97-final%2F</url>
    <content type="text"><![CDATA[final方法 被 final 修饰的方法不可被重写。它可以防止任何继承类修改方法的意义和实现 而且使用 final 修饰方法的执行效率一般高于普通方法，这里不得不提一下 Java 的内联（inline）机制 ​ 当我们调用方法时，实际上是将程序的执行转移到该方法所在的内存地址上，将该方法执行完后，再返回到执行该方法前的位置，这种转移操作要求在转移前保存当前的数据以及内存地址，在执行完后再恢复现场，继续按照转移前的地址执行，也就是通常所说的压栈和出栈（这段文字有点绕口，简单来说，比如 A 方法在执行到第 10 行的时候调用了 B 方法，JVM 会先保存 A 方法当前数据和执行地址，然后跳转到 B 方法所在的内存地址执行 B 方法，执行完后，再返回 A 方法第十行继续执行），因此，函数调用有一定时间和空间方面的开销，对于函数体积不大，但是频繁调用的函数来说，这个开销就会放大。​ 因此，对于这种函数体积不大又频繁调用的的方法，我们可以通过内联函数来提升运行效率，当我们对一个方法使用 final 修饰时，这个方法就有可能成为内联函数（JVM 会根据方法的执行效率决定是否内联）。 内联前： 1234567891011121314class A &#123; int value; public final int get()&#123; return value; &#125;&#125;public class B &#123; public void sum() &#123; A a = new A(); //调用a的get方法 int x = a.get(); &#125;&#125; 内联后： 1234567891011121314class A &#123; int value; public final int get()&#123; return value; &#125;&#125;public class B &#123; public void sum() &#123; A a = new A(); //此处将get方法展开为内联函数 int x = a.value; &#125;&#125; 类 当 final 修饰一个类时，表明其为最终类，它不能被继承 并且类中所有的属性和方法都默认是 final 类型，如 String，Integer 等包装类均为 final 类 方法默认被修饰为 final ，这时方法的内联起到作用了, 这种空间置换时间的策略需要一个平衡点（break-even），如果一个方法过于大，copy 的副本数量过于多，那么这样的平衡就会被打破，优化的目的反而失去了意义 变量 修饰基本类型变量时，变量的值不可改变 修饰引用变量时，变量指向的对象地址不可改变 这里还涉及到了一个类似 C 语言的宏替换概念，由于 final 修饰的 String 变量不可更改，所以，当一个 String 变量被 final 修饰时，这个值在编译期就可以确定，所有将该变量直接替换为它对应的值，如下： 12345678910111213141516171819public class test &#123; public static void main(String[] args) &#123; final String a = "hello"; String b = "hello"; final String c = "world"; String d = "hello" + "world"; String e = a + c; String f = b + c; String g = "helloworld"; // 在编译期，由于 a 和 c 的值已经确定并且不会再更改（效果同 d）， // 所以 e 的值能够在编译期就确定下来，直接指向了常量区的 g，前两个均为 true System.out.println(g == d);//true System.out.println(g == e);//true // 由于 b 值的不确定性，所以在编译期不能确定其值，只能在运行时确认 System.out.println(g == f);//false &#125;&#125; 参数 final 修饰的参数有一个只读的属性，即可以读取该参数，但是无法更改参数的值，同修饰变量一样，当参数为基本类型时，该参数的值不可改变；当参数为引用类型时，参数的引用地址不可改变。 final 的内存语义 volatile 可以禁止指令重排序，final 同样有这样的作用，对于 final 域，编译器和处理器要遵守两个重排序规则 在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 意思是说，在对象引用为任意线程可见之前，对象的 final 域已经被正确初始化了（JVM 禁止把 final 域的写重排序到构造函数之外，要保证该效果，还要确保 final 引用没有从构造函数溢出）。 初次读一个包含 final 域的对象的引用，与随后初次读这个 final 域，这两个操作之间不能重排序。 意思是说，在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。 对于内存语义这块，还需要结合代码去理解，参考《Java 并发编程的艺术》一书 3.6 节。 参考: https://zhuanlan.zhihu.com/p/60889552 https://www.jianshu.com/p/f68d6ef2dcf0]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>final</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人月神话笔记]]></title>
    <url>%2F2020%2F02%2F26%2F%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[人月神话笔记 1975 出版的经典书籍, 记录其中令我印象深刻且到目前也不过时的内容 人月神话 人月是危险和带有欺骗性的神话，因为它暗示人员数量和时间是可以相互替换的 向进度落后的项目增加人手只会导致项目更加落后 任务重新分配本身和所造成的工作中断 培训新人员 额外的相互沟通 关于进度安排, 1/3计划、1/6编码、1/4构件测试以及1/4系统测试 外科手术队伍 把大型团队拆分为若干个类似于外科手术式的小团队 每个小团队有一名主程序员（类似于主刀医生），所有的问题分解和功能定义都通过主程序员来完成，以此来降低沟通成本 每个主程序员配备若干个平庸的人帮他/她打下手 贵族专制、民主政治和系统设计 概念完整性是系统设计中最重要的考虑因素 为了获得概念完整性，设计必须由一个人或者具有共识的小型团队来完成 将设计方法、体系结构方面的工作与具体实现相分离是获得概念完整性的强有力方法 蛇添足, 贯彻执行, 为什么巴比伦塔会失败？ 不要过度设计，尤其是在第二个系统(第一个系统完成后开发的第二个系统)中，不要过度自信，保持警觉，避免初始的概念和目标得到充分的体现，而不让一些次要的功能喧宾夺主 沟通交流的重要性, 尽早交流, 持续沟通 整体部分 在设计系统结构时精心设计，减少各个部分间的耦合，各个模块的独立性越高，系统级的 bug 的可能性就越低 未雨绸缪 目标上（和开发策略上）的一些正常变化无可避免，事先为它们做准备总比假设它们不会出现要好得多 机器在变化，配置在变化，用户的需求在变化，所以现实系统不可能永远可用。崭新的、对于原有系统的重新设计是完全必要的。 祸起萧墙 里程碑的选择只有一个原则，那就是，里程碑必须是具体的、特定的、可度量的事件，能够进行清晰定义 减少角色的冲突。老板必须规范自己，不对项目经理可以解决的问题做出反应 没有银弹 不可能有某种技术突破（银弹）能够彻底解决“根本性困难”，从而导致软件开发效率有数量级的提高 增量开发，把软件当做是生长的有机体, 从简单的核心开始，一边交付一边开发，不断增加新的功能，一边增加新的功能，一边重构已有的部分]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>programing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes 学习笔记]]></title>
    <url>%2F2020%2F02%2F12%2FKubernetes-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Docker 基础 Namespace 进程之间的可见性 Cgoups 限制资源的使用 K8s 基础 Master 控制节点，负责整个集群的管理和控制。Master 节点上包含以下组件： etcd apiserver controller manager scheduler Node 工作节点, 工作负载主要是运行容器应用。Node 节点上包含以下组件： kubelet kube-proxy container runtime Pod 静态 Pod Pod Hook PostStart PreStop 健康检查 livenessProbe readnessProbe Init Container Deploymen Replication Controller（RC） Replication Set（RS） 支持基于集合的 selector 一个 Deployment 控制多个 RS ( 为了支持回滚 ) Service 相关 IP 概念 Node IP Pod IP Cluster IP 类型 ClusterIP NodePort LoadBalancer ExternalName ConfigMap Secret Opaque kubernetes.io/dockerconfigjson kubernetes.io/service-account-token Horizontal Pod Autoscaling (HPA) Heapster Job CronJob RBAC Role 和 ClusterRole Rule Subject User Account Group Service Account RoleBinding 和 ClusterRoleBinding DaemonSet StatefulSet 服务的有状态和无状态 持久化存储 PV PVC StorageClass 组件 Kubernetes 主要由以下几个核心组件组成: etcd 保存了整个集群的状态，就是一个数据库 Apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 Controller Manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 Scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 Kubelet 负责维护容器的生命周期，同时也负责 Volume（CSI）和网络（CNI）的管理； Container Runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI） kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡 除了上面的这些核心组件，还有一些推荐的插件： kube-dns 负责为整个集群提供 DNS 服务 Ingress Controller 为服务提供外网入口 Heapster 提供资源监控 Dashboard 提供 GUI Kubernetes 多组件之间的通信原理 apiserver 负责 etcd 存储的所有操作，且只有 apiserver 才直接操作 etcd 集群 apiserver 对内（集群中的其他组件）和对外（用户）提供统一的 REST API，其他组件均通过 apiserver 进行通信 controller manager、scheduler、kube-proxy 和 kubelet 等均通过 apiserver watch API 监测资源变化情况，并对资源作相应的操作 所有需要更新资源状态的操作均通过 apiserver 的 REST API 进行 apiserver 也会直接调用 kubelet API（如 logs, exec, attach 等），默认不校验 kubelet 证书，但可以通过 --kubelet-certificate-authority 开启（而 GKE 通过 SSH 隧道保护它们之间的通信） 比如最典型的创建 Pod 的流程： 用户通过 REST API 创建一个 Pod apiserver 将其写入 etcd scheduluer 检测到未绑定 Node 的 Pod，开始调度并更新 Pod 的 Node 绑定 kubelet 检测到有新的 Pod 调度过来，通过 container runtime 运行该 Pod kubelet 通过 container runtime 取到 Pod 状态，并更新到 apiserver 中 服务发现 内部服务发现 通过 apiserver 查询 依赖 K8s 通过环境变量 依赖的服务必须在 Pod 启动之前就存在 DNS Server kubedns coredns 外部服务发现 ingress Traefik Helm 概念 chart config release Helm Client Tiller Server]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 定时备份 (基于 Dokcer 运行)]]></title>
    <url>%2F2020%2F01%2F17%2FMysql-%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD-(%E5%9F%BA%E4%BA%8E-Dokcer-%E8%BF%90%E8%A1%8C)%2F</url>
    <content type="text"><![CDATA[脚本编写 vim mysql_bak.sh 123456789101112131415161718192021222324252627282930#!/bin/sh# 数据库相关配置host=1.2.3.4port=3306user=rootpassword=123456db_name=db# 存放目录 (绝对路径)backupdir=/mysqlbackup# 保留天数time=1echo "开始备份数据库";# 生成脚本echo "mysqldump --host=$host --port=$port -u$user -p$password --extended-insert $db_name | gzip &gt; /mysqlbackup/$db_name`date +%Y-%m-%d_%H%M%S`.sql.gz" &gt; $backupdir/run.sh# 赋权sudo chmod 744 $backupdir/run.sh# 启动 docker 运行脚本docker run --rm -v $backupdir:/mysqlbackup mysql:5.7 /mysqlbackup/run.sh# 删除 time 天前的备份文件, 若要改为分钟, 使用 -mminfind $backupdir -name $db_name"*.sql.gz" -type f -mtime +$time -exec rm -rf &#123;&#125; \; echo "备份完成"; 赋权 sudo chmod 744 mysql_bak.sh 执行测试是否成功 sudo ./mysql_bak.sh 查看对应目录下是否生成备份文件 配置定时任务 用 crontab 定时执行备份脚本代码 sudo crontab -u root -e 以 root 身份打开编辑 crontab 的工作内容 加入内容, 若要每小时 30 分时备份, 输入以下内容 30 * * * * /(脚本所在路径)/mysql_bak.sh &gt;&gt; /(脚本所在路径)/mysql_bak.log Ubuntu 系统默认是不打开 cron 日志, 需要配置: 打开文件 sudo vi /etc/rsyslog.d/50-default.conf 在文件中找到 cron.*，把前面的 # 去掉 保存退出 重新加载配置 sudo service rsyslog restart 查看日志 tail -f /var/log/cron.log 其他 恢复数据时, 可能会因为 sql 文件过大报错, 需要修改 max_allowed_packet 的值, 默认为 4MB 12345678# 查看当前 max_allowed_packet 的值mysql&gt; show variables like &apos;max_allowed_packet&apos;;# 数据库中临时修改（重启数据库后失效）, 最大可以设置为 1Gmysql&gt; set global max_allowed_packet = 1 * 1024 * 1024 * 1024;# 需要退出保存mysql&gt; exit]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb 集群分片与容灾备份 (基于 Dokcer Swarm 部署)]]></title>
    <url>%2F2020%2F01%2F16%2FMongoDb-%E9%9B%86%E7%BE%A4%E5%88%86%E7%89%87%E4%B8%8E%E5%AE%B9%E7%81%BE%E5%A4%87%E4%BB%BD-(%E5%9F%BA%E4%BA%8E-Dokcer-Swarm-%E9%83%A8%E7%BD%B2)%2F</url>
    <content type="text"><![CDATA[基础概念 副本集 (Replica Set) 分片 (Sharding)]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-swarm</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 基本使用]]></title>
    <url>%2F2019%2F08%2F02%2FDocker-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[停止并删除所有容器1$ docker stop $(docker ps -q) docker rm $(docker ps -aq) 清理镜像12345# 清理 dangling 镜像$ docker rmi $(docker images -f "dangling=true" -q)# 根据通配符查找删除指定镜像$ docker rmi $(docker images -f "reference=*" --format "&#123;&#123;.Repository&#125;&#125;:&#123;&#123;.Tag&#125;&#125;") 创建 Swarm 集群以及其基本操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 修改 node name￼$ sudo hostnamectl set-hostname &#123;$name&#125;￼$ sudo systemctl restart docker# ￼manager: 创建 swarm 集群￼$ ￼docker swarm init# 创建 swarm 集群时指定 ip 和通讯的 udp 端口 (针对云服务器上部分环境时需用到)$ docker swarm init --advertise-addr 1.2.3.4 --data-path-port 12345# ￼node: 加入 swarm 集群￼$ ￼docker swarm join ......# ￼获取加入token￼$ ￼docker swarm join-token [worker|manager]# ￼manager: 查看节点￼$ ￼docker node ls# 部署单个服务$ docker service create --replicas 3 -p 80:80 --name nginx nginx# 查看服务$ docker service ls # 服务伸缩$ docker service scale nginx=5# 删除服务$ docker service rm nginx# 根据 yaml 文件部署包含多个服务的 stack$ docker stack deploy -c xxxx.yml one-stack# 根据 yaml 文件部署 stack 时能读取同层 .env 文件内设置的环境变量$ docker stack deploy -c &lt;(docker-compose -f xxxx.yml config) one-stack# 根据 yaml 文件部署 stack 时能读取同层 .env 文件内设置的环境变量, 从私库拉取镜像$ docker stack deploy --with-registry-auth -c &lt;(docker-compose -f xxxx.yml config) one-stack# 查看 stack$ docker stack ls # 查看 stack 中的服务$ docker stack ps one-stack # 停止删除 stack (该命令不会移除服务所使用的数据卷，移除数据卷用 docker volume rm)$ docker stack down one-stack# 更新 service 镜像, 从私库拉取$ docker service update --with-registry-auth --image image-name:tag service-name# 批量删除 service$ docker service rm $(docker service ls -qf name=)# 指定 service 在某个 node 运行# 给 node 打标签$ docker node update --label-add run-a=1 xxxxxx# 给 service 加入约束条件$ docker service update --constraint-add "node.labels.run-a==1" swarm_a Docker Compose 文件相关配置 参考官方文档 yaml 中重用代码块 12345678910test: &amp;base a: 1 b: 2use1: *baseuse2: &lt;&lt;: *base b: 3 c: 4 123456789101112test: a: 1 b: 2 use1: a: 1 b: 2 use2: a: 1 b: 3 c: 4 Dockerfile ONBUILD 指令 格式：ONBUILD &lt;其它指令&gt;。 ONBUILD是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。 1234567FROM node:slimRUN mkdir /appWORKDIR /appONBUILD COPY ./package.json /appONBUILD RUN [ "npm", "install" ]ONBUILD COPY . /app/CMD [ "npm", "start" ] 这样各个子镜像在构建的时候就不需要重复加入上面三行命令 多阶段构建 12345678910111213FROM golang AS build-envADD . /go/src/appWORKDIR /go/src/appRUN go get -u -v github.com/kardianos/govendorRUN govendor syncRUN GOOS=linux GOARCH=386 go build -v -o /go/src/app/app-serverFROM alpineRUN apk add -U tzdataRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY --from=build-env /go/src/app/app-server /usr/local/bin/app-serverEXPOSE 8080CMD [ "app-server" ] 默认情况下，构建阶段是没有命令的，我们可以通过它们的索引来引用它们，第一个 FROM 指令从0开始，我们也可以用 AS 指令为阶段命令，比如我们这里的将第一阶段命名为 build-env，然后在其他阶段需要引用的时候使用 --from=build-env 参数即可]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-swarm</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在服务器上的相关运维操作]]></title>
    <url>%2F2019%2F08%2F02%2F%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[安装 Docker 其他系统的安装可以参考官方文档 Ubuntu 12345678910111213141516171819202122232425262728# 安装 Docker 依赖库$ sudo apt-get update $ sudo apt-get install apt-transport-https ca-certificates \ gnupg-agent software-properties-common \ curl# 清理过去遗留的老版本 $ sudo apt-get remove docker docker-engine docker.io containerd runc# 添加 Docker 官方的 GPG key$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 添加 docker 仓库$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"# 安装 Docker CE$ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io# 验证$ sudo docker run hello-world# 配置镜像加速器$ echo '&#123; "registry-mirrors": ["https://umbmb1yu.mirror.aliyuncs.com"] &#125;' | sudo tee /etc/docker/daemon.json$ sudo systemctl daemon-reload$ sudo systemctl restart docker# 登录私库$ sudo docker login --username=abmatrix registry.cn-hangzhou.aliyuncs.com 12# 使用阿里官方安装脚本自动安装 （仅适用于公网环境）$ sudo curl -fsSL https://get.docker.com | sudo bash -s docker --mirror Aliyun 删除 Docker12345# 卸载 Docker CE 包$ sudo apt-get purge docker-ce# 删除 images、containers 和 volumes$ sudo rm -rf /var/lib/docker 修改 hostname12# 修改 hostname$ hostnamectl set-hostname abm-aliyun-x 开启 ssh 密码登录12345$ vim /etc/ssh/sshd_config修改 PasswordAuthentication yes$ service sshd restart 挂载硬盘12345678910111213# 查看主机上的硬盘$ fdisk -l# 硬盘格式化$ mkfs.ext4 /dev/vdb# 挂载$ mount /dev/vdb /mnt# 开机自动挂载, 编辑 /etc/fstab 文件$ vim /etc/fstab# 追加/dev/vdb /mnt ext4 defaults 0 0 添加用户并并将用户加入 Docker 组12345678910111213141516171819202122# 添加用户$ adduser abm# 加入 sudo 权限$ chmod u+w /etc/sudoers$ echo "abm ALL=(ALL:ALL) ALL" &gt;&gt; /etc/sudoers$ chmod u-w /etc/sudoers# 查看是否存在 docker 组$ cat /etc/group | grep docker# 不存的话创建 docker 分组$ groupadd docker# 对应用户登录# 将用户添加 docker 分组$ sudo gpasswd -a $USER docker$ newgrp docker# 设置权限$ sudo chown "$USER":"$USER" /home/"$USER"/.docker -R$ sudo chmod g+rwx "/home/$USER/.docker" -R Docker 其他组件安装12345678# 安装 docker-compose$ sudo curl -L "https://github.com/docker/compose/releases/download/1.25.5/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose# 设置权限$ sudo chmod +x /usr/local/bin/docker-compose# 安装命令补全$ sudo curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose 修改 Docker 储存位置1234567891011# 停止服务$ sudo service docker stop# 转移$ sudo mv /var/lib/docker /mnt/data/docker# 创建软链接$ sudo ln -s /mnt/data/docker /var/lib/docker# 启动服务$ sudo service docker start 设置防火墙规则123456789101112131415161718# 指定端口$ sudo ufw allow 22# Docker Swarm 相关端口$ sudo ufw allow 2376/tcp$ sudo ufw allow 2377/tcp$ sudo ufw allow 7946/tcp$ sudo ufw allow 7946/udp$ sudo ufw allow 4789/udp# 指定 ip$ sudo ufw allow from 123.123.123.123# 开启$ sudo ufw enable# 重新加载$ sudo ufw reload 测试 UPD 端口123456789# 服务端监听：$ nc -l -u 192.168.80.129 8001# 客户端：$ nc -u 192.168.80.129 8001# 在这里输入字符串， 服务端就会回显相同的字符串，表示 8001 端口上的 udp 服务是否启用.# 查看 udp 连接$ netstat -nua]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab Devops 配置]]></title>
    <url>%2F2019%2F06%2F13%2FGitlab-Devops-%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[K8s 环境在 Kubernetes 集群上安装 Gitlab-Runnerhttps://docs.gitlab.com/runner/install/kubernetes.html 123kubectl patch deploy --namespace kube-system tiller-deploy -p '&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'helm install --namespace gitlab --name gitlab-runner -f values.yaml gitlab/gitlab-runner values.yaml 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282## GitLab Runner Image#### By default it's using gitlab/gitlab-runner:alpine-v&#123;VERSION&#125;## where &#123;VERSION&#125; is taken from Chart.yaml from appVersion field#### ref: https://hub.docker.com/r/gitlab/gitlab-runner/tags/##image: gitlab/gitlab-runner:alpine-v12.0.0-rc1## Specify a imagePullPolicy## 'Always' if imageTag is 'latest', else set to 'IfNotPresent'## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images##imagePullPolicy: IfNotPresent## The GitLab Server URL (with protocol) that want to register the runner against## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-register##gitlabUrl: https://gitlab.com/## The Registration Token for adding new Runners to the GitLab Server. This must## be retrieved from your GitLab Instance.## ref: https://docs.gitlab.com/ce/ci/runners/README.html##runnerRegistrationToken: "NkeYywTkYwWf14JZxtM1"## The Runner Token for adding new Runners to the GitLab Server. This must## be retrieved from your GitLab Instance. It is token of already registered runner.## ref: (we don't yet have docs for that, but we want to use existing token)### runnerToken: ""### Unregister all runners before termination#### Updating the runner's chart version or configuration will cause the runner container## to be terminated and created again. This may cause your Gitlab instance to reference## non-existant runners. Un-registering the runner before termination mitigates this issue.## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-unregister##unregisterRunners: true## Set the certsSecretName in order to pass custom certficates for GitLab Runner to use## Provide resource name for a Kubernetes Secret Object in the same namespace,## this is used to populate the /etc/gitlab-runner/certs directory## ref: https://docs.gitlab.com/runner/configuration/tls-self-signed.html#supported-options-for-self-signed-certificates### certsSecretName:## Configure the maximum number of concurrent jobs## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section##concurrent: 10## Defines in seconds how often to check GitLab for a new builds## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section##checkInterval: 30## Configure GitLab Runner's logging level. Available values are: debug, info, warn, error, fatal, panic## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section### logLevel:## For RBAC support:rbac: create: true ## Run the gitlab-bastion container with the ability to deploy/manage containers of jobs ## cluster-wide or only within namespace clusterWideAccess: false ## Use the following Kubernetes Service Account name if RBAC is disabled in this Helm chart (see rbac.create) ## # serviceAccountName: default## Configure integrated Prometheus metrics exporter## ref: https://docs.gitlab.com/runner/monitoring/#configuration-of-the-metrics-http-servermetrics: enabled: true## Configuration for the Pods that that the runner launches for each new job##runners: ## Default container image to use for builds when none is specified ## image: ubuntu:16.04 ## Specify one or more imagePullSecrets ## ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/ ## # imagePullSecrets: [] ## Specify the image pull policy: never, if-not-present, always. The cluster default will be used if not set. ## # imagePullPolicy: "" ## Defines number of concurrent requests for new job from GitLab ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-section ## # requestConcurrency: 1 ## Specify whether the runner should be locked to a specific project: true, false. Defaults to true. ## # locked: true ## Specify the tags associated with the runner. Comma-separated list of tags. ## ## ref: https://docs.gitlab.com/ce/ci/runners/#using-tags ## tags: "k8s-runner" ## Run all containers with the privileged flag enabled ## This will allow the docker:dind image to run if you need to run Docker ## commands. Please read the docs before turning this on: ## ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-dind ## privileged: true ## The name of the secret containing runner-token and runner-registration-token # secret: gitlab-runner ## Namespace to run Kubernetes jobs in (defaults to the same namespace of this release) ## namespace: gitlab ## Distributed runners caching ## ref: https://gitlab.com/gitlab-org/gitlab-runner/blob/master/docs/configuration/autoscale.md#distributed-runners-caching ## ## If you want to use s3 based distributing caching: ## First of all you need to uncomment General settings and S3 settings sections. ## ## Create a secret 's3access' containing 'accesskey' &amp; 'secretkey' ## ref: https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/ ## ## $ kubectl create secret generic s3access \ ## --from-literal=accesskey="YourAccessKey" \ ## --from-literal=secretkey="YourSecretKey" ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ ## ## If you want to use gcs based distributing caching: ## First of all you need to uncomment General settings and GCS settings sections. ## ## Access using credentials file: ## Create a secret 'google-application-credentials' containing your application credentials file. ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section ## You could configure ## $ kubectl create secret generic google-application-credentials \ ## --from-file=gcs-applicaton-credentials-file=./path-to-your-google-application-credentials-file.json ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ ## ## Access using access-id and private-key: ## Create a secret 'gcsaccess' containing 'gcs-access-id' &amp; 'gcs-private-key'. ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section ## You could configure ## $ kubectl create secret generic gcsaccess \ ## --from-literal=gcs-access-id="YourAccessID" \ ## --from-literal=gcs-private-key="YourPrivateKey" ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ cachePath: "/opt/gitlab_runner/cache" cache: &#123;&#125; ## General settings # cacheType: s3 # cachePath: "/opt/gitlab_runner/cache" # cacheShared: true ## S3 settings # s3ServerAddress: s3.amazonaws.com # s3BucketName: # s3BucketLocation: # s3CacheInsecure: false # secretName: s3access ## GCS settings # gcsBucketName: ## Use this line for access using access-id and private-key # secretName: gcsaccess ## Use this line for access using google-application-credentials file # secretName: google-application-credentials ## Build Container specific configuration ## builds: &#123;&#125; # cpuLimit: 200m # memoryLimit: 256Mi # cpuRequests: 100m # memoryRequests: 128Mi # image: gitlab/gitlab-runner-helper:x86_64-latest ## Service Account to be used for runners ## # serviceAccountName: ## If Gitlab is not reachable through $CI_SERVER_URL ## # cloneUrl: ## Specify node labels for CI job pods assignment ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ ## # nodeSelector: &#123;&#125; ## Specify pod labels for CI job pods ## # podLabels: &#123;&#125; ## Specify annotations for job pods, useful for annotations such as iam.amazonaws.com/role # podAnnotations: &#123;&#125; ## Configure environment variables that will be injected to the pods that are created while ## the build is running. These variables are passed as parameters, i.e. `--env "NAME=VALUE"`, ## to `gitlab-runner register` command. ## ## Note that `envVars` (see below) are only present in the runner pod, not the pods that are ## created for each build. ## ## ref: https://docs.gitlab.com/runner/commands/#gitlab-runner-register ## # env: # NAME: VALUE## Configure resource requests and limits## ref: http://kubernetes.io/docs/user-guide/compute-resources/##resources: &#123;&#125; # limits: # memory: 256Mi # cpu: 200m # requests: # memory: 128Mi # cpu: 100m## Affinity for pod assignment## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity##affinity: &#123;&#125;## Node labels for pod assignment## Ref: https://kubernetes.io/docs/user-guide/node-selection/##nodeSelector: &#123;&#125; # Example: The gitlab runner manager should not run on spot instances so you can assign # them to the regular worker nodes only. # node-role.kubernetes.io/worker: "true"## List of node taints to tolerate (requires Kubernetes &gt;= 1.6)## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/##tolerations: [] # Example: Regular worker nodes may have a taint, thus you need to tolerate the taint # when you assign the gitlab runner manager with nodeSelector or affinity to the nodes. # - key: "node-role.kubernetes.io/worker" # operator: "Exists"## Configure environment variables that will be present when the registration command runs## This provides further control over the registration process and the config.toml file## ref: `gitlab-runner register --help`## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html### envVars:# - name: RUNNER_EXECUTOR# value: kubernetes## list of hosts and IPs that will be injected into the pod's hosts filehostAliases: [] # Example: # - ip: "127.0.0.1" # hostnames: # - "foo.local" # - "bar.local" # - ip: "10.1.2.3" # hostnames: # - "foo.remote" # - "bar.remote"## Annotations to be added to manager pod##podAnnotations: &#123;&#125; # Example: # iam.amazonaws.com/role: &lt;my_role_arn&gt; 123456gcr.io/kubernetes-helm/tiller:v2.12.3docker pull fishead/gcr.io.kubernetes-helm.tiller:v2.12.3docker tag fishead/gcr.io.kubernetes-helm.tiller:v2.12.3 gcr.io/kubernetes-helm/tiller:v2.12.3去 docker hub 找个镜像仓库 配置 Kubernetes cluster details 参考 官方文档 - Adding an existing Kubernetes cluster 的说明 安装 Helm Tiller 点击页面 Install 按钮 kubectl get pods -A 能看到 install-helm 的 pod 根据 pod/install-helm 生成 yaml 1kubectl get pod install-helm -n gitlab-managed-apps -o yaml &gt; install-helm.yaml 修改 yaml 中的 pod 启动命令, 加入阿里云仓库 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata:......spec: containers: - args: - -c - $(COMMAND_SCRIPT) command: - /bin/sh env: - name: HELM_VERSION value: 2.12.3 - name: TILLER_NAMESPACE value: gitlab-managed-apps - name: COMMAND_SCRIPT value: |- set -xeo pipefail helm init --tiller-tls --tiller-tls-verify --tls-ca-cert /data/helm/helm/config/ca.pem --tiller-tls-cert /data/helm/helm/config/cert.pem --tiller-tls-key /data/helm/helm/config/key.pem --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.12.3 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts helm repo add stable https://burdenbear.github.io/kube-charts-mirror/ helm repo update...... 根据修改后的 yaml 重新创建 pod 12kubectl delete pod install-helm -n gitlab-managed-apps kubectl apply -f install-helm.yaml 删除 namespace 1kubectl delete namespaces gitlab-managed-apps 重新点击页面 Install 按钮 非 K8s 环境在 Docker 中部署 GitLab Runner运行 GitLab Runner 命令行 1234$ docker run -d --name gitlab-runner --restart always \ -v /path/to/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest docke-compose 123456789version: '3.7'services: gitlab-runner: image: gitlab/gitlab-runner:latest restart: always volumes: - ./gitlab-runner/config:/etc/gitlab-runner - /var/run/docker.sock:/var/run/docker.sock 注册 GitLab Runner 执行命令注册 123456789docker exec gitlab-runner gitlab-runner register -n \ --url https://gitlab.com/ \ --registration-token xxxxxxxxxx \ --executor docker \ --tag-list runInDk \ --description "My Docker Runner" \ --docker-image "docker:latest" \ --docker-volumes /var/run/docker.sock:/var/run/docker.sock \ --docker-volumes /root/.m2:/root/.m2 优化工作 Runner 默认情况下每执行一个 Job 都会重新拉取一次所需镜像，我们可把策略改为：镜像不存在时才拉取，编辑 config.toml 文件，修改 [runners.docker] 栏中加入 pull_policy = &quot;if-not-present&quot; 重启 Runner 容器，使之生效 编写项目的 gitlab-ci.yml 文件 后端项目 12345678910111213141516171819202122232425262728293031323334353637stages: - package - build - deploymy_package: image: maven:3.6.0-jdk-8-alpine stage: package script: - mvn clean package -DskipTests - cp Dockerfile target/Dockerfile cache: key: $&#123;CI_PIPELINE_ID&#125; paths: - target/ only: - master tags: - lvTestmy_build: stage: build cache: key: $&#123;CI_PIPELINE_ID&#125; paths: - target/ script: - cd target - docker build -t 192.168.88.4:5000/$&#123;CI_PROJECT_NAME&#125;:$&#123;CI_PIPELINE_ID&#125; . - docker push 192.168.88.4:5000/$&#123;CI_PROJECT_NAME&#125;:$&#123;CI_PIPELINE_ID&#125; tags: - lvTestmy_deploy: stage: deploy script: - docker stop lxwtest &amp;&amp; docker rm lxwtest - docker run -d -p 8888:8080 --restart=always --name=lxwtest 192.168.88.4:5000/$&#123;CI_PROJECT_NAME&#125;:$&#123;CI_PIPELINE_ID&#125; tags: - lvTest 前端项目]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 笔记]]></title>
    <url>%2F2019%2F06%2F08%2FEffective-Java-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1. 考虑使用静态工厂方法替代构造方法优点 通过方法名体现不同构造方式的差异 不需要每次调用时都创建一个新对象 ( 单例模式, 享元模式 ) 可以返回其返回类型的任何子类型的对象 在编写包含该方法的类时，返回的对象的类不需要存在 限制 没有公共或受保护构造方法的类不能被子类化 ( 因为大部分实现会将构造函数设为私有 ) 没有构造函数那么明显 2. 当构造方法参数过多时使用 builder 模式分析 可伸缩 (telescoping constructor) 构造方法模式, 多个不同参数数量的构造方法 当有很多参数时，很难编写代码，而且很难读懂它 JavaBeans 模式, 调用 setter 方法来设置参数 由于构造方法在多次调用中被分割，在过程中可能处于不一致的状态 Builder 模式, 构造方法为 private, 通过内嵌的 Builder 类调用 build() 返回本身 12NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100).sodium(35).carbohydrate(27).build(); 可以在 build() 里加入参数检查 编写简单, 易读 能区分必须和可选字段 平行层次的 Builder, 抽象类有抽象的 builder, 具体的类有具体的 builder 12345NyPizza pizza = new NyPizza.Builder(SMALL) .addTopping(SAUSAGE).addTopping(ONION).build();Calzone calzone = new Calzone.Builder() .addTopping(HAM).sauceInside().build(); 3. 使用私有构造方法或枚类实现 Singleton 属性私有构造方法 通过公共静态成员提供访问 123456// Singleton with public final fieldpublic class Elvis &#123; public static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public void leaveTheBuilding() &#123; ... &#125;&#125; 通过静态的工厂方法提供访问 优点: 可以灵活地改变你的想法 优点: 可以编写一个泛型单例工厂 优点: 方法引用可以用 Supplier 1234567 // Singleton with static factorypublic class Elvis &#123; private static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public static Elvis getInstance() &#123; return INSTANCE; &#125; public void leaveTheBuilding() &#123; ... &#125;&#125; 警告 可以使用 AccessibleObject.setAccessible 方法，以反射方式调用私有构造方法 为了维护单例的保证，声明所有的实例属性为 transient，并提供一个 readResolve 方法 枚举 声明单一元素的枚举类 简洁 提供了免费的序列化机制 提供了针对多个实例化的保证 12345// Enum singleton - the preferred approachpublic enum Elvis &#123; INSTANCE; public void leaveTheBuilding() &#123; ... &#125;&#125; 4. 使用私有构造方法执行非实例化 如一些工具类, 只包含静态方法, 可以用来避免其实例化和被继承 12345678// Noninstantiable utility classpublic class UtilityClass &#123; // Suppress default constructor for noninstantiability private UtilityClass() &#123; throw new AssertionError(); &#125; ... // Remainder omitted&#125; 5. 使用依赖注入取代硬连接资源(hardwiringresources) 不要使用单例或静态的实用类来实现一个类，该类依赖于一个或多个底层资源，这些资源的行为会影响类的行为，并且不让类直接创建这些资源。相反，将资源或工厂传递给构造方法 (或静态工厂或 builder 模式)。这种称为依赖注入的实践将极大地增强类的灵活性、可重用性和可测试性。 6. 避免创建不必要的对象 如果对象是不可变的，它总是可以被重用 注意无意识的自动装箱 (autoboxing) 在现代 JVM 实现上, 使用构造方法创建和回收小的对象其实是非常廉价的, 创建额外的对象以增强程序的清晰度，简单性或功能性通常是件好事 除非池中的对象非常重量级，否则通过维护自己的对象池来避免对象创建是一个坏主意 7. 消除过期的对象引用 当一个类自己管理内存时，程序员应该警惕内存泄漏问题 每当一个元素被释放时，元素中包含的任何对象引用都应该被清除 另一个常见的内存泄漏来源是缓存 只要在缓存之外存在对某个项 (entry) 的键 (key) 引用，那么这项就是明确有关联的，就可以用 WeakHashMap 来表示缓存 可以通过一个后台线程或将新的项添加到缓存时顺便清理 第三个常见的内存泄漏来源是监听器和其他回调 客户端注册回调, 仅将它们保存在 WeakHashMap 的键 (key) 中 8. 避免使用 Finalizer 和 Cleaner 机制缺点 不能保证他们能够及时执行 不要相信 System.gc 和 System.runFinalization 方法, 可能会增加被执行的几率，但不能保证一定会执行 在执行 Finalizer 机制过程中，未捕获的异常会被忽略 导致严重的性能损失 严重的安全问题: 它们会打开你的类来进行 Finalizer 机制攻击 正确做法 实现 AutoCloseable 接口，并要求客户在不再需要时调用每个实例 close 方法，通常使用 try-with-resources 确保终止 合法用途 作为一个安全网 (safetynet)，以防资源的拥有者忽略了它的 close 方法 与本地对等类(native peers)有关。本地对等类是一个由普通对象委托的本地 (非 Java) 对象。由于本地对等类不是普通的 Java 对象，所以垃圾收集器并不知道它，当它的 Java 对等对象被回收时，本地对等类也不会回收。 9. 使用 try-with-resources 语句替代 try-finally 语句对比 try-finally 12345678910111213141516// try-finally is ugly when used with more than one resource!static void copy(String src, String dst) throws IOException &#123; InputStream in = new FileInputStream(src); try &#123; OutputStream out = new FileOutputStream(dst); try &#123; byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); &#125; finally &#123; out.close(); &#125; &#125; finally &#123; in.close();&#125; &#125; try-with-resources 12345678// try-with-resources on multiple resources - short and sweetstatic void copy(String src, String dst) throws IOException &#123; try (InputStream in = new FileInputStream(src); OutputStream out = new FileOutputStream(dst)) &#123; byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0)&#125; &#125; 分析 用 try-finally 语句关闭资源, 有多个资源时容易犯错 try-with-resources 块和 finally 块中的代码都可能抛出异常 finally 块中close()时抛出的异常会冲掉前面的异常 try-with-resources 块中close()(不可见) 时抛出的异常会被抑制 (suppressed), 这些抑制的异常没 有被抛弃， 而是打印在堆栈跟踪中，并标注为被抑制了 10. 重写 equals 方法时遵守通用约定不覆盖 equals 方法的场景 每个类的实例都是固有唯一的 类不需要提供一个“逻辑相等(logical equality)”的测试功能 父类已经重写了 equals 方法，则父类行为完全适合于该子类 类是私有的或包级私有的 覆盖 equals 方法的场景 需要提供一个逻辑相等的判断, 且父类还没重写过equals 通用约定 自反性 (Reflexivity): 对于任何非空引用 x， x.equals(x) 必须返回 true 对称性 (Symmetry): 对于任何非空引用 x 和 y，如果且仅当 y.equals(x) == true, x.equals(y)必须为 true 传递性 (Transitivity): 对于任何非空引用 x、y、z，如果 x.equals(y) == true, y.equals(z) == true, 则x.equals(z)必须返回 true 一致性 (Consistent): 对于任何非空引用 x 和 y，如果在 equals 比较中使用的信息没有修改，则x.equals(y)的多次调用必须始终返回 true 或始终返回 false 非空性 (Non-nullity): 对于任何非空引用 x, x.equals(null) 必须返回 false 编写高质量 equals 方法 使用 instanceof 运算符来检查参数是否具有正确的类型, 再将参数转换为正确的类型 检查是否与类中的每个重要属性相匹配 不同类型的比较方式 对于类型为非 float 或 double 的基本类型，使用 == 运算符进行比较 对于对象引用属性，递归地调用 equals 方法 对于 float 基本类型的属性，使用静态方法 Float.compare(float, float) 对于 double 基本类型的属性，使用静态方法 Double.compare(double, double) 对于数组属性，将这些准则应用于每个元素 某些对象引用的属性可能合法地包含 null。 为避免出现 NullPointerException 异常，请使用静态方法Objects.equals(Object, Object) 检查这些属性是否相等 性能优化 用 == 运算符检查参数是否为该对象的引用, 如果是, 返回 true 首先比较最可能不同的属性, 开销比较小的属性 不要比较不属于对象逻辑状态的属性 不需要比较可以从“重要属性”计算出来的派生属性 注意 当重写 equals 方法时，同时也要重写 hashCode 方法 不要让 equals 方法试图太聪明, 例如File 类不应该试图将引用的符号链接等同于同一文件对象 在 equal 时方法声明中，不要将参数 Object 替换成其他类型 11. 重写 equals 方法时同时也要重写 hashcode 方法Object 规范 当在一个应用程序执行过程中，如果在 equals 方法比较中没有修改任何信息，在一个对象上重复调用 hashCode 方法时，它必须始终返回相同的值。从一个应用程序到另一个应用程序的每一次执行返回的值可以是不一致的。 如果两个对象根据 equals(Object) 方法比较是相等的，那么在两个对象上调用 hashCode 就必须产生的结果是相同的整数。 如果两个对象根据 equals(Object) 方法比较并不相等，则不要求在每个对象上调用 hashCode 都必须产生不同的结果。 但是，程序员应该意识到，为不相等的对象生成不同的结果可能会提高散列表(hash tables)的性能。 一个简单的配方12345678// Typical hashCode method@Overridepublic int hashCode() &#123; int result = Short.hashCode(areaCode); result = 31 * result + Short.hashCode(prefix); result = 31 * result + Short.hashCode(lineNum); return result;&#125; 基本类型，使用 Type.hashCode(f) 方法计算，其中 Type 类是对应属性 f 基本类型的包装类。 如果该属性是一个对象引用，并且该类的 equals 方法通过递归调用 equals 来比较该属性，并递归地调用 hashCode 方法。 如果需要更复杂的比较，则计算此字段的“范式(“canonical representation)”，并在范式上调用 hashCode。 如果该字段的值为空，则使用 0(也可以使用其他常数，但通常来使用 0 表示)。 如果属性 f 是一个数组，把它看作每个重要的元素都是一个独立的属性。 也就是说，通过递归地应用 这些规则计算每个重要元素的哈希码，并且将每个步骤的值合并。 如果数组没有重要的元素，则使用一个常量，最好不要为 0。如果所有元素都很重要，则使用 Arrays.hashCode 方法。 12. 始终重写 toString 方法 便于调试 13. 谨慎地重写 clone 方法缺陷 Cloneable 接口缺少 clone 方法, 而 Object 的 clone 方法是受保护的, 所以不能保证调用成功 clone 方法的通用规范 ( 非绝对 ) x.clone() != x x.clone().getClass() == x.getClass() x.clone().equals(x) == true 如果一个 final 类有一个不调用 super.clone 的 clone 方法, 那么这个类没有理由实现 Cloneable 接口，因为它不依赖于 Object 的 clone 实现的行为 复制构造方法及其静态工厂变体与 Cloneable/clone 相比有许多优点 不依赖风险很大的语言外的对象创建机制 不要求遵守那些不太明确的惯例 不会与 final 属性的正确使用相冲突 不会抛出不必要的检查异常 不需要类型转换 14. 考虑实现 Comparable 接口 如果你正在编写具有明显自然顺序(如字母顺序，数字顺序或时间顺序)的值类，则应该实现 Comparable 接口: 123public interface Comparable&lt;T&gt; &#123; int compareTo(T t);&#125; compareTo 方法的通用约定 将此对象与指定的对象按照排序进行比较, 返回值可能为负整数, 零或正整数, 因为此对象对应小于，等于或大于指定的对象。 如果指定对象的类型与此对象不能进行比较，则引发 ClassCastException 异常 实现类必须确保所有 x 和 y 都满足 sgn(x.compareTo(y)) == -sgn(y. compareTo(x))。 （这意味着 当且仅当 y.compareTo(x) 抛出异常时， x.compareTo(y) 必须抛出异常。） 实现类还必须确保该关系是可传递的：(x. compareTo(y) &gt; 0 &amp;&amp; y.compareTo(z) &gt; 0) 意味着x.compareTo(z) &gt; 0 。 对于所有的 z，实现类必须确保 x.compareTo(y) == 0 意味着 sgn(x.compareTo(z)) == sgn(y.compareTo(z)) 。 推荐 (x.compareTo(y) == 0) == (x.equals(y)) ，但不是必需的。 一般来说，任何实现了 Comparable 接口的类违反了这个条件都应该清楚地说明这个事实。 推荐的语言是 “注意：这个类有一个自然顺序，与 equals 不一致”。 使用包装类中的静态 compare 方法或 Comparator 接口中的构建方法 12345678910// Comparator based on static compare methodstatic Comparator&lt;Object&gt; hashCodeOrder = new Comparator&lt;&gt;() &#123; public int compare(Object o1, Object o2) &#123; return Integer.compare(o1.hashCode(), o2.hashCode()); &#125;&#125;;// Comparator based on Comparator construction methodstatic Comparator&lt;Object&gt; hashCodeOrder = Comparator.comparingInt(o -&gt; o.hashCode()); 请避免使用 “&lt;” 和 “&gt;” 运算符 15. 使类和成员的可访问性最小化 使用尽可能低的访问级别 类具有公共静态 final 数组属性，或返回这样一个属性的访问器是错误的 12// Potential security hole!public static final Thing[] VALUES = &#123; ... &#125;; 有两种方法可以解决这个问题 你可以使公共数组私有并添加一个公共的不可变列表： 123private static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final List&lt;Thing&gt; VALUES = Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES)); 可以将数组设置为 private，并添加一个返回私有数组拷贝的公共方法： 1234private static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final Thing[] values() &#123; return PRIVATE_VALUES.clone();&#125; 16. 在公共类中使用访问方法而不是公共属性 如果一个类在其包之外是可访问的，则提供访问方法来保留更 改类内部表示的灵活性 如果一个类是包级私有的，或者是一个私有的内部类，那么暴露它的数据属性就没有什么本质上的错误 17. 最小化可变性要使一个类不可变，请遵循以下五条规则 不要提供修改对象状态的方法（也称为 mutators） 确保这个类不能被继承 把所有属性设置为 final 把所有的属性设置为 private 确保对任何可变组件的互斥访问 ( 确保该类的客户端无法获得对这些对象的引用 ) 不可变对象本质上是线程安全的 不需要也不应该在一个不可变的类上提供一个 clone 方法或拷贝构造方法（copy constructor） 一个不可变的类可以提供静态的工厂来缓存经常被请求的实例 一个类不得允许子类化, 可以设置类为 final , 更灵活的方式是使其所有的构造方法私有或包级私有，并添加公共静态工厂，而不是公共构造方法 如果一个类不能设计为不可变类，那么也要尽可能地限制它的可变性 18. 组合优于继承 与方法调用不同，继承打破了封装 , 父类的实现可能会不断变化, 子类可能会被破坏，即使它的代码没有任何改变 包装类 ( 装饰器模式 ) 有时组合和转发的结合被不精确地地称为委托 (delegation). 从技术上讲，除非包装对象把自身传递给被包装对象，否则不是委托 包装类的缺点 包装类不适合在回调框架（callback frameworks）中使用，其中对象将自我引用传递给其他对象以用于后续调用（“回调”） 编写转发方法有些繁琐 只有在子类真的是父类的子类型的情况下，继承才是合适的 19. 如使用继承则设计，应当文档说明，否则不该使用 这个类必须准确地描述重写这个方法带来的影响 测试为继承而设计的类的唯一方法是编写子类, 经验表明，三个子类通常足以测试一个可继承的类。 这些子类应该由父类作者以外的人编写 构造方法绝不能直接或间接调用可重写的方法 如果你决定在为继承而设计的类中实现 Cloneable 或 Serializable 接口, 那么 clone 和 readObject 都不会直接或间接调用可重写的方法 20. 接口优于抽象类 Java 只允许单一继承 接口是定义混合类型（mixin）的理想选择, 允许构建非层级类型的框架 可以通过提供一个抽象的骨架实现类（abstract skeletal implementation class）来与接口一起使用，将接口和抽象类的优点结合起来。 接口定义了类型，可能提供了一些默认的方法，而骨架实现类在原始接口方法的顶层实现了剩余的非原始接口方法。 继承骨架实现需要大部分的工作来实现一个接口。 这就是模板方法设计模式 21. 为后代设计接口 编写一个默认方法并不总是可能的，它保留了每个可能的实现的所有不变量 在默认方法的情况下，接口的现有实现类可以在没有错误或警告的情况下编译，但在运行时会失败 22. 接口仅用来定义类型 常量接口模式是对接口的糟糕使用 23. 优先使用类层次而不是标签类24. 优先考虑静态成员类 非静态成员类的每个实例都隐含地与其包含的类的宿主实例相关联, 可以调用宿主实例上的方法, 不可能在没有宿主实例的情况下创建非静态成员类的实例 非静态成员类的一个常见用法 1234567891011// Typical use of a nonstatic member classpublic class MySet&lt;E&gt; extends AbstractSet&lt;E&gt; &#123; ... // Bulk of the class omitted @Override public Iterator&lt;E&gt; iterator() &#123; return new MyIterator(); &#125; private class MyIterator implements Iterator&lt;E&gt; &#123; ... &#125;&#125; 如果你声明了一个不需要访问宿主实例的成员类，总是把 static 修饰符放在它的声明中，使它成为一个静态成员类，而不是非静态的成员类 有四种不同的嵌套类，每个都有它的用途。 如果一个嵌套的类需要在一个方法之外可见，或者太长而不能很好地适应一个方法，使用一个成员类。 如果一个成员类的每个实例都需要一个对其宿主实例的引用，使其成为非静态的; 否则，使其静态。 假设这个类属于一个方法内部，如果你只需要从一个地方创建实例，并且存在一个预置类型来说明这个类的特征，那么把它作为一个匿名类; 否则，把它变成局部类。 25. 将源文件限制为单个顶级类26. 不要使用原始类型 如果你使用原始类型，则会丧失泛型的所有安全性和表达上的优势 以下是使用泛型类型的 instanceof 运算符的首选方法 12345// Legitimate use of raw type - instanceof operatorif (o instanceof Set) &#123; // Raw type Set&lt;?&gt; s = (Set&lt;?&gt;) o; // Wildcard type ...&#125; 27. 消除非检查警告 尽可能 地消除每一个未经检查的警告 如果你不能消除警告，但你可以证明引发警告的代码是类型安全的，那么（并且只能这样）用@SuppressWarnings(“unchecked”) 注解来抑制警告 每当使用 @SuppressWarnings(“unchecked”) 注解时，请添加注释，说明为什么是安全的 28. 列表优于数组29. 优先考虑泛型30. 优先使用泛型方法31. 使用限定通配符来增加 API 的灵活性12345// pushAll method without wildcard type - deficient!public void pushAll(Iterable&lt;E&gt; src) &#123; for (E e : src) push(e);&#125; 假设有一个 Stack&lt;Number&gt;，并调用 push(intVal)，其中 intVal 的类型是 Integer, 会得到错误消息 12345// Wildcard type for a parameter that serves as an E producerpublic void pushAll(Iterable&lt;? extends E&gt; src) &#123; for (E e : src) push(e);&#125; 为了获得最大的灵活性，对代表生产者或消费者的输入参数使用通配符类型 producer-extends, consumer-super（PECS） 如果一个参数化类型代表一个 T 生产者，使用 &lt;? extends T&gt; 如果它代表 T 消费者，则使用 &lt;? super T&gt; 改造 max 方法 123public static &lt;T extends Comparable&lt;T&gt;&gt; T max(List&lt;T&gt; list)public static &lt;T extends Comparable&lt;? super T&gt;&gt; T max(List&lt;? extends T&gt; list) max 方法返回 T , 所以 List&lt;? extends T&gt; list Comparable 的 T 消费 T 实例（并生成指示顺序关系的整数）, 所以 &lt;T extends Comparable&lt;? super T&gt;&gt; 32. 合理地结合泛型和可变参数 在 Java 7 中， @SafeVarargs 注解已添加到平台，以允许具有泛型可变参数的方法的作者自动禁止客户端警 告 如果可变参数数组仅用于从调用者向方法传递可变数量的参数, 那么该方法是安全的 33. 优先考虑类型安全的异构容器]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>effective-java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 关键字 transient]]></title>
    <url>%2F2019%2F05%2F31%2FJava-%E5%85%B3%E9%94%AE%E5%AD%97-transient%2F</url>
    <content type="text"><![CDATA[transient 一旦变量被 transient 修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 transient 关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被 transient 关键字修饰的。变量如果是用户自定义类变量，则该类需要实现 Serializable 接口。 一个静态变量不管是否被 transient 修饰，均不能被序列化。 参考: https://www.cnblogs.com/lanxuezaipiao/p/3369962.html]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串池、常量池（运行时常量池、Class常量池）、intern]]></title>
    <url>%2F2019%2F05%2F30%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%B1%A0%E3%80%81%E5%B8%B8%E9%87%8F%E6%B1%A0%EF%BC%88%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%E3%80%81Class%E5%B8%B8%E9%87%8F%E6%B1%A0%EF%BC%89%E3%80%81intern%2F</url>
    <content type="text"><![CDATA[重点： Class 常量池 是编译期生成的 .class 文件中的常量池 运行时常量池 是 Class 常量池 在运行时的表示形式 字符串常量池 是缓存字符串的，全局共享，它保存的是 String 实例对象的引用 Class 常量池 常量池中主要存放两大类常量：字面量（Literal） 和 符号引用（Symbolic Reference），字面量比较接近于 Java 语言层面的常量概念，如文本字符串 、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念，包括了下面三类常量： 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 通过 javap 命令可以看到 .class 文件的常量池部分。 运行时常量池 运行时常量池（Runtime Constant Pool）是方法区的一部分，它是 Class 文件中每一个类或接口的常量池表的运行时表示形式。Class 常量池中存放的编译期生成的各种字面量和符号引用，将在类加载后进入方法区的运行时常量池中存放。 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态常量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆）。目的应该是与 Java 堆区分开来。 字符串常量池 字符串常量池是用来缓存字符串的。对于需要重复使用的字符串，每次都去 new 一个 String 实例，无疑是在浪费资源，降低效率。所以，JVM 一般会维护一个字符串常量池，它是全局共享的，你可是把它看成是一个 HashSet&lt;String&gt;。需要注意的是，它保存的是堆中字符串实例的引用，并不存储实例本身。 在 JDK 1.6, 常量池是在永久代中的，和 Java 堆是完全分开来的区域 在 JDK 1.7, 常量池在堆中 String.intern() 查找当前字符串常量池是否存在该字符串的引用，如果存在直接返回引用；如果不存在，则在堆中创建该字符串实例，并返回其引用。]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-安装-Ubuntu-国内环境]]></title>
    <url>%2F2019%2F05%2F30%2Fk8s-%E5%AE%89%E8%A3%85-Ubuntu-%E5%9B%BD%E5%86%85%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[参考: https://zhuanlan.zhihu.com/p/46341911 https://juejin.im/post/5ca6ff3a51882543e10ecb36 添加相应的源 由于需要下载Kubeadm，Kubelet和Kubernetes-cni，多以需要添加源。 123cat &lt;&lt;EOF &gt; /etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial mainEOF 下载Docker &amp; Kubeadm &amp; Kubelet &amp; Kubernetes-cni 1apt-get update &amp;&amp; apt-get install -y docker.io kubelet kubernetes-cni=0.7.5-00 kubeadm 添加源之后，使用 apt-get update 命令会出现错误，原因是缺少相应的key，可以通过下面命令添加(E084DAB9 为上面报错的key后8位)：1234gpg --keyserver keyserver.ubuntu.com --recv-keys E084DAB9gpg --export --armor E084DAB9 | sudo apt-key add -apt-get update &amp;&amp; apt-get install -y docker.io kubelet kubernetes-cni=0.7.5-00 kubeadm 调整系统参数 1234567sudo swapoff -a # 暂时关闭 swapoff sudo systemctl stop ufw.service # 关闭防火墙 sudo /etc/init.d/apparmor stop # 停止 AppArmorsudo modprobe br_netfiltersudo echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptablessudo echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tablessudo sysctl -p 获取镜像列表 由于官方镜像地址被墙，所以我们需要首先获取所需镜像以及它们的版本。然后从国内镜像站获取。1kubeadm config images list 获取镜像列表后可以通过下面的脚本从阿里云获取：123456789101112131415images=( # 下面的镜像应该去除"k8s.gcr.io/"的前缀，版本换成上面获取到的版本 kube-apiserver:v1.14.2 kube-controller-manager:v1.14.2 kube-scheduler:v1.14.2 kube-proxy:v1.14.2 pause:3.1 etcd:3.3.10 coredns:1.3.1)for imageName in $&#123;images[@]&#125; ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageNamedone master 初始化环境1kubeadm init --kubernetes-version=v1.14.2 --apiserver-advertise-address=192.168.14.177 --apiserver-cert-extra-sans=122.112.207.8 --pod-network-cidr=10.244.0.0/16 1234567--apiserver-advertise-address=&lt;ip&gt;指定 apiserver 的访问 ip, ip 默认为当前虚拟机的默认网卡 ip.当 ip 为内网地址时, k8s 集群只能搭建在网段内部,如果有需求通过外网 ip 来操作 apiserver,需要在启动集群时添加可信参数 --apiserver-cert-extra-sans=116.196.81.106 将外网的 ip 添加进去. 当 ip 为外网地址时,可以实现不同网段的虚拟机组成 k8s 集群. 配置授权信息 所需的命令在init成功后也会有提示，主要是为了保存相关的配置信息在用户目录下，这样不用每次都输入相关的认证信息。123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 添加网络插件 ( flannel ) 上面安装成功后如果通过查询 kube-system 下 Pod 的运行情况，会发现和网络相关的 Pod 都处于 Pending 的状态，这是因为缺少相关的网络插件，而网络插件有很多个，可以选择自己需要的。1kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel 查看是否安装成功1kubectl get pods -n kube-system 如果出现类似下面的情况就说明安装完成了12345678NAME READY STATUS RESTARTS AGEcoredns-86c58d9df4-mmjls 1/1 Running 0 6h26mcoredns-86c58d9df4-p7brk 1/1 Running 0 6h26metcd-promote 1/1 Running 1 6h26mkube-apiserver-promote 1/1 Running 1 6h26mkube-controller-manager-promote 1/1 Running 1 6h25mkube-proxy-6ml6w 1/1 Running 1 6h26mkube-scheduler-promote 1/1 Running 1 6h25m node 加入集群 根据 master 节点 init 后提供的 join 命令加入集群 1kubeadm join 192.168.14.177:6443 --token 3pkmi4.okabu6926c6pfett --discovery-token-ca-cert-hash sha256:138262f072252dd81692cf02ed5cb0d090202a67db38962c6e64b1bb065b6014 在 master 节点确认 1kubectl get nodes 节点都为 Ready 状态说明集群已经正确启动了。 1234NAME STATUS ROLES AGE VERSIONndoe2 Ready master 3h38m v1.14.2node1 Ready &lt;none&gt; 28s v1.14.2node3 Ready &lt;none&gt; 3h2m v1.14.2 其他 节点之间的 hostname 不能重复, 修改命令为 1sudo hostnamectl set-hostname &#123;$name&#125; 默认情况下，通过 kubeadm create token 创建的 token ，过期时间是24小时，这就是为什么过了一天无法再次使用之前记录的 kube join 原生脚本的原因，也可以运行 kubeadm token create --ttl 0 生成一个永不过期的 token 查看 token 1$ kubeadm token list 查看 CA证书 sha256 1openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' 删除节点 12345(master)kubectl drain $&#123;nodename&#125; --delete-local-datakubectl delete node $&#123;nodename&#125; 1234567891011121314(node)kubeadm resetsystemctl stop kubeletsystemctl stop dockerrm -rf /var/lib/cni/rm -rf /var/lib/kubelet/*rm -rf /etc/cni/ifconfig cni0 downifconfig flannel.1 downifconfig docker0 downip link delete cni0ip link delete flannel.1systemctl start docker 获取 master 的 join token 1kubeadm token create --print-join-command]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>install</tag>
      </tags>
  </entry>
</search>
