<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mysql 定时备份 (基于 Dokcer 运行)]]></title>
    <url>%2F2020%2F01%2F17%2FMysql-%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD-(%E5%9F%BA%E4%BA%8E-Dokcer-%E8%BF%90%E8%A1%8C)%2F</url>
    <content type="text"><![CDATA[脚本编写 vim mysql_bak.sh 123456789101112131415161718192021222324252627282930#!/bin/sh# 数据库相关配置host=1.2.3.4port=3306user=rootpassword=123456db_name=db# 存放目录 (绝对路径)backupdir=/mysqlbackup# 保留天数time=1echo "开始备份数据库";# 生成脚本echo "mysqldump --host=$host --port=$port -u$user -p$password --extended-insert $db_name | gzip &gt; /mysqlbackup/$db_name`date +%Y-%m-%d_%H%M%S`.sql.gz" &gt; $backupdir/run.sh# 赋权sudo chmod 744 $backupdir/run.sh# 启动 docker 运行脚本docker run --rm -v $backupdir:/mysqlbackup mysql:5.7 /mysqlbackup/run.sh# 删除 time 天前的备份文件, 若要改为分钟, 使用 -mminfind $backupdir -name $db_name"*.sql.gz" -type f -mtime +$time -exec rm -rf &#123;&#125; \; echo "备份完成"; 赋权 sudo chmod 744 mysql_bak.sh 执行测试是否成功 sudo ./mysql_bak.sh 查看对应目录下是否生成备份文件 配置定时任务 用 crontab 定时执行备份脚本代码 sudo crontab -u root -e 以 root 身份打开编辑 crontab 的工作内容 加入内容, 若要每小时 30 分时备份, 输入以下内容 30 * * * * /(脚本所在路径)/mysql_bak.sh &gt;&gt; /(脚本所在路径)/mysql_bak.log Ubuntu 系统默认是不打开 cron 日志, 需要配置: 打开文件 sudo vi /etc/rsyslog.d/50-default.conf 在文件中找到 cron.*，把前面的 # 去掉 保存退出 重新加载配置 sudo service rsyslog restart 查看日志 tail -f /var/log/cron.log 其他 恢复数据时, 可能会因为 sql 文件过大报错, 需要修改 max_allowed_packet 的值, 默认为 4MB 12345678# 查看当前max_allowed_packet的值mysql&gt; show variables like &apos;max_allowed_packet&apos;;# 数据库中临时修改（重启数据库后失效）, 最大可以设置为 1Gmysql&gt; set global max_allowed_packet = 1 * 1024 * 1024 * 1024;# 需要退出保存mysql&gt; exit]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb 集群分片与容灾备份 (基于 Dokcer Swarm 部署)]]></title>
    <url>%2F2020%2F01%2F16%2FMongoDb-%E9%9B%86%E7%BE%A4%E5%88%86%E7%89%87%E4%B8%8E%E5%AE%B9%E7%81%BE%E5%A4%87%E4%BB%BD-(%E5%9F%BA%E4%BA%8E-Dokcer-Swarm-%E9%83%A8%E7%BD%B2)%2F</url>
    <content type="text"><![CDATA[基础概念 副本集 (Replica Set) 分片 (Sharding)]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-swarm</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 基本使用]]></title>
    <url>%2F2019%2F08%2F02%2FDocker-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[停止并删除所有容器1$ docker stop $(docker ps -q) docker rm $(docker ps -aq) 清理镜像12345# 清理 dangling 镜像$ docker rmi $(docker images -f "dangling=true" -q)# 根据通配符查找删除指定镜像$ docker rmi $(docker images -f "reference=*" --format "&#123;&#123;.Repository&#125;&#125;:&#123;&#123;.Tag&#125;&#125;") 创建 Swarm 集群以及其基本操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 修改 node name￼$ sudo hostnamectl set-hostname &#123;$name&#125;￼$ sudo systemctl restart docker# ￼manager: 创建 swarm 集群￼$ ￼docker swarm init# 创建 swarm 集群时指定 ip 和通讯的 udp 端口 (针对云服务器上部分环境时需用到)$ docker swarm init --advertise-addr 1.2.3.4 --data-path-port 12345# ￼node: 加入 swarm 集群￼$ ￼docker swarm join ......# ￼获取加入token￼$ ￼docker swarm join-token [worker|manager]# ￼manager: 查看节点￼$ ￼docker node ls# 部署单个服务$ docker service create --replicas 3 -p 80:80 --name nginx nginx# 查看服务$ docker service ls # 服务伸缩$ docker service scale nginx=5# 删除服务$ docker service rm nginx# 根据 yaml 文件部署包含多个服务的 stack$ docker stack deploy -c xxxx.yml one-stack# 根据 yaml 文件部署 stack 时能读取同层 .env 文件内设置的环境变量$ docker stack deploy -c &lt;(docker-compose -f xxxx.yml config) one-stack# 根据 yaml 文件部署 stack 时能读取同层 .env 文件内设置的环境变量, 从私库拉取镜像$ docker stack deploy --with-registry-auth -c &lt;(docker-compose -f xxxx.yml config) one-stack# 查看 stack$ docker stack ls # 查看 stack 中的服务$ docker stack ps one-stack # 停止删除 stack (该命令不会移除服务所使用的数据卷，移除数据卷用 docker volume rm)$ docker stack down one-stack# 更新 service 镜像, 从私库拉取$ docker service update --with-registry-auth --image image-name:tag service-name# 批量删除 service$ docker service rm $(docker service ls -qf name=)# 指定 service 在某个 node 运行# 给 node 打标签$ docker node update --label-add run-a=1 xxxxxx# 给 service 加入约束条件$ docker service update --constraint-add "node.labels.run-a==1" swarm_a Docker Compose 文件相关配置 参考官方文档 yaml 中重用代码块 12345678910test: &amp;base a: 1 b: 2use1: *baseuse2: &lt;&lt;: *base b: 3 c: 4 123456789101112test: a: 1 b: 2 use1: a: 1 b: 2 use2: a: 1 b: 3 c: 4]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-swarm</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在服务器上的相关运维操作]]></title>
    <url>%2F2019%2F08%2F02%2F%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[安装 Docker 其他系统的安装可以参考官方文档 Ubuntu 12345678910111213141516171819202122232425262728# 安装 Docker 依赖库$ sudo apt-get update $ sudo apt-get install apt-transport-https ca-certificates \ gnupg-agent software-properties-common \ curl# 清理过去遗留的老版本 $ sudo apt-get remove docker docker-engine docker.io containerd runc# 添加 Docker 官方的 GPG key$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 添加 docker 仓库$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"# 安装 Docker CE$ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io# 验证$ sudo docker run hello-world# 配置镜像加速器$ echo '&#123; "registry-mirrors": ["https://umbmb1yu.mirror.aliyuncs.com"] &#125;' | sudo tee /etc/docker/daemon.json$ sudo systemctl daemon-reload$ sudo systemctl restart docker# 登录私库$ sudo docker login --username=abmatrix registry.cn-hangzhou.aliyuncs.com 12# 使用阿里官方安装脚本自动安装 （仅适用于公网环境）$ sudo curl -fsSL https://get.docker.com | sudo bash -s docker --mirror Aliyun 删除 Docker12345# 卸载 Docker CE 包$ sudo apt-get purge docker-ce# 删除 images、containers 和 volumes$ sudo rm -rf /var/lib/docker 修改 hostname12# 修改 hostname$ hostnamectl set-hostname abm-aliyun-x 添加用户并并将用户加入 Docker 组12345678910111213141516171819202122# 添加用户$ adduser abm# 加入 sudo 权限$ chmod u+w /etc/sudoers$ echo "abm ALL=(ALL:ALL) ALL" &gt;&gt; /etc/sudoers$ chmod u-w /etc/sudoers# 查看是否存在 docker 组$ cat /etc/group | grep docker# 不存的话创建 docker 分组$ groupadd docker# 对应用户登录# 将用户添加 docker 分组$ sudo gpasswd -a $USER docker$ newgrp docker# 设置权限$ sudo chown "$USER":"$USER" /home/"$USER"/.docker -R$ sudo chmod g+rwx "/home/$USER/.docker" -R Docker 其他组件安装12345678# 安装 docker-compose$ sudo curl -L "https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose# 设置权限$ sudo chmod +x /usr/local/bin/docker-compose# 安装命令补全$ sudo curl -L https://raw.githubusercontent.com/docker/compose/1.24.1/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose 修改 Docker 储存位置1234567891011# 停止服务$ sudo service docker stop# 转移$ sudo mv /var/lib/docker /mnt/data/docker# 创建软链接$ sudo ln -s /mnt/data/docker /var/lib/docker# 启动服务$ sudo service docker start 设置防火墙规则123456789101112131415161718# 指定端口$ sudo ufw allow 22# Docker Swarm 相关端口$ sudo ufw allow 2376/tcp$ sudo ufw allow 2377/tcp$ sudo ufw allow 7946/tcp$ sudo ufw allow 7946/udp$ sudo ufw allow 4789/udp# 指定 ip$ sudo ufw allow from 123.123.123.123# 开启$ sudo ufw enable# 重新加载$ sudo ufw reload]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab Devops 配置]]></title>
    <url>%2F2019%2F06%2F13%2FGitlab-Devops-%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在 Kubernetes 集群上安装 Gitlab-Runnerhttps://docs.gitlab.com/runner/install/kubernetes.html 123kubectl patch deploy --namespace kube-system tiller-deploy -p '&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'helm install --namespace gitlab --name gitlab-runner -f values.yaml gitlab/gitlab-runner values.yaml 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282## GitLab Runner Image#### By default it's using gitlab/gitlab-runner:alpine-v&#123;VERSION&#125;## where &#123;VERSION&#125; is taken from Chart.yaml from appVersion field#### ref: https://hub.docker.com/r/gitlab/gitlab-runner/tags/##image: gitlab/gitlab-runner:alpine-v12.0.0-rc1## Specify a imagePullPolicy## 'Always' if imageTag is 'latest', else set to 'IfNotPresent'## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images##imagePullPolicy: IfNotPresent## The GitLab Server URL (with protocol) that want to register the runner against## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-register##gitlabUrl: https://gitlab.com/## The Registration Token for adding new Runners to the GitLab Server. This must## be retrieved from your GitLab Instance.## ref: https://docs.gitlab.com/ce/ci/runners/README.html##runnerRegistrationToken: "NkeYywTkYwWf14JZxtM1"## The Runner Token for adding new Runners to the GitLab Server. This must## be retrieved from your GitLab Instance. It is token of already registered runner.## ref: (we don't yet have docs for that, but we want to use existing token)### runnerToken: ""### Unregister all runners before termination#### Updating the runner's chart version or configuration will cause the runner container## to be terminated and created again. This may cause your Gitlab instance to reference## non-existant runners. Un-registering the runner before termination mitigates this issue.## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-unregister##unregisterRunners: true## Set the certsSecretName in order to pass custom certficates for GitLab Runner to use## Provide resource name for a Kubernetes Secret Object in the same namespace,## this is used to populate the /etc/gitlab-runner/certs directory## ref: https://docs.gitlab.com/runner/configuration/tls-self-signed.html#supported-options-for-self-signed-certificates### certsSecretName:## Configure the maximum number of concurrent jobs## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section##concurrent: 10## Defines in seconds how often to check GitLab for a new builds## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section##checkInterval: 30## Configure GitLab Runner's logging level. Available values are: debug, info, warn, error, fatal, panic## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section### logLevel:## For RBAC support:rbac: create: true ## Run the gitlab-bastion container with the ability to deploy/manage containers of jobs ## cluster-wide or only within namespace clusterWideAccess: false ## Use the following Kubernetes Service Account name if RBAC is disabled in this Helm chart (see rbac.create) ## # serviceAccountName: default## Configure integrated Prometheus metrics exporter## ref: https://docs.gitlab.com/runner/monitoring/#configuration-of-the-metrics-http-servermetrics: enabled: true## Configuration for the Pods that that the runner launches for each new job##runners: ## Default container image to use for builds when none is specified ## image: ubuntu:16.04 ## Specify one or more imagePullSecrets ## ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/ ## # imagePullSecrets: [] ## Specify the image pull policy: never, if-not-present, always. The cluster default will be used if not set. ## # imagePullPolicy: "" ## Defines number of concurrent requests for new job from GitLab ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-section ## # requestConcurrency: 1 ## Specify whether the runner should be locked to a specific project: true, false. Defaults to true. ## # locked: true ## Specify the tags associated with the runner. Comma-separated list of tags. ## ## ref: https://docs.gitlab.com/ce/ci/runners/#using-tags ## tags: "k8s-runner" ## Run all containers with the privileged flag enabled ## This will allow the docker:dind image to run if you need to run Docker ## commands. Please read the docs before turning this on: ## ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-dind ## privileged: true ## The name of the secret containing runner-token and runner-registration-token # secret: gitlab-runner ## Namespace to run Kubernetes jobs in (defaults to the same namespace of this release) ## namespace: gitlab ## Distributed runners caching ## ref: https://gitlab.com/gitlab-org/gitlab-runner/blob/master/docs/configuration/autoscale.md#distributed-runners-caching ## ## If you want to use s3 based distributing caching: ## First of all you need to uncomment General settings and S3 settings sections. ## ## Create a secret 's3access' containing 'accesskey' &amp; 'secretkey' ## ref: https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/ ## ## $ kubectl create secret generic s3access \ ## --from-literal=accesskey="YourAccessKey" \ ## --from-literal=secretkey="YourSecretKey" ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ ## ## If you want to use gcs based distributing caching: ## First of all you need to uncomment General settings and GCS settings sections. ## ## Access using credentials file: ## Create a secret 'google-application-credentials' containing your application credentials file. ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section ## You could configure ## $ kubectl create secret generic google-application-credentials \ ## --from-file=gcs-applicaton-credentials-file=./path-to-your-google-application-credentials-file.json ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ ## ## Access using access-id and private-key: ## Create a secret 'gcsaccess' containing 'gcs-access-id' &amp; 'gcs-private-key'. ## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-gcs-section ## You could configure ## $ kubectl create secret generic gcsaccess \ ## --from-literal=gcs-access-id="YourAccessID" \ ## --from-literal=gcs-private-key="YourPrivateKey" ## ref: https://kubernetes.io/docs/concepts/configuration/secret/ cachePath: "/opt/gitlab_runner/cache" cache: &#123;&#125; ## General settings # cacheType: s3 # cachePath: "/opt/gitlab_runner/cache" # cacheShared: true ## S3 settings # s3ServerAddress: s3.amazonaws.com # s3BucketName: # s3BucketLocation: # s3CacheInsecure: false # secretName: s3access ## GCS settings # gcsBucketName: ## Use this line for access using access-id and private-key # secretName: gcsaccess ## Use this line for access using google-application-credentials file # secretName: google-application-credentials ## Build Container specific configuration ## builds: &#123;&#125; # cpuLimit: 200m # memoryLimit: 256Mi # cpuRequests: 100m # memoryRequests: 128Mi # image: gitlab/gitlab-runner-helper:x86_64-latest ## Service Account to be used for runners ## # serviceAccountName: ## If Gitlab is not reachable through $CI_SERVER_URL ## # cloneUrl: ## Specify node labels for CI job pods assignment ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ ## # nodeSelector: &#123;&#125; ## Specify pod labels for CI job pods ## # podLabels: &#123;&#125; ## Specify annotations for job pods, useful for annotations such as iam.amazonaws.com/role # podAnnotations: &#123;&#125; ## Configure environment variables that will be injected to the pods that are created while ## the build is running. These variables are passed as parameters, i.e. `--env "NAME=VALUE"`, ## to `gitlab-runner register` command. ## ## Note that `envVars` (see below) are only present in the runner pod, not the pods that are ## created for each build. ## ## ref: https://docs.gitlab.com/runner/commands/#gitlab-runner-register ## # env: # NAME: VALUE## Configure resource requests and limits## ref: http://kubernetes.io/docs/user-guide/compute-resources/##resources: &#123;&#125; # limits: # memory: 256Mi # cpu: 200m # requests: # memory: 128Mi # cpu: 100m## Affinity for pod assignment## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity##affinity: &#123;&#125;## Node labels for pod assignment## Ref: https://kubernetes.io/docs/user-guide/node-selection/##nodeSelector: &#123;&#125; # Example: The gitlab runner manager should not run on spot instances so you can assign # them to the regular worker nodes only. # node-role.kubernetes.io/worker: "true"## List of node taints to tolerate (requires Kubernetes &gt;= 1.6)## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/##tolerations: [] # Example: Regular worker nodes may have a taint, thus you need to tolerate the taint # when you assign the gitlab runner manager with nodeSelector or affinity to the nodes. # - key: "node-role.kubernetes.io/worker" # operator: "Exists"## Configure environment variables that will be present when the registration command runs## This provides further control over the registration process and the config.toml file## ref: `gitlab-runner register --help`## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html### envVars:# - name: RUNNER_EXECUTOR# value: kubernetes## list of hosts and IPs that will be injected into the pod's hosts filehostAliases: [] # Example: # - ip: "127.0.0.1" # hostnames: # - "foo.local" # - "bar.local" # - ip: "10.1.2.3" # hostnames: # - "foo.remote" # - "bar.remote"## Annotations to be added to manager pod##podAnnotations: &#123;&#125; # Example: # iam.amazonaws.com/role: &lt;my_role_arn&gt; 123456gcr.io/kubernetes-helm/tiller:v2.12.3docker pull fishead/gcr.io.kubernetes-helm.tiller:v2.12.3docker tag fishead/gcr.io.kubernetes-helm.tiller:v2.12.3 gcr.io/kubernetes-helm/tiller:v2.12.3去 docker hub 找个镜像仓库 配置 Kubernetes cluster details 参考 官方文档 - Adding an existing Kubernetes cluster 的说明 安装 Helm Tiller 点击页面 Install 按钮 kubectl get pods -A 能看到 install-helm 的 pod 根据 pod/install-helm 生成 yaml 1kubectl get pod install-helm -n gitlab-managed-apps -o yaml &gt; install-helm.yaml 修改 yaml 中的 pod 启动命令, 加入阿里云仓库 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata:......spec: containers: - args: - -c - $(COMMAND_SCRIPT) command: - /bin/sh env: - name: HELM_VERSION value: 2.12.3 - name: TILLER_NAMESPACE value: gitlab-managed-apps - name: COMMAND_SCRIPT value: |- set -xeo pipefail helm init --tiller-tls --tiller-tls-verify --tls-ca-cert /data/helm/helm/config/ca.pem --tiller-tls-cert /data/helm/helm/config/cert.pem --tiller-tls-key /data/helm/helm/config/key.pem --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.12.3 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts helm repo add stable https://burdenbear.github.io/kube-charts-mirror/ helm repo update...... 根据修改后的 yaml 重新创建 pod 12kubectl delete pod install-helm -n gitlab-managed-apps kubectl apply -f install-helm.yaml 删除 namespace 1kubectl delete namespaces gitlab-managed-apps 重新点击页面 Install 按钮]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 笔记]]></title>
    <url>%2F2019%2F06%2F08%2FEffective-Java-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1. 考虑使用静态工厂方法替代构造方法优点 通过方法名体现不同构造方式的差异 不需要每次调用时都创建一个新对象 ( 单例模式, 享元模式 ) 可以返回其返回类型的任何子类型的对象 在编写包含该方法的类时，返回的对象的类不需要存在 限制 没有公共或受保护构造方法的类不能被子类化 ( 因为大部分实现会将构造函数设为私有 ) 没有构造函数那么明显 2. 当构造方法参数过多时使用 builder 模式分析 可伸缩 (telescoping constructor) 构造方法模式, 多个不同参数数量的构造方法 当有很多参数时，很难编写代码，而且很难读懂它 JavaBeans 模式, 调用 setter 方法来设置参数 由于构造方法在多次调用中被分割，在过程中可能处于不一致的状态 Builder 模式, 构造方法为 private, 通过内嵌的 Builder 类调用 build() 返回本身 12NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100).sodium(35).carbohydrate(27).build(); 可以在 build() 里加入参数检查 编写简单, 易读 能区分必须和可选字段 平行层次的 Builder, 抽象类有抽象的 builder, 具体的类有具体的 builder 12345NyPizza pizza = new NyPizza.Builder(SMALL) .addTopping(SAUSAGE).addTopping(ONION).build();Calzone calzone = new Calzone.Builder() .addTopping(HAM).sauceInside().build(); 3. 使用私有构造方法或枚类实现 Singleton 属性私有构造方法 通过公共静态成员提供访问 123456// Singleton with public final fieldpublic class Elvis &#123; public static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public void leaveTheBuilding() &#123; ... &#125;&#125; 通过静态的工厂方法提供访问 优点: 可以灵活地改变你的想法 优点: 可以编写一个泛型单例工厂 优点: 方法引用可以用 Supplier 1234567 // Singleton with static factorypublic class Elvis &#123; private static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public static Elvis getInstance() &#123; return INSTANCE; &#125; public void leaveTheBuilding() &#123; ... &#125;&#125; 警告 可以使用 AccessibleObject.setAccessible 方法，以反射方式调用私有构造方法 为了维护单例的保证，声明所有的实例属性为 transient，并提供一个 readResolve 方法 枚举 声明单一元素的枚举类 简洁 提供了免费的序列化机制 提供了针对多个实例化的保证 12345// Enum singleton - the preferred approachpublic enum Elvis &#123; INSTANCE; public void leaveTheBuilding() &#123; ... &#125;&#125; 4. 使用私有构造方法执行非实例化 如一些工具类, 只包含静态方法, 可以用来避免其实例化和被继承 12345678// Noninstantiable utility classpublic class UtilityClass &#123; // Suppress default constructor for noninstantiability private UtilityClass() &#123; throw new AssertionError(); &#125; ... // Remainder omitted&#125; 5. 使用依赖注入取代硬连接资源(hardwiringresources) 不要使用单例或静态的实用类来实现一个类，该类依赖于一个或多个底层资源，这些资源的行为会影响类的行为，并且不让类直接创建这些资源。相反，将资源或工厂传递给构造方法 (或静态工厂或 builder 模式)。这种称为依赖注入的实践将极大地增强类的灵活性、可重用性和可测试性。 6. 避免创建不必要的对象 如果对象是不可变的，它总是可以被重用 注意无意识的自动装箱 (autoboxing) 在现代 JVM 实现上, 使用构造方法创建和回收小的对象其实是非常廉价的, 创建额外的对象以增强程序的清晰度，简单性或功能性通常是件好事 除非池中的对象非常重量级，否则通过维护自己的对象池来避免对象创建是一个坏主意 7. 消除过期的对象引用 当一个类自己管理内存时，程序员应该警惕内存泄漏问题 每当一个元素被释放时，元素中包含的任何对象引用都应该被清除 另一个常见的内存泄漏来源是缓存 只要在缓存之外存在对某个项 (entry) 的键 (key) 引用，那么这项就是明确有关联的，就可以用 WeakHashMap 来表示缓存 可以通过一个后台线程或将新的项添加到缓存时顺便清理 第三个常见的内存泄漏来源是监听器和其他回调 客户端注册回调, 仅将它们保存在 WeakHashMap 的键 (key) 中 8. 避免使用 Finalizer 和 Cleaner 机制缺点 不能保证他们能够及时执行 不要相信 System.gc 和 System.runFinalization 方法, 可能会增加被执行的几率，但不能保证一定会执行 在执行 Finalizer 机制过程中，未捕获的异常会被忽略 导致严重的性能损失 严重的安全问题: 它们会打开你的类来进行 Finalizer 机制攻击 正确做法 实现 AutoCloseable 接口，并要求客户在不再需要时调用每个实例 close 方法，通常使用 try-with-resources 确保终止 合法用途 作为一个安全网 (safetynet)，以防资源的拥有者忽略了它的 close 方法 与本地对等类(native peers)有关。本地对等类是一个由普通对象委托的本地 (非 Java) 对象。由于本地对等类不是普通的 Java 对象，所以垃圾收集器并不知道它，当它的 Java 对等对象被回收时，本地对等类也不会回收。 9. 使用 try-with-resources 语句替代 try-finally 语句对比 try-finally 12345678910111213141516// try-finally is ugly when used with more than one resource!static void copy(String src, String dst) throws IOException &#123; InputStream in = new FileInputStream(src); try &#123; OutputStream out = new FileOutputStream(dst); try &#123; byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); &#125; finally &#123; out.close(); &#125; &#125; finally &#123; in.close();&#125; &#125; try-with-resources 12345678// try-with-resources on multiple resources - short and sweetstatic void copy(String src, String dst) throws IOException &#123; try (InputStream in = new FileInputStream(src); OutputStream out = new FileOutputStream(dst)) &#123; byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0)&#125; &#125; 分析 用 try-finally 语句关闭资源, 有多个资源时容易犯错 try-with-resources 块和 finally 块中的代码都可能抛出异常 finally 块中close()时抛出的异常会冲掉前面的异常 try-with-resources 块中close()(不可见) 时抛出的异常会被抑制 (suppressed), 这些抑制的异常没 有被抛弃， 而是打印在堆栈跟踪中，并标注为被抑制了 10. 重写 equals 方法时遵守通用约定不覆盖 equals 方法的场景 每个类的实例都是固有唯一的 类不需要提供一个“逻辑相等(logical equality)”的测试功能 父类已经重写了 equals 方法，则父类行为完全适合于该子类 类是私有的或包级私有的 覆盖 equals 方法的场景 需要提供一个逻辑相等的判断, 且父类还没重写过equals 通用约定 自反性 (Reflexivity): 对于任何非空引用 x， x.equals(x) 必须返回 true 对称性 (Symmetry): 对于任何非空引用 x 和 y，如果且仅当 y.equals(x) == true, x.equals(y)必须为 true 传递性 (Transitivity): 对于任何非空引用 x、y、z，如果 x.equals(y) == true, y.equals(z) == true, 则x.equals(z)必须返回 true 一致性 (Consistent): 对于任何非空引用 x 和 y，如果在 equals 比较中使用的信息没有修改，则x.equals(y)的多次调用必须始终返回 true 或始终返回 false 非空性 (Non-nullity): 对于任何非空引用 x, x.equals(null) 必须返回 false 编写高质量 equals 方法 使用 instanceof 运算符来检查参数是否具有正确的类型, 再将参数转换为正确的类型 检查是否与类中的每个重要属性相匹配 不同类型的比较方式 对于类型为非 float 或 double 的基本类型，使用 == 运算符进行比较 对于对象引用属性，递归地调用 equals 方法 对于 float 基本类型的属性，使用静态方法 Float.compare(float, float) 对于 double 基本类型的属性，使用静态方法 Double.compare(double, double) 对于数组属性，将这些准则应用于每个元素 某些对象引用的属性可能合法地包含 null。 为避免出现 NullPointerException 异常，请使用静态方法Objects.equals(Object, Object) 检查这些属性是否相等 性能优化 用 == 运算符检查参数是否为该对象的引用, 如果是, 返回 true 首先比较最可能不同的属性, 开销比较小的属性 不要比较不属于对象逻辑状态的属性 不需要比较可以从“重要属性”计算出来的派生属性 注意 当重写 equals 方法时，同时也要重写 hashCode 方法 不要让 equals 方法试图太聪明, 例如File 类不应该试图将引用的符号链接等同于同一文件对象 在 equal 时方法声明中，不要将参数 Object 替换成其他类型 11. 重写 equals 方法时同时也要重写 hashcode 方法Object 规范 当在一个应用程序执行过程中，如果在 equals 方法比较中没有修改任何信息，在一个对象上重复调用 hashCode 方法时，它必须始终返回相同的值。从一个应用程序到另一个应用程序的每一次执行返回的值可以是不一致的。 如果两个对象根据 equals(Object) 方法比较是相等的，那么在两个对象上调用 hashCode 就必须产生的结果是相同的整数。 如果两个对象根据 equals(Object) 方法比较并不相等，则不要求在每个对象上调用 hashCode 都必须产生不同的结果。 但是，程序员应该意识到，为不相等的对象生成不同的结果可能会提高散列表(hash tables)的性能。 一个简单的配方12345678// Typical hashCode method@Overridepublic int hashCode() &#123; int result = Short.hashCode(areaCode); result = 31 * result + Short.hashCode(prefix); result = 31 * result + Short.hashCode(lineNum); return result;&#125; 基本类型，使用 Type.hashCode(f) 方法计算，其中 Type 类是对应属性 f 基本类型的包装类。 如果该属性是一个对象引用，并且该类的 equals 方法通过递归调用 equals 来比较该属性，并递归地调用 hashCode 方法。 如果需要更复杂的比较，则计算此字段的“范式(“canonical representation)”，并在范式上调用 hashCode。 如果该字段的值为空，则使用 0(也可以使用其他常数，但通常来使用 0 表示)。 如果属性 f 是一个数组，把它看作每个重要的元素都是一个独立的属性。 也就是说，通过递归地应用 这些规则计算每个重要元素的哈希码，并且将每个步骤的值合并。 如果数组没有重要的元素，则使用一个常量，最好不要为 0。如果所有元素都很重要，则使用 Arrays.hashCode 方法。 12. 始终重写 toString 方法 便于调试 13. 谨慎地重写 clone 方法缺陷 Cloneable 接口缺少 clone 方法, 而 Object 的 clone 方法是受保护的, 所以不能保证调用成功 clone 方法的通用规范 ( 非绝对 ) x.clone() != x x.clone().getClass() == x.getClass() x.clone().equals(x) == true 如果一个 final 类有一个不调用 super.clone 的 clone 方法, 那么这个类没有理由实现 Cloneable 接口，因为它不依赖于 Object 的 clone 实现的行为 复制构造方法及其静态工厂变体与 Cloneable/clone 相比有许多优点 不依赖风险很大的语言外的对象创建机制 不要求遵守那些不太明确的惯例 不会与 final 属性的正确使用相冲突 不会抛出不必要的检查异常 不需要类型转换 14. 考虑实现 Comparable 接口 如果你正在编写具有明显自然顺序(如字母顺序，数字顺序或时间顺序)的值类，则应该实现 Comparable 接口: 123public interface Comparable&lt;T&gt; &#123; int compareTo(T t);&#125; compareTo 方法的通用约定 将此对象与指定的对象按照排序进行比较, 返回值可能为负整数, 零或正整数, 因为此对象对应小于，等于或大于指定的对象。 如果指定对象的类型与此对象不能进行比较，则引发 ClassCastException 异常 实现类必须确保所有 x 和 y 都满足 sgn(x.compareTo(y)) == -sgn(y. compareTo(x))。 （这意味着 当且仅当 y.compareTo(x) 抛出异常时， x.compareTo(y) 必须抛出异常。） 实现类还必须确保该关系是可传递的：(x. compareTo(y) &gt; 0 &amp;&amp; y.compareTo(z) &gt; 0) 意味着x.compareTo(z) &gt; 0 。 对于所有的 z，实现类必须确保 x.compareTo(y) == 0 意味着 sgn(x.compareTo(z)) == sgn(y.compareTo(z)) 。 推荐 (x.compareTo(y) == 0) == (x.equals(y)) ，但不是必需的。 一般来说，任何实现了 Comparable 接口的类违反了这个条件都应该清楚地说明这个事实。 推荐的语言是 “注意：这个类有一个自然顺序，与 equals 不一致”。 使用包装类中的静态 compare 方法或 Comparator 接口中的构建方法 12345678910// Comparator based on static compare methodstatic Comparator&lt;Object&gt; hashCodeOrder = new Comparator&lt;&gt;() &#123; public int compare(Object o1, Object o2) &#123; return Integer.compare(o1.hashCode(), o2.hashCode()); &#125;&#125;;// Comparator based on Comparator construction methodstatic Comparator&lt;Object&gt; hashCodeOrder = Comparator.comparingInt(o -&gt; o.hashCode()); 请避免使用 “&lt;” 和 “&gt;” 运算符 15. 使类和成员的可访问性最小化 使用尽可能低的访问级别 类具有公共静态 final 数组属性，或返回这样一个属性的访问器是错误的 12// Potential security hole!public static final Thing[] VALUES = &#123; ... &#125;; 有两种方法可以解决这个问题 你可以使公共数组私有并添加一个公共的不可变列表： 123private static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final List&lt;Thing&gt; VALUES = Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES)); 可以将数组设置为 private，并添加一个返回私有数组拷贝的公共方法： 1234private static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final Thing[] values() &#123; return PRIVATE_VALUES.clone();&#125; 16. 在公共类中使用访问方法而不是公共属性 如果一个类在其包之外是可访问的，则提供访问方法来保留更 改类内部表示的灵活性 如果一个类是包级私有的，或者是一个私有的内部类，那么暴露它的数据属性就没有什么本质上的错误 17. 最小化可变性要使一个类不可变，请遵循以下五条规则 不要提供修改对象状态的方法（也称为 mutators） 确保这个类不能被继承 把所有属性设置为 final 把所有的属性设置为 private 确保对任何可变组件的互斥访问 ( 确保该类的客户端无法获得对这些对象的引用 ) 不可变对象本质上是线程安全的 不需要也不应该在一个不可变的类上提供一个 clone 方法或拷贝构造方法（copy constructor） 一个不可变的类可以提供静态的工厂来缓存经常被请求的实例 一个类不得允许子类化, 可以设置类为 final , 更灵活的方式是使其所有的构造方法私有或包级私有，并添加公共静态工厂，而不是公共构造方法 如果一个类不能设计为不可变类，那么也要尽可能地限制它的可变性 18. 组合优于继承 与方法调用不同，继承打破了封装 , 父类的实现可能会不断变化, 子类可能会被破坏，即使它的代码没有任何改变 包装类 ( 装饰器模式 ) 有时组合和转发的结合被不精确地地称为委托 (delegation). 从技术上讲，除非包装对象把自身传递给被包装对象，否则不是委托 包装类的缺点 包装类不适合在回调框架（callback frameworks）中使用，其中对象将自我引用传递给其他对象以用于后续调用（“回调”） 编写转发方法有些繁琐 只有在子类真的是父类的子类型的情况下，继承才是合适的 19. 如使用继承则设计，应当文档说明，否则不该使用 这个类必须准确地描述重写这个方法带来的影响 测试为继承而设计的类的唯一方法是编写子类, 经验表明，三个子类通常足以测试一个可继承的类。 这些子类应该由父类作者以外的人编写 构造方法绝不能直接或间接调用可重写的方法 如果你决定在为继承而设计的类中实现 Cloneable 或 Serializable 接口, 那么 clone 和 readObject 都不会直接或间接调用可重写的方法 20. 接口优于抽象类 Java 只允许单一继承 接口是定义混合类型（mixin）的理想选择, 允许构建非层级类型的框架 可以通过提供一个抽象的骨架实现类（abstract skeletal implementation class）来与接口一起使用，将接口和抽象类的优点结合起来。 接口定义了类型，可能提供了一些默认的方法，而骨架实现类在原始接口方法的顶层实现了剩余的非原始接口方法。 继承骨架实现需要大部分的工作来实现一个接口。 这就是模板方法设计模式 21. 为后代设计接口 编写一个默认方法并不总是可能的，它保留了每个可能的实现的所有不变量 在默认方法的情况下，接口的现有实现类可以在没有错误或警告的情况下编译，但在运行时会失败 22. 接口仅用来定义类型 常量接口模式是对接口的糟糕使用 23. 优先使用类层次而不是标签类24. 优先考虑静态成员类 非静态成员类的每个实例都隐含地与其包含的类的宿主实例相关联, 可以调用宿主实例上的方法, 不可能在没有宿主实例的情况下创建非静态成员类的实例 非静态成员类的一个常见用法 1234567891011// Typical use of a nonstatic member classpublic class MySet&lt;E&gt; extends AbstractSet&lt;E&gt; &#123; ... // Bulk of the class omitted @Override public Iterator&lt;E&gt; iterator() &#123; return new MyIterator(); &#125; private class MyIterator implements Iterator&lt;E&gt; &#123; ... &#125;&#125; 如果你声明了一个不需要访问宿主实例的成员类，总是把 static 修饰符放在它的声明中，使它成为一个静态成员类，而不是非静态的成员类 有四种不同的嵌套类，每个都有它的用途。 如果一个嵌套的类需要在一个方法之外可见，或者太长而不能很好地适应一个方法，使用一个成员类。 如果一个成员类的每个实例都需要一个对其宿主实例的引用，使其成为非静态的; 否则，使其静态。 假设这个类属于一个方法内部，如果你只需要从一个地方创建实例，并且存在一个预置类型来说明这个类的特征，那么把它作为一个匿名类; 否则，把它变成局部类。 25. 将源文件限制为单个顶级类26. 不要使用原始类型 如果你使用原始类型，则会丧失泛型的所有安全性和表达上的优势 以下是使用泛型类型的 instanceof 运算符的首选方法 12345// Legitimate use of raw type - instanceof operatorif (o instanceof Set) &#123; // Raw type Set&lt;?&gt; s = (Set&lt;?&gt;) o; // Wildcard type ...&#125; 27. 消除非检查警告 尽可能 地消除每一个未经检查的警告 如果你不能消除警告，但你可以证明引发警告的代码是类型安全的，那么（并且只能这样）用@SuppressWarnings(“unchecked”) 注解来抑制警告 每当使用 @SuppressWarnings(“unchecked”) 注解时，请添加注释，说明为什么是安全的 28. 列表优于数组29. 优先考虑泛型30. 优先使用泛型方法31. 使用限定通配符来增加 API 的灵活性12345// pushAll method without wildcard type - deficient!public void pushAll(Iterable&lt;E&gt; src) &#123; for (E e : src) push(e);&#125; 假设有一个 Stack&lt;Number&gt;，并调用 push(intVal)，其中 intVal 的类型是 Integer, 会得到错误消息 12345// Wildcard type for a parameter that serves as an E producerpublic void pushAll(Iterable&lt;? extends E&gt; src) &#123; for (E e : src) push(e);&#125; 为了获得最大的灵活性，对代表生产者或消费者的输入参数使用通配符类型 producer-extends, consumer-super（PECS） 如果一个参数化类型代表一个 T 生产者，使用 &lt;? extends T&gt; 如果它代表 T 消费者，则使用 &lt;? super T&gt; 改造 max 方法 123public static &lt;T extends Comparable&lt;T&gt;&gt; T max(List&lt;T&gt; list)public static &lt;T extends Comparable&lt;? super T&gt;&gt; T max(List&lt;? extends T&gt; list) max 方法返回 T , 所以 List&lt;? extends T&gt; list Comparable 的 T 消费 T 实例（并生成指示顺序关系的整数）, 所以 &lt;T extends Comparable&lt;? super T&gt;&gt; 32. 合理地结合泛型和可变参数 在 Java 7 中， @SafeVarargs 注解已添加到平台，以允许具有泛型可变参数的方法的作者自动禁止客户端警 告 如果可变参数数组仅用于从调用者向方法传递可变数量的参数, 那么该方法是安全的 33. 优先考虑类型安全的异构容器]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>effective-java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 关键字 transient]]></title>
    <url>%2F2019%2F05%2F31%2FJava-%E5%85%B3%E9%94%AE%E5%AD%97-transient%2F</url>
    <content type="text"><![CDATA[transient 一旦变量被 transient 修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 transient 关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被 transient 关键字修饰的。变量如果是用户自定义类变量，则该类需要实现 Serializable 接口。 一个静态变量不管是否被 transient 修饰，均不能被序列化。 参考: https://www.cnblogs.com/lanxuezaipiao/p/3369962.html]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 关键字 volatile、synchronized]]></title>
    <url>%2F2019%2F05%2F31%2FJava-%E5%85%B3%E9%94%AE%E5%AD%97-volatile%E3%80%81synchronized%2F</url>
    <content type="text"><![CDATA[volatile, synchronized1. 内存模型的相关概念 CPU 的高速缓存解决了内存读写数据慢的问题。但在多核 CPU 或多线程中, 会有缓存一致性问题: 如果一个变量在多个 CPU中 都存在缓存 ( 此变量称为共享变量 )，那么就可能存在缓存不一致的问题。 通常来说有以下 2 种解决方法 ( 硬件层面上提供的方式 )： 通过在总线加 LOCK# 锁的方式 在锁住总线期间，其他 CPU 无法访问内存，会导致效率低下。 通过缓存一致性协议 当CPU写数据时，如果发现其他 CPU 中也存在该变量的副本，会发出信号通知其他 CPU 将该变量的缓存行置为无效状态，因此当其他 CPU 需要读取这个变量时会从内存重新读取。 2. 并发编程三大性质1. 原子性 一个操作或者多个操作, 要么全部执行并且执行的过程不会被任何因素打断, 要么就都不执行。 2. 可见性 当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 3. 有序性 即程序执行的顺序按照代码的先后顺序执行。 JVM 优化时可能会发生指令重排序（Instruction Reorder） 不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是会保证程序最终执行结果和代码顺序执行的结果是一致的 ( as-if-serial语义 )。 指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 以下代码中, 指令重排序可能会导致语句 1 在语句 2 之后执行, 使得线程 2 doSomethingwithconfig(context); 中 context 未初始化导致程序出错 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 3. Java 内存模型 ( Java Memory Model, JMM ) 在 Java 虚拟机规范中试图定义一种 Java 内存模型来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。 在 Java 内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java 对原子性, 可见性, 有序性提供的保证1. 原子性 除 long 和 double 外的基本类型的赋值操作 所有引用 reference 的赋值操作 java.concurrent.Atomic.* 包中所有类的一切操作 2. 可见性 当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 通过 synchronized 和 Lock 也能够保证可见性，synchronized 和 Lock 能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。 3. 有序性 可以通过 volatile 关键字来保证一定的有序性 可以通过 synchronized 和 Lock 来保证有序性 Java 内存模型具备一些先天的“有序性”，称为 happens-before 原则。如果两个操作的执行次序无法从 happens-before 原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 happens-before原则（先行发生原则）, 摘自《深入理解 Java 虚拟机》: 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个 unLock 操作先行发生于后面对同一个锁的 lock 操作 volatile 变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作 A 先行发生于操作 B，而操作 B 又先行发生于操作 C，则可以得出操作 A 先行发生于操作 C 线程启动规则：Thread 对象的 start() 方法先行发生于此线程的每个一个动作 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过 Thread.join() 方法结束、Thread.isAlive() 的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的 finalize() 方法的开始 4. 深入剖析 volatile 关键字1. volatile 关键字的两层语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被 volatile 修饰之后，那么就具备了两层语义： 1. 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 ​ 2. 禁止进行指令重排序。 2. volatile 不能保证原子性3. volatile 能在一定程度上保证有序性 volatile 关键字能禁止指令重排序，所以 volatile 能在一定程度上保证有序性。 12345678// x、y 为非 volatile 变量// flag 为 volatile 变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 volatile 关键字能保证，执行到语句 3 时，语句 1 和语句 2 必定是执行完毕了的 ( 1 和 2 的执行顺序不保证 )，且语句 1 和语句 2 的执行结果对语句 3、语句 4、语句 5 是可见的。 4. volatile 的原理和实现机制 volatile 是如何保证可见性和禁止指令重排序, 摘自《深入理解 Java 虚拟机》: “ 观察加入 volatile 关键字和没有加入 volatile 关键字时所生成的汇编代码发现，加入 volatile 关键字时，会多出一个 lock 前缀指令 ” lock 前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供 3 个功能： 1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2. 它会强制将对缓存的修改操作立即写入主存； 3. 如果是写操作，它会导致其他 CPU 中对应的缓存行无效。 5. volatile 的使用场景 保证操作是原子性操作，才能保证使用 volatile 关键字的程序在并发时能够正确执行。 状态标记量 12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep();&#125;doSomethingwithconfig(context); Double Check 1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 加入 volatile 原因: 由于指令重排, instance = new Singleton(); 语句的内部的实现可能会在完成对象初始化之前就已经将其赋值给 instance 引用，恰好另一个线程进入方法判断 instance 引用不为 null，然后就将其返回使用，导致出错。 5. synchronized 关键字1. 使用场景 2. 对象锁（monitor）机制 锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。Synchronized 先天具有重入性。 12345678class MyClass &#123; public synchronized void method1() &#123; method2(); &#125; public synchronized void method2() &#123; &#125;&#125; 每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。 对于 synchronized 方法或者 synchronized 代码块，当出现异常时，JVM 会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。 参考: https://www.cnblogs.com/dolphin0520/p/3920373.html https://juejin.im/post/5ae6dc04f265da0ba351d3ff#heading-1]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>volatile</tag>
        <tag>synchronized</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串池、常量池（运行时常量池、Class常量池）、intern]]></title>
    <url>%2F2019%2F05%2F30%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%B1%A0%E3%80%81%E5%B8%B8%E9%87%8F%E6%B1%A0%EF%BC%88%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%E3%80%81Class%E5%B8%B8%E9%87%8F%E6%B1%A0%EF%BC%89%E3%80%81intern%2F</url>
    <content type="text"><![CDATA[重点： Class 常量池 是编译期生成的 Class 文件中的常量池 运行时常量池 是 Class 常量池 在运行时的表示形式 字符串常量池 是缓存字符串的，全局共享，它保存的是 String 实例对象的引用 Class 常量池常量池中主要存放两大类常量：字面量（Literal） 和 符号引用（Symbolic Reference），字面量比较接近于 Java 语言层面的常量概念，如文本字符串 、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念，包括了下面三类常量： 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 通过 javap 命令可以看到 Class 文件的常量池部分。 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分，它是 Class 文件中每一个类或接口的常量池表的运行时表示形式。Class 常量池中存放的编译期生成的各种字面量和符号引用，将在类加载后进入方法区的运行时常量池中存放。 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态常量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆）。目的应该是与 Java 堆区分开来。 字符串常量池字符串常量池是用来缓存字符串的。对于需要重复使用的字符串，每次都去 new 一个 String 实例，无疑是在浪费资源，降低效率。所以，JVM 一般会维护一个字符串常量池，它是全局共享的，你可是把它看成是一个 HashSet。需要注意的是，它保存的是堆中字符串实例的引用，并不存储实例本身。 String.intern()查找当前字符串常量池是否存在该字符串的引用，如果存在直接返回引用；如果不存在，则在堆中创建该字符串实例，并返回其引用。 在 JDK 1.6，常量池是在永久代中的，和 Java 堆是完全分开来的区域 在 JDK 1.7, 常量池在堆中]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-安装-Ubuntu-国内环境]]></title>
    <url>%2F2019%2F05%2F30%2Fk8s-%E5%AE%89%E8%A3%85-Ubuntu-%E5%9B%BD%E5%86%85%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[参考: https://zhuanlan.zhihu.com/p/46341911 https://juejin.im/post/5ca6ff3a51882543e10ecb36 添加相应的源 由于需要下载Kubeadm，Kubelet和Kubernetes-cni，多以需要添加源。 123cat &lt;&lt;EOF &gt; /etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial mainEOF 下载Docker &amp; Kubeadm &amp; Kubelet &amp; Kubernetes-cni 1apt-get update &amp;&amp; apt-get install -y docker.io kubelet kubernetes-cni=0.7.5-00 kubeadm 添加源之后，使用 apt-get update 命令会出现错误，原因是缺少相应的key，可以通过下面命令添加(E084DAB9 为上面报错的key后8位)：1234gpg --keyserver keyserver.ubuntu.com --recv-keys E084DAB9gpg --export --armor E084DAB9 | sudo apt-key add -apt-get update &amp;&amp; apt-get install -y docker.io kubelet kubernetes-cni=0.7.5-00 kubeadm 调整系统参数 1234567sudo swapoff -a # 暂时关闭 swapoff sudo systemctl stop ufw.service # 关闭防火墙 sudo /etc/init.d/apparmor stop # 停止 AppArmorsudo modprobe br_netfiltersudo echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptablessudo echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tablessudo sysctl -p 获取镜像列表 由于官方镜像地址被墙，所以我们需要首先获取所需镜像以及它们的版本。然后从国内镜像站获取。1kubeadm config images list 获取镜像列表后可以通过下面的脚本从阿里云获取：123456789101112131415images=( # 下面的镜像应该去除"k8s.gcr.io/"的前缀，版本换成上面获取到的版本 kube-apiserver:v1.14.2 kube-controller-manager:v1.14.2 kube-scheduler:v1.14.2 kube-proxy:v1.14.2 pause:3.1 etcd:3.3.10 coredns:1.3.1)for imageName in $&#123;images[@]&#125; ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageNamedone master 初始化环境1kubeadm init --kubernetes-version=v1.14.2 --apiserver-advertise-address=192.168.14.177 --apiserver-cert-extra-sans=122.112.207.8 --pod-network-cidr=10.244.0.0/16 1234567--apiserver-advertise-address=&lt;ip&gt;指定 apiserver 的访问 ip, ip 默认为当前虚拟机的默认网卡 ip.当 ip 为内网地址时, k8s 集群只能搭建在网段内部,如果有需求通过外网 ip 来操作 apiserver,需要在启动集群时添加可信参数 --apiserver-cert-extra-sans=116.196.81.106 将外网的 ip 添加进去. 当 ip 为外网地址时,可以实现不同网段的虚拟机组成 k8s 集群. 配置授权信息 所需的命令在init成功后也会有提示，主要是为了保存相关的配置信息在用户目录下，这样不用每次都输入相关的认证信息。123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 添加网络插件 ( flannel ) 上面安装成功后如果通过查询 kube-system 下 Pod 的运行情况，会发现和网络相关的 Pod 都处于 Pending 的状态，这是因为缺少相关的网络插件，而网络插件有很多个，可以选择自己需要的。1kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel 查看是否安装成功1kubectl get pods -n kube-system 如果出现类似下面的情况就说明安装完成了12345678NAME READY STATUS RESTARTS AGEcoredns-86c58d9df4-mmjls 1/1 Running 0 6h26mcoredns-86c58d9df4-p7brk 1/1 Running 0 6h26metcd-promote 1/1 Running 1 6h26mkube-apiserver-promote 1/1 Running 1 6h26mkube-controller-manager-promote 1/1 Running 1 6h25mkube-proxy-6ml6w 1/1 Running 1 6h26mkube-scheduler-promote 1/1 Running 1 6h25m node 加入集群 根据 master 节点 init 后提供的 join 命令加入集群 1kubeadm join 192.168.14.177:6443 --token 3pkmi4.okabu6926c6pfett --discovery-token-ca-cert-hash sha256:138262f072252dd81692cf02ed5cb0d090202a67db38962c6e64b1bb065b6014 在 master 节点确认 1kubectl get nodes 节点都为 Ready 状态说明集群已经正确启动了。 1234NAME STATUS ROLES AGE VERSIONndoe2 Ready master 3h38m v1.14.2node1 Ready &lt;none&gt; 28s v1.14.2node3 Ready &lt;none&gt; 3h2m v1.14.2 其他 节点之间的 hostname 不能重复, 修改命令为 1sudo hostnamectl set-hostname &#123;$name&#125; 默认情况下，通过 kubeadm create token 创建的 token ，过期时间是24小时，这就是为什么过了一天无法再次使用之前记录的 kube join 原生脚本的原因，也可以运行 kubeadm token create --ttl 0 生成一个永不过期的 token 查看 token 1$ kubeadm token list 查看 CA证书 sha256 1openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' 删除节点 12345(master)kubectl drain $&#123;nodename&#125; --delete-local-datakubectl delete node $&#123;nodename&#125; 1234567891011121314(node)kubeadm resetsystemctl stop kubeletsystemctl stop dockerrm -rf /var/lib/cni/rm -rf /var/lib/kubelet/*rm -rf /etc/cni/ifconfig cni0 downifconfig flannel.1 downifconfig docker0 downip link delete cni0ip link delete flannel.1systemctl start docker 获取 master 的 join token 1kubeadm token create --print-join-command]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>install</tag>
      </tags>
  </entry>
</search>
